<!DOCTYPE HTML>
<html lang="zh" class="sidebar-visible no-js light">
    <head>
        <!-- Book generated using mdBook -->
        <meta charset="UTF-8">
        <title>Lean中文教程</title>
        
        <meta name="robots" content="noindex" />
        
        


        <!-- Custom HTML head -->
        


        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <meta name="description" content="">
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta name="theme-color" content="#ffffff" />

        
        <link rel="icon" href="favicon.svg">
        
        
        <link rel="shortcut icon" href="favicon.png">
        
        <link rel="stylesheet" href="css/variables.css">
        <link rel="stylesheet" href="css/general.css">
        <link rel="stylesheet" href="css/chrome.css">
        
        <link rel="stylesheet" href="css/print.css" media="print">
        

        <!-- Fonts -->
        <link rel="stylesheet" href="FontAwesome/css/font-awesome.css">
        
        <link rel="stylesheet" href="fonts/fonts.css">
        

        <!-- Highlight.js Stylesheets -->
        <link rel="stylesheet" href="highlight.css">
        <link rel="stylesheet" href="tomorrow-night.css">
        <link rel="stylesheet" href="ayu-highlight.css">

        <!-- Custom theme stylesheets -->
        

        
    </head>
    <body>
        <!-- Provide site root to javascript -->
        <script type="text/javascript">
            var path_to_root = "";
            var default_theme = window.matchMedia("(prefers-color-scheme: dark)").matches ? "navy" : "light";
        </script>

        <!-- Work around some values being stored in localStorage wrapped in quotes -->
        <script type="text/javascript">
            try {
                var theme = localStorage.getItem('mdbook-theme');
                var sidebar = localStorage.getItem('mdbook-sidebar');

                if (theme.startsWith('"') && theme.endsWith('"')) {
                    localStorage.setItem('mdbook-theme', theme.slice(1, theme.length - 1));
                }

                if (sidebar.startsWith('"') && sidebar.endsWith('"')) {
                    localStorage.setItem('mdbook-sidebar', sidebar.slice(1, sidebar.length - 1));
                }
            } catch (e) { }
        </script>

        <!-- Set the theme before any content is loaded, prevents flash -->
        <script type="text/javascript">
            var theme;
            try { theme = localStorage.getItem('mdbook-theme'); } catch(e) { }
            if (theme === null || theme === undefined) { theme = default_theme; }
            var html = document.querySelector('html');
            html.classList.remove('no-js')
            html.classList.remove('light')
            html.classList.add(theme);
            html.classList.add('js');
        </script>

        <!-- Hide / unhide sidebar before it is displayed -->
        <script type="text/javascript">
            var html = document.querySelector('html');
            var sidebar = 'hidden';
            if (document.body.clientWidth >= 1080) {
                try { sidebar = localStorage.getItem('mdbook-sidebar'); } catch(e) { }
                sidebar = sidebar || 'visible';
            }
            html.classList.remove('sidebar-visible');
            html.classList.add("sidebar-" + sidebar);
        </script>

        <nav id="sidebar" class="sidebar" aria-label="Table of contents">
            <div class="sidebar-scrollbox">
                <ol class="chapter"><li class="chapter-item expanded affix "><a href="title_page.html">Lean 4定理证明</a></li><li class="chapter-item expanded "><a href="introduction.html"><strong aria-hidden="true">1.</strong> 介绍</a></li><li><ol class="section"><li class="chapter-item expanded "><a href="setup.html"><strong aria-hidden="true">1.1.</strong> 安装</a></li></ol></li><li class="chapter-item expanded "><a href="dependent_type_theory.html"><strong aria-hidden="true">2.</strong> 依赖类型论</a></li><li class="chapter-item expanded "><a href="propositions_and_proofs.html"><strong aria-hidden="true">3.</strong> 命题和证明</a></li><li class="chapter-item expanded "><a href="quantifiers_and_equality.html"><strong aria-hidden="true">4.</strong> 量词与等价</a></li><li class="chapter-item expanded "><a href="tactics.html"><strong aria-hidden="true">5.</strong> 证明策略</a></li><li class="chapter-item expanded "><a href="interacting_with_lean.html"><strong aria-hidden="true">6.</strong> Interacting with Lean</a></li><li class="chapter-item expanded "><a href="inductive_types.html"><strong aria-hidden="true">7.</strong> Inductive Types</a></li><li class="chapter-item expanded "><a href="induction_and_recursion.html"><strong aria-hidden="true">8.</strong> Induction and Recursion</a></li><li class="chapter-item expanded "><a href="structures_and_records.html"><strong aria-hidden="true">9.</strong> 结构体和记录</a></li><li class="chapter-item expanded "><a href="type_classes.html"><strong aria-hidden="true">10.</strong> Type Classes</a></li><li class="chapter-item expanded "><a href="conv.html"><strong aria-hidden="true">11.</strong> 转换策略模式</a></li><li class="chapter-item expanded "><a href="axioms_and_computation.html"><strong aria-hidden="true">12.</strong> Axioms and Computation</a></li></ol>
            </div>
            <div id="sidebar-resize-handle" class="sidebar-resize-handle"></div>
        </nav>

        <div id="page-wrapper" class="page-wrapper">

            <div class="page">
                
                <div id="menu-bar-hover-placeholder"></div>
                <div id="menu-bar" class="menu-bar sticky bordered">
                    <div class="left-buttons">
                        <button id="sidebar-toggle" class="icon-button" type="button" title="Toggle Table of Contents" aria-label="Toggle Table of Contents" aria-controls="sidebar">
                            <i class="fa fa-bars"></i>
                        </button>
                        <button id="theme-toggle" class="icon-button" type="button" title="Change theme" aria-label="Change theme" aria-haspopup="true" aria-expanded="false" aria-controls="theme-list">
                            <i class="fa fa-paint-brush"></i>
                        </button>
                        <ul id="theme-list" class="theme-popup" aria-label="Themes" role="menu">
                            <li role="none"><button role="menuitem" class="theme" id="light">Light (default)</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="rust">Rust</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="coal">Coal</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="navy">Navy</button></li>
                            <li role="none"><button role="menuitem" class="theme" id="ayu">Ayu</button></li>
                        </ul>
                        
                        <button id="search-toggle" class="icon-button" type="button" title="Search. (Shortkey: s)" aria-label="Toggle Searchbar" aria-expanded="false" aria-keyshortcuts="S" aria-controls="searchbar">
                            <i class="fa fa-search"></i>
                        </button>
                        
                    </div>

                    <h1 class="menu-title">Lean中文教程</h1>

                    <div class="right-buttons">
                        
                        <a href="print.html" title="Print this book" aria-label="Print this book">
                            <i id="print-button" class="fa fa-print"></i>
                        </a>
                        
                        
                        <a href="https://github.com/subfish-zhou/theorem_proving_in_lean4_zh_CN" title="Git repository" aria-label="Git repository">
                            <i id="git-repository-button" class="fa fa-github"></i>
                        </a>
                        
                    </div>
                </div>

                
                <div id="search-wrapper" class="hidden">
                    <form id="searchbar-outer" class="searchbar-outer">
                        <input type="search" name="search" id="searchbar" name="searchbar" placeholder="Search this book ..." aria-controls="searchresults-outer" aria-describedby="searchresults-header">
                    </form>
                    <div id="searchresults-outer" class="searchresults-outer hidden">
                        <div id="searchresults-header" class="searchresults-header"></div>
                        <ul id="searchresults">
                        </ul>
                    </div>
                </div>
                

                <!-- Apply ARIA attributes after the sidebar and the sidebar toggle button are added to the DOM -->
                <script type="text/javascript">
                    document.getElementById('sidebar-toggle').setAttribute('aria-expanded', sidebar === 'visible');
                    document.getElementById('sidebar').setAttribute('aria-hidden', sidebar !== 'visible');
                    Array.from(document.querySelectorAll('#sidebar a')).forEach(function(link) {
                        link.setAttribute('tabIndex', sidebar === 'visible' ? 0 : -1);
                    });
                </script>

                <div id="content" class="content">
                    <main>
                        <h1><a class="header" href="#在lean-4中进行定理证明" id="在lean-4中进行定理证明">在Lean 4中进行定理证明</a></h1>
<p><em>作者：Jeremy Avigad, Leonardo de Moura, Soonho Kong and Sebastian Ullrich, 以及Lean社区</em>
<em>译者 <a href="https://github.com/subfish-zhou">subfish_zhou</a></em></p>
<p>本中文教程旨在教你使用Lean 4。 参考<a href="https://leanprover.github.io/lean4/doc/">Lean 4 Manual</a>中的<a href="https://leanprover.github.io/lean4/doc/setup.html">Setting Up Lean section</a>一节来安装Lean。
本书的Lean 2 和Lean 3 版本见<a href="https://leanprover.github.io/theorem_proving_in_lean/">这里</a>。</p>
<p>欢迎对本译文提出宝贵意见，可邮件至<a href="mailto:subfishzhou@gmail.com">subfishzhou@gmail.com</a>
译者自制的习题参考答案在本项目Github仓库的Exercise文件夹中。本项目尚未完工。</p>
<h1><a class="header" href="#介绍" id="介绍">介绍</a></h1>
<h2><a class="header" href="#计算机和定理证明" id="计算机和定理证明">计算机和定理证明</a></h2>
<p><em>形式验证</em>（Formal verification）包括使用逻辑和计算方法来验证用精确的数学术语表达的命题。这包括普通的数学定理，以及硬件或软件、网络协议、机械和混合系统中的形式命题。在实践中，验证数学命题和验证系统的正确性之间很类似：形式验证用数学术语描述硬件和软件系统，在此基础上验证其命题的正确性，这就像定理证明的过程。相反，一个数学定理的证明可能需要冗长的计算，在这种情况下，验证定理的真实性需要验证计算过程是否出错。</p>
<p>二十世纪的逻辑学发展表明，绝大多数传统证明方法可以简化为若干基础系统中的一小套公理和规则。有了这种简化，计算机能以两种方式帮助建立命题：它可以首先帮助寻找一个证明，并可以帮助验证一个所谓的证明是正确的。</p>
<p><em>自动定理证明</em>（Automated theorem proving）着眼于 &quot;寻找&quot; 证明。解析定理证明器、表格法定理证明器、快速可满足性求解器等提供了在命题逻辑和一阶逻辑中验证公式有效性的方法。还有些系统为特定的语言和问题提供搜索和决策程序，例如整数或实数上的线性或非线性表达式。像SMT（satisfiability modulo theories）这样的架构将通用的搜索方法与特定领域的程序相结合。计算机代数系统和专门的数学软件包提供了进行数学计算或寻找数学对象的手段。计算也可以被看作是一种证明，而这些系统也可以帮助建立数学命题。</p>
<p>自动推理系统努力追求能力和效率，但往往牺牲稳定性。这样的系统可能会有bug，而且很难保证它们所提供的结果是正确的。相比之下，<em>交互式定理证明</em>侧重于 &quot;验证&quot; 证明，要求每个命题都有合适的公理基础的证明来支持。这就设定了非常高的标准：每一条推理规则和每一步计算都必须通过求助于先前的定义和定理来证明，一直到基本公理和规则。事实上，大多数这样的系统提供了精心设计的 &quot;证明对象&quot;，可以传给其他系统并独立检查。构建这样的证明通常需要用户更多的输入和交互，但它可以让你获得更深入、更复杂的证明。</p>
<p><em>Lean 定理证明器</em>旨在融合交互式和自动化定理证明，它将自动化工具和方法置于一个支持用户交互和构建完整公理化证明的框架中。它的目标是支持数学推理和复杂系统的推理，并验证这两个领域的命题。</p>
<p>Lean的底层逻辑有一个计算的解释，与此同时Lean可以被视为一种编程语言。更重要的是，它可以被看作是一个编写具有精确语义的程序的系统，以及对程序所计算的功能进行推理。Lean也有机制作为它自己的<em>元编程语言</em>，这意味着你可以使用Lean本身实现自动化和扩展Lean的功能。Lean的这些方面将在本教程的配套教程【Lean 4编程】（<em>译者注：尚未完成</em>）中进行探讨，本书只介绍计算方面。</p>
<h2><a class="header" href="#关于lean" id="关于lean">关于Lean</a></h2>
<p><em>Lean</em> 项目由微软雷德蒙德研究院的Leonardo de Moura在2013年发起，这是个长期项目，自动化方法的潜力会在未来逐步被挖掘。Lean是在<a href="LICENSE">Apache 2.0 license</a>下发布的，这是一个允许他人自由使用和扩展代码和数学库的许可性开源许可证。</p>
<p>通常有两种办法来运行Lean。第一个是网页版本：由Javascript编写，包含标准定义和定理库，编辑器会下载到你的浏览器上运行。这是个方便快捷的办法。</p>
<p>第二种是本地版本：本地版本远快于网页版本，并且非常灵活。Visual Studio Code和Emacs扩展模块给编写和调试证明提供了有力支撑，因此更适合正式使用。源代码和安装方法见<a href="https://github.com/leanprover/lean4/">https://github.com/leanprover/lean4/</a>.</p>
<p>本教程介绍的是Lean的当前版本：Lean 4。</p>
<h2><a class="header" href="#关于本书" id="关于本书">关于本书</a></h2>
<p>本书的目的是教你在Lean中编写和验证证明，并且不太需要针对Lean的基础知识。首先，你将学习Lean所基于的逻辑系统，它是<em>依赖类型论</em>（dependent type theory）的一个版本，足以证明几乎所有传统的数学定理，并且有足够的表达能力自然地表示数学定理。更具体地说，Lean是基于具有归纳类型（inductive type）的构造演算（Calculus of Construction）系统的类型论版本。Lean不仅可以定义数学对象和表达依赖类型论的数学断言，而且还可以作为一种语言来编写证明。</p>
<p>由于完全深入细节的公理证明十分复杂，定理证明的难点在于让计算机尽可能多地填补证明细节。你将通过<a href="dependent_type_theory.html">依赖类型论</a>语言来学习各种方法实现自动证明，例如项重写，以及Lean中的项和表达式的自动简化方法。同样，<em>阐释</em>（elaboration）和<em>类型推理</em>（type inference）的方法，可以用来支持灵活的代数推理。</p>
<p>最后，你会学到Lean的一些特性，包括与系统交流的语言，和Lean提供的对复杂理论和数据的管理机制。</p>
<p>在本书中你会见到类似下面这样的代码：</p>
<pre><code class="language-lean">theorem and_commutative (p q : Prop) : p ∧ q → q ∧ p :=
  fun hpq : p ∧ q =&gt;
  have hp : p := And.left hpq
  have hq : q := And.right hpq
  show q ∧ p from And.intro hq hp
</code></pre>
<p>你可以在<a href="https://leanprover-community.github.io/lean-web-editor/#">Lean在线编辑器</a>中尝试运行这些代码。（<em>译者注：该编辑器速度很慢，且目前只支持Lean 3，但足够运行本书中大多数代码。</em>）</p>
<h2><a class="header" href="#致谢" id="致谢">致谢</a></h2>
<p>This tutorial is an open access project maintained on Github. Many people have contributed to the effort, providing
corrections, suggestions, examples, and text. We are grateful to Ulrik Buchholz, Kevin Buzzard, Mario Carneiro, Nathan
Carter, Eduardo Cavazos, Amine Chaieb, Joe Corneli, William DeMeo, Marcus Klaas de Vries, Ben Dyer, Gabriel Ebner,
Anthony Hart, Simon Hudon, Sean Leather, Assia Mahboubi, Gihan Marasingha, Patrick Massot, Christopher John Mazey,
Sebastian Ullrich, Floris van Doorn, Daniel Velleman, Théo Zimmerman, Paul Chisholm, and Chris Lovett for their contributions.  Please see <a href="https://github.com/leanprover/">lean prover</a> and <a href="https://github.com/leanprover-community/">lean community</a> for an up to date list
of our amazing contributors.</p>
<h2><a class="header" href="#安装lean" id="安装lean">安装Lean</a></h2>
<p><em>（本节译自Lean Manual的Setup一节，并记录了译者个人遇到的报错以及解决方案）</em></p>
<p>目前有两种方法来建立Lean 4 开发环境：</p>
<ul>
<li><a href="./setup.html#%E5%9F%BA%E6%9C%AC%E5%AE%89%E8%A3%85">基本安装</a> (Linux/macOS/Windows): 用 <a href="https://github.com/leanprover/elan"><code>elan</code></a> + 预装代码编辑器</li>
<li><a href="./setup.html#Nix%E5%AE%89%E8%A3%85">Nix安装</a> (Linux/macOS/WSL): 用 <a href="https://nixos.org/nix/">Nix</a>，这是个用于安装项目所有本地依赖的包管理器</li>
</ul>
<p><a href="./setup.html#%E5%BF%AB%E9%80%9F%E5%BC%80%E5%A7%8B">快速开始</a>一节介绍使用VS Code使用Lean的方法。</p>
<h2><a class="header" href="#基本安装" id="基本安装">基本安装</a></h2>
<p>所有受支持平台的发布版本都可以在<a href="https://github.com/leanprover/lean4/releases">https://github.com/leanprover/lean4/releases</a>中找到。
推荐使用精益版本管理器<a href="https://github.com/leanprover/elan"><code>elan</code></a>代替下载文件和手动设置路径。</p>
<pre><code class="language-sh">$ elan self update  # 以防你很久没升级+elan
# 下载及应用最新的Lean4版本 (https://github.com/leanprover/lean4/releases)
$ elan default leanprover/lean4:stable
# 也可选择，用最新的nightly构建 (https://github.com/leanprover/lean4-nightly/releases)
$ elan default leanprover/lean4:nightly
# 也可选择，只在当前目录下使用Lean4
$ elan override set leanprover/lean4:stable
</code></pre>
<h2><a class="header" href="#快速开始" id="快速开始">快速开始</a></h2>
<p>这些指令将引导你使用“基本”设置和VS Code作为编辑器来设置Lean。</p>
<ol>
<li>
<p>用<a href="https://github.com/leanprover/elan"><code>elan</code></a>安装最新版Lean 4 nightly：在任何支持bash的shell中运行：</p>
<pre><code class="language-sh">curl https://raw.githubusercontent.com/leanprover/elan/master/elan-init.sh -sSf | sh -s -- --default-toolchain leanprover/lean4:nightly
</code></pre>
<p>或者在Windows系统中, 在<code>cmd</code>中运行</p>
<pre><code class="language-sh">curl -O --location https://raw.githubusercontent.com/leanprover/elan/master/elan-init.ps1
powershell -f elan-init.ps1 --default-toolchain leanprover/lean4:nightly
del elan-init.ps1
</code></pre>
<blockquote>
<p>译者注：需要科学上网。我在运行第二句话时发生了“<em>无法加载文件……因为在此系统上禁止运行此脚本</em>”报错。解决方案是
1.用管理员身份运行Powershell；
2.输入命令<code>set-Executionpolicy Remotesigned</code>，选择<code>Y</code>；
然后就可以正常使用了。考虑到系统安全性，建议安装完成后将该选项改回默认值<code>N</code>。
效果如下图
<img src="images/setuplean.png" alt="setuplean" />
由于本网站无法提供讨论区，欢迎向译者提供新的报错和解决方案，以丰富本页面。可邮件至<a href="mailto:subfishzhou@gmail.com">subfishzhou@gmail.com</a></p>
</blockquote>
</li>
<li>
<p>安装 <a href="https://code.visualstudio.com/">VS Code</a>。</p>
</li>
<li>
<p>打开VS Code 安装<code>lean4</code>扩展。</p>
<p><img src="images/code-ext.png" alt="installing the vscode-lean4 extension" /></p>
</li>
<li>
<p>创建一个以 <code>.lean</code> 为扩展名的新文件，并写入以下代码：</p>
<pre><code class="language-lean">import Leanpkg

#eval Leanpkg.leanVersionString
</code></pre>
<p>你会看到语法高亮。当你把光标放在最后一行时，在右边有一个“Lean信息视图”，显示已经安装的Lean版本。</p>
<p><img src="images/code-success.png" alt="successful setup" /></p>
</li>
<li>
<p>你成功了！尝试打开一个包含包文件<code>leanpkg.toml</code>的Lean文件夹。您可以在命令行上使用<code>leanpkg init</code>创建自己的包。软件包<strong>必须</strong>使用“文件&gt;打开文件夹…”来打开导入。在运行“Lean 4: Refresh File Dependencies”(<code>Ctrl+Shift+X</code>)后，保存的更改可以在其他文件中看到。</p>
</li>
</ol>
<h1><a class="header" href="#依赖类型论" id="依赖类型论">依赖类型论</a></h1>
<p>依赖类型论（Dependent type theory）是一种强大而富有表达力的语言，允许你表达复杂的数学断言，编写复杂的硬件和软件规范，并以自然和统一的方式对这两者进行推理。Lean是基于一个被称为<em>构造演算</em>（Calculus of Constructions）的依赖类型论的版本，它拥有一个可数的非累积性宇宙（non-cumulative universe）的层次结构以及递归类型（inductive type）。在本章结束时，你将学会一大部分。</p>
<h2><a class="header" href="#普通类型论" id="普通类型论">普通类型论</a></h2>
<p>“类型论”得名于其中每个表达式都有一个<em>类型</em>。举例：在一个给定的语境中，<code>x + 0</code>可能表示一个自然数，<code>f</code>可能表示一个定义在自然数上的函数。Lean中的自然数是任意精度的无符号整数。</p>
<p>这里的一些例子展示了如何声明对象以及检查其类型。</p>
<pre><code class="language-lean">/- 定义一些常数 -/

def m : Nat := 1       -- m 是自然数
def n : Nat := 0
def b1 : Bool := true  -- b1 是布尔型
def b2 : Bool := false

/- 检查类型 -/

#check m            -- 输出: Nat
#check n
#check n + 0        -- Nat
#check m * (n + 0)  -- Nat
#check b1           -- Bool
#check b1 &amp;&amp; b2     -- &quot;&amp;&amp;&quot; is the Boolean and
#check b1 || b2     -- Boolean or
#check true         -- Boolean &quot;true&quot;

/- 求值（Evaluate） -/

#eval 5 * 4         -- 20
#eval m + 2         -- 3
#eval b1 &amp;&amp; b2      -- false
</code></pre>
<p>位于<code>/-</code>和<code>-/</code>之间的文本组成了一个注释块，会被Lean的编译器忽略。类似地，两条横线<code>--</code>后面也是注释。注释块可以嵌套，这样就可以“注释掉”一整块代码，这和任何程序语言都是一样的。</p>
<p><code>def</code>关键字声明工作环境中的新常量符号。在上面的例子中，<code>def m : Nat := 1</code>定义了一个<code>Nat</code>类型的新常量<code>m</code>，其值为<code>1</code>。<code>#check</code>命令要求Lean给出它的类型，用于向系统询问信息的辅助命令都以井号(#)开头。<code>#eval</code>命令让Lean计算给出的表达式。你应该试试自己声明一些常量和检查一些表达式的类型。</p>
<p>普通类型论的强大之处在于，你可以从其他类型中构建新的类型。例如，如果<code>a</code>和<code>b</code>是类型，<code>a -&gt; b</code>表示从<code>a</code>到<code>b</code>的函数类型，<code>a × b</code>表示由<code>a</code>元素与<code>b</code>元素配对构成的类型，也称为<em>笛卡尔积</em>。注意<code>×</code>是一个Unicode符号，可以使用<code>\times</code>或简写<code>\tim</code>来输入。合理使用Unicode提高了易读性，所有现代编辑器都支持它。在Lean标准库中，你经常看到希腊字母表示类型，Unicode符号<code>→</code>是<code>-&gt;</code>的更紧凑版本。</p>
<pre><code class="language-lean">#check Nat → Nat      -- 用&quot;\to&quot; or &quot;\r&quot;来打出这个箭头
#check Nat -&gt; Nat     -- 也可以用 ASCII 符号

#check Nat × Nat      -- 用&quot;\times&quot;打出乘号
#check Prod Nat Nat   -- 换成ASCII 符号

#check Nat → Nat → Nat
#check Nat → (Nat → Nat)  --  结果和上一个一样

#check Nat × Nat → Nat
#check (Nat → Nat) → Nat -- 一个“泛函”

#check Nat.succ     -- Nat → Nat
#check (0, 1)       -- Nat × Nat
#check Nat.add      -- Nat → Nat → Nat

#check Nat.succ 2   -- Nat
#check Nat.add 3    -- Nat → Nat
#check Nat.add 5 2  -- Nat
#check (5, 9).1     -- Nat
#check (5, 9).2     -- Nat

#eval Nat.succ 2   -- 3
#eval Nat.add 5 2  -- 7
#eval (5, 9).1     -- 5
#eval (5, 9).2     -- 9
</code></pre>
<p>同样，你应该自己尝试一些例子。</p>
<p>让我们看一些基本语法。你可以通过输入<code>\to</code>或者<code>\r</code>或者<code>\-&gt;</code>来输入<code>→</code>。你也可以就用ASCII码<code>-&gt;</code>，所以表达式<code>Nat -&gt; Nat</code>和<code>Nat → Nat</code>意思是一样的，都表示以一个自然数作为输入并返回一个自然数作为输出的函数类型。Unicode符号<code>×</code>是笛卡尔积，用<code>\times</code>输入。小写的希腊字母<code>α</code>，<code>β</code>，和<code>γ</code>等等常用来表示类型变量，可以用<code>\a</code>，<code>\b</code>，和<code>\g</code>来输入。</p>
<p>这里还有一些需要注意的事情。第一，函数<code>f</code>应用到值<code>x</code>上写为<code>f x</code>(例：<code>Nat.succ 2</code>)。第二，当写类型表达式时，箭头是<em>右结合</em>的；例如，<code>Nat.add</code>的类型是<code>Nat → Nat → Nat</code>，等价于<code>Nat → (Nat → Nat)</code>。</p>
<p>因此你可以把<code>Nat.add</code>看作一个函数，它接受一个自然数并返回另一个函数，该函数接受一个自然数并返回一个自然数。在类型论中，把<code>Nat.add</code>函数看作接受一对自然数作为输入并返回一个自然数作为输出的函数通常会更方便。系统允许你“部分应用”函数<code>Nat.add</code>，比如<code>Nat.add 3</code>具有类型<code>Nat → Nat</code>，即<code>Nat.add 3</code>返回一个“等待”第二个参数<code>n</code>的函数，然后可以继续写<code>Nat.add 3 n</code>。</p>
<blockquote>
<p>注：取一个类型为<code>Nat × Nat → Nat</code>的函数，然后“重定义”它，让它变成<code>Nat → Nat → Nat</code>类型，这个过程被称作<em>柯里化</em>（currying）。</p>
</blockquote>
<p>如果你有<code>m : Nat</code>和<code>n : Nat</code>，那么<code>(m, n)</code>表示<code>m</code>和<code>n</code>组成的有序对，其类型为<code>Nat × Nat</code>。这个方法可以制造自然数对。反过来，如果你有<code>p : Nat × Nat</code>，之后你可以写<code>p.1 : Nat</code>和<code>p.2 : Nat</code>。这个方法用于提取它的两个组件。</p>
<h2><a class="header" href="#类型作为对象" id="类型作为对象">类型作为对象</a></h2>
<p>Lean所依据的依赖类型论对普通类型论的其中一项升级是，类型本身（如<code>Nat</code>和<code>Bool</code>这些东西）也是对象，因此也具有类型。</p>
<pre><code class="language-lean">#check Nat               -- Type
#check Bool              -- Type
#check Nat → Bool        -- Type
#check Nat × Bool        -- Type
#check Nat → Nat         -- ...
#check Nat × Nat → Nat
#check Nat → Nat → Nat
#check Nat → (Nat → Nat)
#check Nat → Nat → Bool
#check (Nat → Nat) → Nat
</code></pre>
<p>上面的每个表达式都是类型为<code>Type</code>的对象。你也可以为类型声明新的常量:</p>
<pre><code class="language-lean">def α : Type := Nat
def β : Type := Bool
def F : Type → Type := List
def G : Type → Type → Type := Prod

#check α        -- Type
#check F α      -- Type
#check F Nat    -- Type
#check G α      -- Type → Type
#check G α β    -- Type
#check G α Nat  -- Type
</code></pre>
<p>正如上面所示，你已经看到了一个类型为<code>Type → Type → Type</code>的函数例子，即笛卡尔积 <code>Prod</code>：</p>
<pre><code class="language-lean">def α : Type := Nat
def β : Type := Bool

#check Prod α β       -- Type
#check α × β          -- Type

#check Prod Nat Nat   -- Type
#check Nat × Nat      -- Type
</code></pre>
<p>这里有另一个例子：给出任意类型<code>α</code>，那么类型<code>List α</code>是类型为<code>α</code>的元素的列表的类型。</p>
<pre><code class="language-lean">def α : Type := Nat

#check List α    -- Type
#check List Nat  -- Type
</code></pre>
<p>看起来Lean中任何表达式都有一个类型，因此你可能会想到：<code>Type</code>自己的类型是什么？</p>
<pre><code class="language-lean">#check Type      -- Type 1
</code></pre>
<p>实际上，你已经遇到了Lean系统的一个最微妙的方面：Lean的底层基础有无限的类型层次：</p>
<pre><code class="language-lean">#check Type     -- Type 1
#check Type 1   -- Type 2
#check Type 2   -- Type 3
#check Type 3   -- Type 4
#check Type 4   -- Type 5
</code></pre>
<p>可以将<code>Type 0</code>看作是一个由“小”或“普通”类型组成的宇宙。然后，<code>Type 1</code>是一个更大的类型范围，其中包含<code>Type 0</code>作为一个元素，而<code>Type 2</code>是一个更大的类型范围，其中包含<code>Type 1</code>作为一个元素。这个列表是不确定的，所以对于每个自然数<code>n</code>都有一个<code>Type n</code>。<code>Type</code>是<code>Type 0</code>的缩写：</p>
<pre><code class="language-lean">#check Type
#check Type 0
</code></pre>
<p>然而，有些操作需要在类型宇宙上具有<em>多态</em>（polymorphic）。例如，<code>List α</code>应该对任何类型的<code>α</code>都有意义，无论<code>α</code>存在于哪种类型的宇宙中。所以函数<code>List</code>有如下的类型：</p>
<pre><code class="language-lean">#check List    -- Type u_1 → Type u_1
</code></pre>
<p>这里<code>u_1</code>是一个覆盖类型级别的变量。<code>#check</code>命令的输出意味着当<code>α</code>有类型<code>Type n</code>时，<code>List α</code>也有类型<code>Type n</code>。函数<code>Prod</code>具有类似的多态性：</p>
<pre><code class="language-lean">#check Prod    -- Type u_1 → Type u_2 → Type (max u_1 u_2)
</code></pre>
<p>你可以使用 <code>universe</code> 命令来声明宇宙变量，这样就可以定义定义多态常量：</p>
<pre><code class="language-lean">universe u

def F (α : Type u) : Type u := Prod α α

#check F    -- Type u → Type u
</code></pre>
<p>可以通过在定义F时提供universe参数来避免使用universe命令：</p>
<pre><code class="language-lean">def F.{u} (α : Type u) : Type u := Prod α α

#check F    -- Type u → Type u
</code></pre>
<h2><a class="header" href="#函数抽象和求值" id="函数抽象和求值">函数抽象和求值</a></h2>
<p>Lean提供 <code>fun</code> (或 <code>λ</code>)关键字用于从给定表达式创建函数，如下所示：</p>
<pre><code class="language-lean">#check fun (x : Nat) =&gt; x + 5   -- Nat → Nat
#check λ (x : Nat) =&gt; x + 5     -- λ 和 fun 是同义词
#check fun x : Nat =&gt; x + 5     -- 同上
#check λ x : Nat =&gt; x + 5       -- 同上
</code></pre>
<p>你可以通过传递所需的参数来计算lambda函数：</p>
<pre><code class="language-lean">#eval (λ x : Nat =&gt; x + 5) 10    -- 15
</code></pre>
<p>从另一个表达式创建函数的过程称为<em>lambda 抽象</em>。假设你有一个变量<code>x : α</code>和一个表达式<code>t : β</code>，那么表达式<code>fun (x : α) =&gt; t</code>或者<code>λ (x : α) =&gt; t</code>是一个类型为<code>α → β</code>的对象。这个从<code>α</code>到<code>β</code>的函数把任意<code>x</code>映射到<code>t</code>。</p>
<p>这有些例子：</p>
<pre><code class="language-lean">#check fun x : Nat =&gt; fun y : Bool =&gt; if not y then x + 1 else x + 2
#check fun (x : Nat) (y : Bool) =&gt; if not y then x + 1 else x + 2
#check fun x y =&gt; if not y then x + 1 else x + 2   -- Nat → Bool → Nat
</code></pre>
<p>Lean将这三个例子解释为相同的表达式；在最后一个表达式中，Lean可以从表达式<code>if not y then x + 1 else x + 2</code>推断<code>x</code>和<code>y</code>的类型。</p>
<p>一些数学上常见的函数运算的例子可以用lambda抽象的项来描述:</p>
<pre><code class="language-lean">def f (n : Nat) : String := toString n
def g (s : String) : Bool := s.length &gt; 0

#check fun x : Nat =&gt; x        -- Nat → Nat
#check fun x : Nat =&gt; true     -- Nat → Bool
#check fun x : Nat =&gt; g (f x)  -- Nat → Bool
#check fun x =&gt; g (f x)        -- Nat → Bool
</code></pre>
<p>看看这些表达式的意思。表达式<code>fun x : Nat =&gt; x</code>代表<code>Nat</code>上的恒等函数，表达式<code>fun x : Nat =&gt; true</code>表示一个永远输出<code>true</code>的常值函数，表达式<code>fun x : Nat =&gt; g (f x)</code>表示<code>f</code>和<code>g</code>的复合。一般来说，你可以省略类型注释，让Lean自己推断它。因此你可以写<code>fun x =&gt; g (f x)</code>来代替<code>fun x : Nat =&gt; g (f x)</code>。</p>
<p>你可以以函数作为参数，通过给它们命名<code>f</code>和<code>g</code>，你可以在实现中使用这些函数：</p>
<pre><code class="language-lean">#check fun (g : String → Bool) (f : Nat → String) (x : Nat) =&gt; g (f x)
-- (String → Bool) → (Nat → String) → Nat → Bool
</code></pre>
<p>你还可以以类型作为参数：</p>
<pre><code class="language-lean">#check fun (α β γ : Type) (g : β → γ) (f : α → β) (x : α) =&gt; g (f x)
</code></pre>
<p>这个表达式表示一个接受三个类型<code>α</code>，<code>β</code>和<code>γ</code>和两个函数<code>g : β → γ</code>和<code>f : α → β</code>，并返回的<code>g</code>和<code>f</code>的复合的函数。(理解这个函数的类型需要理解依赖乘积类型，下面将对此进行解释。)</p>
<p>lambda表达式的一般形式是<code>fun x : α =&gt; t</code>，其中变量<code>x</code>是一个“约束变量”：它实际上是一个占位符，其“作用域”没有扩展到表达式<code>t</code>之外。例如，表达式<code>fun (b : β) (x : α) =&gt; b</code>中的变量<code>b</code>与前面声明的常量<code>b</code>没有任何关系。事实上，这个表达式表示的函数与<code>fun (u : β) (z : α) =&gt; u</code>是一样的。形式上，可以通过给约束变量重命名来使形式相同的表达式被看作是<em>alpha等价</em>的，也就是被认为是“一样的”。Lean认识这种等价性。</p>
<p>注意到项<code>t : α → β</code>应用到项<code>s : α</code>上导出了表达式<code>t s : β</code>。回到前面的例子，为清晰起见给约束变量重命名，注意以下表达式的类型:</p>
<pre><code class="language-lean">#check (fun x : Nat =&gt; x) 1     -- Nat
#check (fun x : Nat =&gt; true) 1  -- Bool

def f (n : Nat) : String := toString n
def g (s : String) : Bool := s.length &gt; 0

#check
  (fun (α β γ : Type) (u : β → γ) (v : α → β) (x : α) =&gt; u (v x)) Nat String Bool g f 0
  -- Bool
</code></pre>
<p>表达式<code>(fun x : Nat =&gt;  x) 1</code>的类型是<code>Nat</code>。实际上，应用<code>(fun x : Nat =&gt; x)</code>到<code>1</code>上返回的值是<code>1</code>。</p>
<pre><code class="language-lean">#eval (fun x : Nat =&gt; x) 1     -- 1
#eval (fun x : Nat =&gt; true) 1  -- true
</code></pre>
<p>稍后你将看到这些项是如何计算的。现在，请注意这是依赖类型论的一个重要特征：每个项都有一个计算行为，并支持“标准化”的概念。从原则上讲，两个可以化约为相同形式的项被称为“定义等价”。它们被Lean的类型检查器认为是“相同的”，并且Lean尽其所能地识别和支持这些识别结果。</p>
<p>Lean是个完备的编程语言。它有一个生成二进制可执行文件的编译器，和一个交互式解释器。你可以用<code>#eval</code>命令执行表达式，这也是测试你的函数的好办法。</p>
<blockquote>
<p>注意到<code>#eval</code>和<code>#reduce</code><em>不是</em>等价的。<code>#eval</code>命令首先把Lean表达式编译成中间表示（intermediate representation, IR）然后用一个解释器来执行这个IR。某些内建类型（例如，<code>Nat</code>、<code>String</code>、<code>Array</code>）在IR中有更有效率的表示。IR支持使用对Lean不透明的外部函数。
<code>#reduce</code>命令建立在一个化简引擎上，类似于在Lean的可信内核中使用的那个，它是负责检查和验证表达式和证明正确性的那一部分。它的效率不如<code>#eval</code>，且将所有外部函数视为不透明的常量。之后你将了解到这两个命令之间还有其他一些差异。</p>
</blockquote>
<h2><a class="header" href="#定义" id="定义">定义</a></h2>
<p><code>def</code>关键字提供了一个声明新对象的重要方式。</p>
<pre><code class="language-lean">def double (x : Nat) : Nat :=
  x + x
</code></pre>
<p>这很类似其他编程语言中的函数。名字<code>double</code>被定义为一个函数，它接受一个类型为<code>Nat</code>的输入参数<code>x</code>，其结果是<code>x + x</code>，因此它返回类型<code>Nat</code>。然后你可以调用这个函数:</p>
<pre><code class="language-lean">#eval double 3    -- 6
</code></pre>
<p>在这种情况下你可以把<code>def</code>想成一种<code>lambda</code>。下面给出了相同的结果：</p>
<pre><code class="language-lean">def double :=
  fun (x : Nat) =&gt; x + x
</code></pre>
<p>当Lean有足够的信息来推断时，你可以省略类型声明。类型推断是Lean的重要组成部分:</p>
<pre><code class="language-lean">def double : Nat → Nat :=
  fun x =&gt; x + x

#eval double 3    -- 6
</code></pre>
<p>定义的一般形式是<code>def foo : α := bar</code>，其中<code>α</code>是表达式<code>bar</code>返回的类型。Lean通常可以推断类型<code>α</code>，但是精确写出它可以澄清你的意图，并且如果定义的右侧没有匹配你的类型，Lean将标记一个错误。</p>
<p><code>bar</code>可以是任何一个表达式，不只是一个lambda表达式。因此<code>def</code>也可以用于给一些值命名，例如：</p>
<pre><code class="language-lean">def pi := 3.141592654
</code></pre>
<p><code>def</code>可以接受多个输入参数。比如定义两自然数之和：</p>
<pre><code class="language-lean">def add (x y : Nat) :=
  x + y

#eval add 3 2               -- 5
</code></pre>
<p>参数列表可以像这样分开写：</p>
<pre><code class="language-lean">def add (x : Nat) (y : Nat) :=
  x + y

#eval add (double 3) (7 + 9)  -- 22
</code></pre>
<p>注意到这里我们使用了<code>double</code>函数来创建<code>add</code>函数的第一个参数。</p>
<p>你还可以在<code>def</code>中写一些更有趣的表达式：</p>
<pre><code class="language-lean">def greater (x y : Nat) :=
  if x &gt; y then x
  else y
</code></pre>
<p>你可能能猜到这个可以做什么。</p>
<p>还可以定义一个函数，该函数接受另一个函数作为输入。下面调用一个给定函数两次，将第一次调用的输出传递给第二次:</p>
<pre><code class="language-lean">def doTwice (f : Nat → Nat) (x : Nat) : Nat :=
  f (f x)

#eval doTwice double 2   -- 8
</code></pre>
<p>现在为了更抽象一点，你也可以指定类型参数等：</p>
<pre><code class="language-lean">def compose (α β γ : Type) (g : β → γ) (f : α → β) (x : α) : γ :=
  g (f x)
</code></pre>
<p>这句代码的意思是：函数<code>compose</code>首先接受任何两个函数作为参数，这其中两个函数各自接受一个输入。类型<code>β → γ</code>和<code>α → β</code>意思是要求第二个函数的输出类型必须与第一个函数的输入类型匹配，否则这两个函数将无法复合。</p>
<p><code>compose</code>再接受一个类型为<code>α</code>的参数作为第二个函数（这里叫做<code>f</code>）的输入，通过这个函数之后的返回结果类型为<code>β</code>，再作为第一个函数（这里叫做<code>g</code>）的输入。第一个函数返回类型为<code>γ</code>，这就是<code>compose</code>函数最终返回的类型。</p>
<p><code>compose</code>可以在任意的类型<code>α β γ</code>上使用，它可以复合任意两个函数，只要前一个的输出类型是后一个的输入类型。举例：</p>
<pre><code class="language-lean">-- def compose (α β γ : Type) (g : β → γ) (f : α → β) (x : α) : γ :=
--  g (f x)
-- def double (x : Nat) : Nat :=
--  x + x
def square (x : Nat) : Nat :=
  x * x

#eval compose Nat Nat Nat double square 3  -- 18
</code></pre>
<h2><a class="header" href="#局部定义" id="局部定义">局部定义</a></h2>
<p>Lean还允许你使用<code>let</code>关键字来引入“局部定义”。表达式<code>let a := t1; t2</code>定义等价于把<code>t2</code>中所有的<code>a</code>替换成<code>t1</code>的结果。</p>
<pre><code class="language-lean">#check let y := 2 + 2; y * y   -- Nat
#eval  let y := 2 + 2; y * y   -- 16

def twice_double (x : Nat) : Nat :=
  let y := x + x; y * y

#eval twice_double 2   -- 16
</code></pre>
<p>这里<code>twice_double x</code>定义等价于<code>(x + x) * (x + x)</code>。</p>
<p>你可以连续使用多个<code>let</code>命令来进行多次替换：</p>
<pre><code class="language-lean">#check let y := 2 + 2; let z := y + y; z * z   -- Nat
#eval  let y := 2 + 2; let z := y + y; z * z   -- 64
</code></pre>
<p>换行可以省略分号<code>;</code>。</p>
<pre><code class="language-lean">def t (x : Nat) : Nat :=
  let y := x + x
  y * y
</code></pre>
<p>表达式<code>let a := t1; t2</code>的意思很类似<code>(fun a =&gt; t2) t1</code>，但是这两者并不一样。前者中你要把<code>t2</code>中每一个<code>a</code>的实例考虑成<code>t1</code>的一个缩写。后者中<code>a</code>是一个变量，表达式<code>fun a =&gt; t2</code>不依赖于<code>a</code>的取值而可以单独具有意义。作为一个对照，考虑为什么下面的<code>foo</code>定义是合法的，但<code>bar</code>不行（因为在确定了<code>x</code>所属的<code>a</code>是什么之前，是无法让它<code>+ 2</code>的）。</p>
<pre><code class="language-lean">def foo := let a := Nat; fun x : a =&gt; x + 2
/-
  def bar := (fun a =&gt; fun x : a =&gt; x + 2) Nat
-/
</code></pre>
<h1><a class="header" href="#变量和节" id="变量和节">变量和节</a></h1>
<p>考虑下面这三个函数定义：</p>
<pre><code class="language-lean">def compose (α β γ : Type) (g : β → γ) (f : α → β) (x : α) : γ :=
  g (f x)

def doTwice (α : Type) (h : α → α) (x : α) : α :=
  h (h x)

def doThrice (α : Type) (h : α → α) (x : α) : α :=
  h (h (h x))
</code></pre>
<p>Lean提供<code>variable</code>指令来让这些声明变得紧凑：</p>
<pre><code class="language-lean">variable (α β γ : Type)

def compose (g : β → γ) (f : α → β) (x : α) : γ :=
  g (f x)

def doTwice (h : α → α) (x : α) : α :=
  h (h x)

def doThrice (h : α → α) (x : α) : α :=
  h (h (h x))
</code></pre>
<p>你可以声明任意类型的变量，不只是<code>Type</code>类型：</p>
<pre><code class="language-lean">variable (α β γ : Type)
variable (g : β → γ) (f : α → β) (h : α → α)
variable (x : α)

def compose := g (f x)
def doTwice := h (h x)
def doThrice := h (h (h x))

#print compose
#print doTwice
#print doThrice
</code></pre>
<p>输出结果表明所有三组定义具有完全相同的效果。</p>
<p><code>variable</code>命令指示Lean将声明的变量作为约束变量插入定义中，这些定义通过名称引用它们。Lean足够聪明，它能找出定义中显式或隐式使用哪些变量。因此在写定义时，你可以将<code>α</code>、<code>β</code>、<code>γ</code>、<code>g</code>、<code>f</code>、<code>h</code>和<code>x</code>视为固定的对象，并让Lean自动抽象这些定义。</p>
<p>当以这种方式声明时，变量将一直保持存在，直到所处理的文件结束。然而，有时需要限制变量的作用范围。Lean提供了节标记<code>section</code>来实现这个目的：</p>
<pre><code class="language-lean">section useful
  variable (α β γ : Type)
  variable (g : β → γ) (f : α → β) (h : α → α)
  variable (x : α)

  def compose := g (f x)
  def doTwice := h (h x)
  def doThrice := h (h (h x))
end useful
</code></pre>
<p>当一个节结束后，变量不再发挥作用。</p>
<p>你不需要缩进一个节中的行。你也不需要命名一个节，也就是说，你可以使用一个匿名的<code>section</code> /<code>end</code>对。但是，如果你确实命名了一个节，你必须使用相同的名字关闭它。节也可以嵌套，这允许你逐步增加声明新变量。</p>
<h2><a class="header" href="#命名空间" id="命名空间">命名空间</a></h2>
<p>Lean可以让你把定义放进一个“命名空间”（<code>namespace</code>）里，并且命名空间也是层次化的：</p>
<pre><code class="language-lean">namespace Foo
  def a : Nat := 5
  def f (x : Nat) : Nat := x + 7

  def fa : Nat := f a
  def ffa : Nat := f (f a)

  #check a
  #check f
  #check fa
  #check ffa
  #check Foo.fa
end Foo

-- #check a  -- error
-- #check f  -- error
#check Foo.a
#check Foo.f
#check Foo.fa
#check Foo.ffa

open Foo

#check a
#check f
#check fa
#check Foo.fa
</code></pre>
<p>当你声明你在命名空间<code>Foo</code>中工作时，你声明的每个标识符都有一个前缀<code>Foo.</code>。在打开的命名空间中，可以通过较短的名称引用标识符，但是关闭命名空间后，必须使用较长的名称。与<code>section</code>不同，命名空间需要一个名称。只有一个匿名命名空间在根级别上。</p>
<p><code>open</code>命令使你可以在当前使用较短的名称。通常，当你导入一个模块时，你会想打开它包含的一个或多个命名空间，以访问短标识符。但是，有时你希望将这些信息保留在一个完全限定的名称中，例如，当它们与你想要使用的另一个命名空间中的标识符冲突时。因此，命名空间为你提供了一种在工作环境中管理名称的方法。</p>
<p>例如，Lean把和列表相关的定义和定理都放在了命名空间<code>List</code>之中。</p>
<pre><code class="language-lean">#check List.nil
#check List.cons
#check List.map
</code></pre>
<p><code>open List</code>命令允许你使用短一点的名字：</p>
<pre><code class="language-lean">open List

#check nil
#check cons
#check map
</code></pre>
<p>像节一样，命名空间也是可以嵌套的：</p>
<pre><code class="language-lean">namespace Foo
  def a : Nat := 5
  def f (x : Nat) : Nat := x + 7

  def fa : Nat := f a

  namespace Bar
    def ffa : Nat := f (f a)

    #check fa
    #check ffa
  end Bar

  #check fa
  #check Bar.ffa
end Foo

#check Foo.fa
#check Foo.Bar.ffa

open Foo

#check fa
#check Bar.ffa
</code></pre>
<p>关闭的命名空间可以之后重新打开，甚至是在另一个文件里：</p>
<pre><code class="language-lean">namespace Foo
  def a : Nat := 5
  def f (x : Nat) : Nat := x + 7

  def fa : Nat := f a
end Foo

#check Foo.a
#check Foo.f

namespace Foo
  def ffa : Nat := f (f a)
end Foo
</code></pre>
<p>与节一样，嵌套的名称空间必须按照打开的顺序关闭。命名空间和节有不同的用途：命名空间组织数据，节声明变量，以便在定义中插入。节对于分隔<code>set_option</code>和<code>open</code>等命令的范围也很有用。</p>
<p>然而，在许多方面，<code>namespace ... end</code>结构块和<code>section ... end</code>表现出来的特征是一样的。尤其是你在命名空间中使用<code>variable</code>命令时，它的作用范围被限制在命名空间里。类似地，如果你在命名空间中使用<code>open</code>命令，它的效果在命名空间关闭后消失。</p>
<h2><a class="header" href="#依赖类型论依赖着什么" id="依赖类型论依赖着什么">依赖类型论“依赖”着什么?</a></h2>
<p>简单地说，类型可以依赖于参数。你已经看到了一个很好的例子：类型<code>List α</code>依赖于参数<code>α</code>，而这种依赖性是区分<code>List Nat</code>和<code>List Bool</code>的关键。另一个例子，考虑类型<code>Vector α n</code>，即长度为<code>n</code>的<code>α</code>元素的向量类型。这个类型取决于<em>两个</em>参数：向量中元素的类型<code>α : Type</code>和向量的长度<code>n : Nat</code>。</p>
<p>假设你希望编写一个函数<code>cons</code>，它在列表的开头插入一个新元素。<code>cons</code>应该有什么类型？这样的函数是<em>多态的</em>（polymorphic）：你期望<code>Nat</code>，<code>Bool</code>或任意类型<code>α</code>的<code>cons</code>函数表现相同的方式。因此，将类型作为<code>cons</code>的第一个参数是有意义的，因此对于任何类型<code>α</code>，<code>cons α</code>是类型<code>α</code>列表的插入函数。换句话说，对于每个<code>α</code>，<code>cons α</code>是将元素<code>a : α</code>插入列表<code>as : List α</code>的函数，并返回一个新的列表，因此有<code>cons α a as : List α</code>。</p>
<p>很明显，<code>cons α</code>具有类型<code>α → List α → List α</code>，但是<code>cons</code>具有什么类型？如果我们假设是<code>Type → α → list α → list α</code>，那么问题在于，这个类型表达式没有意义：<code>α</code>没有任何的所指，但它实际上指的是某个类型<code>Type</code>。换句话说，<em>假设</em><code>α : Type</code>是函数的首个参数，之后的两个参数的类型是<code>α</code>和<code>List α</code>，它们依赖于首个参数<code>α</code>。</p>
<pre><code class="language-lean">def cons (α : Type) (a : α) (as : List α) : List α :=
  List.cons a as

#check cons Nat        -- Nat → List Nat → List Nat
#check cons Bool       -- Bool → List Bool → List Bool
#check cons            -- (α : Type) → α → List α → List α
</code></pre>
<p>这就是<em>依赖函数类型</em>，或者<em>依赖箭头类型</em>的一个例子。给定<code>α : Type</code>和<code>β : α → Type</code>，把<code>β</code>考虑成<code>α</code>之上的类型族，也就是说，对于每个<code>a : α</code>都有类型<code>β a</code>。在这种情况下，类型<code>(a : α) → β a</code>表示的是具有如下性质的函数<code>f</code>的类型：对于每个<code>a : α</code>，<code>f a</code>是<code>β a</code>的一个元素。换句话说，<code>f</code>返回值的类型取决于其输入。</p>
<p>注意到<code>(a : α) → β</code>对于任意表达式<code>β : Type</code>都有意义。当<code>β</code>的值依赖于<code>a</code>（例如，在前一段的表达式<code>β a</code>），<code>(a : α) → β</code>表示一个依赖函数类型。当<code>β</code>的值不依赖于<code>a</code>，<code>(a : α) → β</code>与类型<code>α → β</code>无异。实际上，在依赖类型论（以及Lean）中，<code>α → β</code>表达的意思就是当<code>β</code>的值不依赖于<code>a</code>时的<code>(a : α) → β</code>。【注】</p>
<blockquote>
<p>译者注：在依赖类型论的数学符号体系中，依赖类型是用<code>Π</code>符号来表达的，在Lean 3中还使用这种表达，例如<code>Π x : α, β x</code>。Lean 4抛弃了这种对新手不友好的写法，但是沿袭了三代中另外两种意义更明朗的写法：<code>forall x : α, β x</code>和<code>∀ x : α, β x</code>。这几个表达式都和<code>(x : α) → β x</code>同义。但是个人感觉本教程这一段的讲法也对新手不友好，<code>(x : α) → β x</code>这种写法在引入“构造子”之后意义会更明朗一些（见下一个注释），当前反倒是<code>forall x : α, β x</code>这种写法更加清楚明白，在<a href="./quantifiers_and_equality.html">量词与等价</a>一章中有更详细的说明。同时，依赖类型有着更丰富的引入动机，推荐读者寻找一些拓展读物。</p>
</blockquote>
<p>回到列表的例子，你可以使用<code>#check</code>命令来检查下列的<code>List</code>函数。<code>@</code>符号以及圆括号和花括号之间的区别将在后面解释。</p>
<pre><code class="language-lean">#check @List.cons    -- {α : Type u_1} → α → List α → List α
#check @List.nil     -- {α : Type u_1} → List α
#check @List.length  -- {α : Type u_1} → List α → Nat
#check @List.append  -- {α : Type u_1} → List α → List α → List α
</code></pre>
<p>就像依赖函数类型<code>(a : α) → β a</code>通过允许<code>β</code>依赖<code>α</code>从而推广了函数类型<code>α → β</code>，依赖笛卡尔积类型<code>(a : α) × β a</code>同样推广了笛卡尔积<code>α × β</code>。依赖积类型又称为<em>sigma</em>类型，可写成<code>Σ a : α, β a</code>。你可以用<code>⟨a, b⟩</code>或者<code>Sigma.mk a b</code>来创建依赖对。</p>
<pre><code class="language-lean">universe u v

def f (α : Type u) (β : α → Type v) (a : α) (b : β a) : (a : α) × β a :=
  ⟨a, b⟩

def g (α : Type u) (β : α → Type v) (a : α) (b : β a) : Σ a : α, β a :=
  Sigma.mk a b

def h1 (x : Nat) : Nat :=
  (f Type (fun α =&gt; α) Nat x).2

#eval h1 5 -- 5

def h2 (x : Nat) : Nat :=
  (g Type (fun α =&gt; α) Nat x).2

#eval h2 5 -- 5
</code></pre>
<p>函数<code>f</code>和<code>g</code>表达的是同样的函数。</p>
<h2><a class="header" href="#隐参数" id="隐参数">隐参数</a></h2>
<p>假设我们有一个列表的实现如下：</p>
<pre><code class="language-lean">universe u
def Lst (α : Type u) : Type u := List α
def Lst.cons (α : Type u) (a : α) (as : Lst α) : Lst α := List.cons a as
def Lst.nil (α : Type u) : Lst α := List.nil
def Lst.append (α : Type u) (as bs : Lst α) : Lst α := List.append as bs
#check Lst          -- Type u_1 → Type u_1
#check Lst.cons     -- (α : Type u_1) → α → Lst α → Lst α
#check Lst.nil      -- (α : Type u_1) → Lst α
#check Lst.append   -- (α : Type u_1) → Lst α → Lst α → Lst α
</code></pre>
<p>然后，你可以建立一个自然数列表如下：</p>
<pre><code class="language-lean">#check Lst.cons Nat 0 (Lst.nil Nat)

def as : Lst Nat := Lst.nil Nat
def bs : Lst Nat := Lst.cons Nat 5 (Lst.nil Nat)

#check Lst.append Nat as bs
</code></pre>
<p>由于构造子对类型是多态的【注】，我们需要重复插入类型<code>Nat</code>作为一个参数。但是这个信息是多余的：我们可以推断表达式<code>Lst.cons Nat 5 (Lst.nil Nat)</code>中参数<code>α</code>的类型，这是通过第二个参数<code>5</code>的类型是<code>Nat</code>来实现的。类似地，我们可以推断<code>Lst.nil Nat</code>中参数的类型，这是通过它作为函数<code>Lst.cons</code>的一个参数，且这个函数在这个位置需要接收的是一个具有<code>Lst α</code>类型的参数来实现的。</p>
<blockquote>
<p>译者注：“构造子”（constructor）的概念前文未加解释，对类型论不熟悉的读者可能会困惑。它指的是一种“依赖类型的类型”，也可以看作“类型的构造器”，例如<code>λ α : α -&gt; α</code>甚至可看成<code>⋆ -&gt; ⋆</code>。当给<code>α</code>或者<code>⋆</code>赋予一个具体的类型时，这个表达式就成为了一个类型。前文中<code>(x : α) → β x</code>中的<code>β</code>就可以看成一个构造子，<code>(x : α)</code>就是传进的类型参数。原句“构造子对类型是多态的”意为给构造子中放入不同类型时它会变成不同类型。</p>
</blockquote>
<p>这是依赖类型论的一个主要特征：项包含大量信息，而且通常可以从上下文推断出一些信息。在Lean中，我们使用下划线<code>_</code>来指定系统应该自动填写信息。这就是所谓的“隐参数”。</p>
<pre><code class="language-lean">#check Lst.cons _ 0 (Lst.nil _)

def as : Lst Nat := Lst.nil _
def bs : Lst Nat := Lst.cons _ 5 (Lst.nil _)

#check Lst.append _ as bs
</code></pre>
<p>然而，敲这么多下划线仍然很无聊。当一个函数接受一个通常可以从上下文推断出来的参数时，Lean允许你指定该参数在默认情况下应该保持隐式。这是通过将参数放入花括号来实现的，如下所示:</p>
<pre><code class="language-lean">universe u
def Lst (α : Type u) : Type u := List α

def Lst.cons {α : Type u} (a : α) (as : Lst α) : Lst α := List.cons a as
def Lst.nil {α : Type u} : Lst α := List.nil
def Lst.append {α : Type u} (as bs : Lst α) : Lst α := List.append as bs

#check Lst.cons 0 Lst.nil

def as : Lst Nat := Lst.nil
def bs : Lst Nat := Lst.cons 5 Lst.nil

#check Lst.append as bs
</code></pre>
<p>唯一改变的是变量声明中<code>α : Type u</code>周围的花括号。我们也可以在函数定义中使用这个技巧：</p>
<pre><code class="language-lean">universe u
def ident {α : Type u} (x : α) := x

#check ident         -- ?m → ?m
#check ident 1       -- Nat
#check ident &quot;hello&quot; -- String
#check @ident        -- {α : Type u_1} → α → α
</code></pre>
<p>这使得<code>ident</code>的第一个参数是隐式的。从符号上讲，这隐藏了类型的说明，使它看起来好像<code>ident</code>只是接受任何类型的参数。事实上，函数<code>id</code>在标准库中就是以这种方式定义的。我们在这里选择一个非传统的名字只是为了避免名字的冲突。</p>
<p><code>variable</code>命令也可以用这种技巧来来把变量变成隐式的：</p>
<pre><code class="language-lean">universe u

section
  variable {α : Type u}
  variable (x : α)
  def ident := x
end

#check ident
#check ident 4
#check ident &quot;hello&quot;
</code></pre>
<p>Lean有非常复杂的机制来实例化隐参数，我们将看到它们可以用来推断函数类型、谓词，甚至证明。实例化这些“洞”或“占位符”的过程通常被称为<em>阐释</em>（elaboration）。隐参数的存在意味着有时可能没有足够的信息来精确地确定表达式的含义。像<code>id</code>或<code>List.nil</code>这样的表达式被认为是“多态的”，因为它可以在不同的上下文中具有不同的含义。</p>
<p>可以通过写<code>(e : T)</code>来指定表达式<code>e</code>的类型<code>T</code>。这就指导Lean的阐释器在试图解决隐式参数时使用值<code>T</code>作为<code>e</code>的类型。在下面的第二个例子中，这种机制用于指定表达式<code>id</code>和<code>List.nil</code>所需的类型:</p>
<pre><code class="language-lean">#check List.nil               -- List ?m
#check id                     -- ?m → ?m

#check (List.nil : List Nat)  -- List Nat
#check (id : Nat → Nat)       -- Nat → Nat
</code></pre>
<p>Lean中数字是重载的，但是当数字的类型不能被推断时，Lean默认假设它是一个自然数。因此，下面的前两个<code>#check</code>命令中的表达式以同样的方式进行了阐释，而第三个<code>#check</code>命令将<code>2</code>解释为整数。</p>
<pre><code class="language-lean">#check 2            -- Nat
#check (2 : Nat)    -- Nat
#check (2 : Int)    -- Int
</code></pre>
<p>然而，有时我们可能会发现自己处于这样一种情况：我们已经声明了函数的参数是隐式的，但现在想显式地提供参数。如果<code>foo</code>是有隐参数的函数，符号<code>@foo</code>表示所有参数都是显式的该函数。</p>
<pre><code class="language-lean">#check @id        -- {α : Type u_1} → α → α
#check @id Nat    -- Nat → Nat
#check @id Bool   -- Bool → Bool

#check @id Nat 1     -- Nat
#check @id Bool true -- Bool
</code></pre>
<p>第一个<code>#check</code>命令给出了标识符的类型<code>id</code>，没有插入任何占位符。而且，输出表明第一个参数是隐式的。</p>
<h1><a class="header" href="#命题和证明" id="命题和证明">命题和证明</a></h1>
<p>前一章你已经看到了在Lean中定义对象和函数的一些方法。在本章中，我们还将开始解释如何用依赖类型论的语言来编写数学命题和证明。</p>
<h2><a class="header" href="#命题即类型" id="命题即类型">命题即类型</a></h2>
<p>证明在依赖类型论语言中定义的对象的断言（assertion）的一种策略是在定义语言之上分层断言语言和证明语言。但是，没有理由以这种方式重复使用多种语言：依赖类型论是灵活和富有表现力的，我们也没有理由不能在同一个总框架中表示断言和证明。</p>
<p>例如，我们可引入一种新类型<code>Prop</code>，来表示命题，然后引入用其他命题构造新命题的构造子。</p>
<pre><code class="language-lean">def Implies (p q : Prop) : Prop := p → q
#check And     -- Prop → Prop → Prop
#check Or      -- Prop → Prop → Prop
#check Not     -- Prop → Prop
#check Implies -- Prop → Prop → Prop

variable (p q r : Prop)
#check And p q                      -- Prop
#check Or (And p q) r               -- Prop
#check Implies (And p q) (And q p)  -- Prop
</code></pre>
<p>对每个元素<code>p : Prop</code>，可以引入另一个类型<code>Proof p</code>，作为<code>p</code>的证明的类型。“公理”是这个类型中的常值。</p>
<pre><code class="language-lean">structure Proof (p : Prop) : Type where
  proof : p
#check Proof   -- Proof : Prop → Type

axiom and_comm (p q : Prop) : Proof (Implies (And p q) (And q p))

variable (p q : Prop)
#check and_comm p q     -- Proof (Implies (And p q) (And q p))
</code></pre>
<p>然而，除了公理之外，我们还需要从旧证明中建立新证明的规则。例如，在许多命题逻辑的证明系统中，我们有肯定前件式（modus ponens）推理规则:</p>
<blockquote>
<p>如果能证明<code>Implies p q</code>和<code>p</code>，则能证明<code>q</code>。</p>
</blockquote>
<p>我们可以如下地表示它：</p>
<pre><code class="language-lean">axiom modus_ponens : (p q : Prop) → Proof (Implies p q) → Proof p → Proof q
</code></pre>
<p>命题逻辑的自然演绎系统通常也依赖于以下规则：</p>
<blockquote>
<p>当假设<code>p</code>成立时，如果我们能证明<code>q</code>. 则我们能证明<code>Implies p q</code>.</p>
</blockquote>
<p>我们可以如下地表示它：</p>
<pre><code class="language-lean">axiom implies_intro : (p q : Prop) → (Proof p → Proof q) → Proof (Implies p q)
</code></pre>
<p>这个功能让我们可以合理地搭建断言和证明。确定表达式<code>t</code>是<code>p</code>的证明，只需检查<code>t</code>具有类型<code>Proof p</code>。</p>
<p>可以做一些简化。首先，我们可以通过将<code>Proof p</code>和<code>p</code>本身合并来避免重复地写<code>Proof</code>这个词。换句话说，只要我们有<code>p : Prop</code>，我们就可以把<code>p</code>解释为一种类型，也就是它的证明类型。然后我们可以把<code>t : p</code>读作<code>t</code>是<code>p</code>的证明。</p>
<p>此外，我们可以在<code>Implies p q</code>和<code>p → q</code>之间来回切换。换句话说，命题<code>p</code>和<code>q</code>之间的含义对应于一个函数，它将<code>p</code>的任何元素接受为<code>q</code>的一个元素。因此，引入连接词<code>Implies</code>是完全多余的：我们可以使用依赖类型论中常见的函数空间构造子<code>p → q</code>作为我们的蕴含概念。</p>
<p>这是在构造演算（Calculus of Constructions）中遵循的方法，因此在Lean中也是如此。自然演绎证明系统中的蕴含规则与控制函数抽象（abstraction）和应用（application）的规则完全一致，这是<em>Curry-Howard同构</em>的一个实例，有时也被称为<em>命题即类型</em>。事实上，类型<code>Prop</code>是上一章描述的类型层次结构的最底部<code>Sort 0</code>的语法糖。此外，<code>Type u</code>也只是<code>Sort (u+1)</code>的语法糖。<code>Prop</code>有一些特殊的特性，但像其他类型宇宙一样，它在箭头构造子下是封闭的:如果我们有<code>p q : Prop</code>，那么<code>p → q : Prop</code>。</p>
<p>至少有两种将命题作为类型来思考的方法。对于那些对逻辑和数学中的构造主义者来说，这是对命题含义的忠实诠释：命题<code>p</code>代表了一种数据类型，即构成证明的数据类型的说明。<code>p</code>的证明就是正确类型的对象<code>t : p</code>。</p>
<p>非构造主义者可以把它看作是一种简单的编码技巧。对于每个命题<code>p</code>，我们关联一个类型，如果<code>p</code>为假，则该类型为空，如果<code>p</code>为真，则有且只有一个元素，比如<code>*</code>。在后一种情况中，让我们说(与之相关的类型)<code>p</code>被<em>占据</em>（inhabited）。恰好，函数应用和抽象的规则可以方便地帮助我们跟踪<code>Prop</code>的哪些元素是被占据的。所以构造一个元素<code>t : p</code>告诉我们<code>p</code>确实是正确的。你可以把<code>p</code>的占据者想象成“<code>p</code>为真”的事实。对<code>p → q</code>的证明使用“<code>p</code>是真的”这个事实来得到“<code>q</code>是真的”这个事实。</p>
<p>事实上，如果<code>p : Prop</code>是任何命题，那么Lean的内核将任意两个元素<code>t1 t2 : p</code>看作定义相等，就像它把<code>(fun x =&gt; t) s</code>和<code>t[s/x]</code>看作定义等价。这就是所谓的“证明无关性”（proof irrelevance）。这意味着，即使我们可以把证明<code>t : p</code>当作依赖类型论语言中的普通对象，它们除了<code>p</code>是真的这一事实之外，没有其他信息。</p>
<p>我们所建议的思考“命题即类型”范式的两种方式在一个根本性的方面有所不同。从构造的角度看，证明是抽象的数学对象，它被依赖类型论中的合适表达式所<em>表示</em>。相反，如果我们从上述编码技巧的角度考虑，那么表达式本身并不表示任何有趣的东西。相反，是我们可以写下它们并检查它们是否有良好的类型这一事实确保了有关命题是真的。换句话说，表达式<em>本身</em>就是证明。</p>
<p>在下面的论述中，我们将在这两种说话方式之间来回切换，有时说一个表达式“构造”或“产生”或“返回”一个命题的证明，有时则简单地说它“是”这样一个证明。这类似于计算机科学家偶尔会模糊语法和语义之间的区别，有时说一个程序“计算”某个函数，有时又说该程序“是”该函数。</p>
<p>为了用依赖类型论的语言正式表达一个数学断言，我们需要展示一个项<code>p : Prop</code>。为了<em>证明</em>该断言，我们需要展示一个项<code>t : p</code>。Lean的任务，作为一个证明助手，是帮助我们构造这样一个项<code>t</code>，并验证它的格式是否良好，类型是否正确。</p>
<h2><a class="header" href="#以命题即类型的方式工作" id="以命题即类型的方式工作">以“命题即类型”的方式工作</a></h2>
<p>在“命题即类型”范式中，只涉及<code>→</code>的定理可以通过lambda抽象和应用来证明。在Lean中，<code>theorem</code>命令引入了一个新的定理：</p>
<pre><code class="language-lean">variable {p : Prop}
variable {q : Prop}

theorem t1 : p → q → p := fun hp : p =&gt; fun hq : q =&gt; hp
</code></pre>
<p>这与上一章中常量函数的定义完全相同，唯一的区别是参数是<code>Prop</code>的元素，而不是<code>Type</code>的元素。直观地说，我们对<code>p → q → p</code>的证明假设<code>p</code>和<code>q</code>为真，并使用第一个假设(平凡地)建立结论<code>p</code>为真。</p>
<p>请注意，<code>theorem</code>命令实际上是<code>def</code>命令的一个翻版：在命题和类型对应下，证明定理<code>p → q → p</code>实际上与定义关联类型的元素是一样的。对于内核类型检查器，这两者之间没有区别。</p>
<p>然而，定义和定理之间有一些实用的区别。正常情况下，永远没有必要展开一个定理的“定义”；通过证明无关性，该定理的任何两个证明在定义上都是相等的。一旦一个定理的证明完成，通常我们只需要知道该证明的存在；证明是什么并不重要。鉴于这一事实，Lean将证明标记为<em>不可还原</em>（irreducible），作为对解析器（更确切地说，是<em>阐释器</em>）的提示，在处理文件时一般不需要展开它。事实上，Lean通常能够并行地处理和检查证明，因为评估一个证明的正确性不需要知道另一个证明的细节。</p>
<p>和定义一样，<code>#print</code>命令可以展示一个定理的证明。</p>
<pre><code class="language-lean">theorem t1 : p → q → p := fun hp : p =&gt; fun hq : q =&gt; hp

#print t1
</code></pre>
<p>注意，lambda抽象<code>hp : p</code>和<code>hq : q</code>可以被视为<code>t1</code>的证明中的临时假设。Lean还允许我们通过<code>show</code>语句明确指定最后一个项<code>hp</code>的类型。</p>
<pre><code class="language-lean">theorem t1 : p → q → p :=
  fun hp : p =&gt;
  fun hq : q =&gt;
  show p from hp --试试改成 show q from hp 会怎样？
</code></pre>
<p>添加这些额外的信息可以提高证明的清晰度，并有助于在编写证明时发现错误。<code>show</code>命令只是注释类型，而且在内部，我们看到的所有关于<code>t1</code>的表示都产生了相同的项。</p>
<p>与普通定义一样，我们可以将lambda抽象的变量移到冒号的左边：</p>
<pre><code class="language-lean">theorem t1 (hp : p) (hq : q) : p := hp

#print t1    -- p → q → p
</code></pre>
<p>现在我们可以把定理<code>t1</code>作为一个函数应用。</p>
<pre><code class="language-lean">theorem t1 (hp : p) (hq : q) : p := hp

axiom hp : p

theorem t2 : q → p := t1 hp
</code></pre>
<p>这里，<code>axiom</code>声明假定存在给定类型的元素，因此可能会破坏逻辑一致性。例如，我们可以使用它来假设空类型<code>False</code>有一个元素：</p>
<pre><code class="language-lean">axiom unsound : False
-- false可导出一切
theorem ex : 1 = 0 :=
False.elim unsound
</code></pre>
<p>声明“公理”<code>hp : p</code>等同于声明<code>p</code>为真，正如<code>hp</code>所证明的那样。应用定理<code>t1 : p → q → p</code>到事实<code>hp : p</code>（也就是<code>p</code>为真）得到定理<code>t1 hp : q → p</code>。</p>
<p>回想一下，我们也可以这样写定理<code>t1</code>:</p>
<pre><code class="language-lean">theorem t1 {p q : Prop} (hp : p) (hq : q) : p := hp

#print t1
</code></pre>
<p><code>t1</code>的类型现在是<code>∀ {p q : Prop}, p → q → p</code>。我们可以把它理解为“对于每一对命题<code>p q</code>，我们都有<code>p → q → p</code>”。例如，我们可以将所有参数移到冒号的右边：</p>
<pre><code class="language-lean">theorem t1 : ∀ {p q : Prop}, p → q → p :=
  fun {p q : Prop} (hp : p) (hq : q) =&gt; hp
</code></pre>
<p>如果<code>p</code>和<code>q</code>被声明为变量，Lean会自动为我们推广它们:</p>
<pre><code class="language-lean">variable {p q : Prop}

theorem t1 : p → q → p := fun (hp : p) (hq : q) =&gt; hp
</code></pre>
<p>事实上，通过命题即类型的对应关系，我们可以声明假设<code>hp</code>为<code>p</code>，作为另一个变量:</p>
<pre><code class="language-lean">variable {p q : Prop}
variable (hp : p)

theorem t1 : q → p := fun (hq : q) =&gt; hp
</code></pre>
<p>Lean检测到证明使用<code>hp</code>，并自动添加<code>hp : p</code>作为前提。在所有情况下，命令<code>#print t1</code>仍然会产生<code>∀ p q : Prop, p → q → p</code>。这个类型也可以写成<code>∀ (p q : Prop) (hp : p) (hq :q), p</code>，因为箭头仅仅表示一个箭头类型，其中目标不依赖于约束变量。</p>
<p>当我们以这种方式推广<code>t1</code>时，我们就可以将它应用于不同的命题对，从而得到一般定理的不同实例。</p>
<pre><code class="language-lean">theorem t1 (p q : Prop) (hp : p) (hq : q) : p := hp

variable (p q r s : Prop)

#check t1 p q                -- p → q → p
#check t1 r s                -- r → s → r
#check t1 (r → s) (s → r)    -- (r → s) → (s → r) → r → s

variable (h : r → s)
#check t1 (r → s) (s → r) h  -- (s → r) → r → s
</code></pre>
<p>同样，使用命题即类型对应，类型为<code>r → s</code>的变量<code>h</code>可以看作是<code>r → s</code>存在的假设或前提。</p>
<p>作为另一个例子，让我们考虑上一章讨论的组合函数，现在用命题代替类型。</p>
<pre><code class="language-lean">variable (p q r s : Prop)

theorem t2 (h₁ : q → r) (h₂ : p → q) : p → r :=
fun h₃ : p =&gt;
show r from h₁ (h₂ h₃)
</code></pre>
<p>作为一个命题逻辑定理，<code>t2</code>是什么意思？</p>
<p>注意，数字unicode下标输入方式为<code>\0</code>，<code>\1</code>，<code>\2</code>，...。</p>
<h2><a class="header" href="#命题逻辑" id="命题逻辑">命题逻辑</a></h2>
<p>Lean定义了所有标准的逻辑连接词和符号。命题连接词有以下表示法:</p>
<table><thead><tr><th>Ascii</th><th>Unicode</th><th>编辑器缩写</th><th>定义</th></tr></thead><tbody>
<tr><td>True</td><td></td><td></td><td>True</td></tr>
<tr><td>False</td><td></td><td></td><td>False</td></tr>
<tr><td>Not</td><td>¬</td><td><code>\not</code>, <code>\neg</code></td><td>Not</td></tr>
<tr><td>/\</td><td>∧</td><td><code>\and</code></td><td>And</td></tr>
<tr><td>\/</td><td>∨</td><td><code>\or</code></td><td>Or</td></tr>
<tr><td>-&gt;</td><td>→</td><td><code>\to</code>, <code>\r</code>, <code>\imp</code></td><td></td></tr>
<tr><td>&lt;-&gt;</td><td>↔</td><td><code>\iff</code>, <code>\lr</code></td><td>Iff</td></tr>
</tbody></table>
<p>它们都接收<code>Prop</code>值。</p>
<pre><code class="language-lean">variable (p q : Prop)

#check p → q → p ∧ q
#check ¬p → p ↔ False
#check p ∨ q → q ∨ p
</code></pre>
<p>操作符的优先级如下：<code>¬ &gt; ∧ &gt; ∨ &gt; → &gt; ↔</code>。举例：<code>a ∧ b → c ∨ d ∧ e</code>意为<code>(a ∧ b) → (c ∨ (d ∧ e))</code>。<code>→</code>等二元关系是右结合的。所以如果我们有<code>p q r : Prop</code>，表达式<code>p → q → r</code>读作“如果<code>p</code>，那么如果<code>q</code>，那么<code>r</code>”。这是<code>p ∧ q → r</code>的柯里化形式。</p>
<p>在上一章中，我们观察到lambda抽象可以被看作是<code>→</code>的“引入规则”，展示了如何“引入”或建立一个蕴含。应用可以看作是一个“消去规则”，展示了如何在证明中“消去”或使用一个蕴含。其他的命题连接词在Lean的库<code>Prelude.core</code>文件中定义。(参见<a href="./interacting_with_lean.html#_importing_files">导入文件</a>以获得关于库层次结构的更多信息)，并且每个连接都带有其规范引入和消去规则。</p>
<h3><a class="header" href="#合取" id="合取">合取</a></h3>
<p>表达式<code>And.intro h1 h2</code>是<code>p ∧ q</code>的证明，它使用了<code>h1 : p</code>和<code>h2 : q</code>的证明。通常把<code>And.intro</code>称为<em>合取引入</em>规则。下面的例子我们使用<code>And.intro</code>来创建<code>p → q → p ∧ q</code>的证明。</p>
<pre><code class="language-lean">variable (p q : Prop)

example (hp : p) (hq : q) : p ∧ q := And.intro hp hq

#check fun (hp : p) (hq : q) =&gt; And.intro hp hq
</code></pre>
<p><code>example</code>命令声明了一个没有名字也不会永久保存的定理。本质上，它只是检查给定项是否具有指定的类型。它便于说明，我们将经常使用它。</p>
<p>表达式<code>And.left h</code>从<code>h : p ∧ q</code>建立了一个<code>p</code>的证明。类似地，<code>And.right h</code>是<code>q</code>的证明。它们常被称为左或右<em>合取消去</em>规则。</p>
<pre><code class="language-lean">variable (p q : Prop)

example (h : p ∧ q) : p := And.left h
example (h : p ∧ q) : q := And.right h
</code></pre>
<p>我们现在可以证明<code>p ∧ q → q ∧ p</code>：</p>
<pre><code class="language-lean">variable (p q : Prop)

example (h : p ∧ q) : q ∧ p :=
And.intro (And.right h) (And.left h)
</code></pre>
<p>请注意，引入和消去与笛卡尔积的配对和投影操作类似。区别在于，给定<code>hp : p</code>和<code>hq : q</code>，<code>And.intro hp hq</code>具有类型<code>p ∧ q : Prop</code>，而<code>Prod hp hq</code>具有类型<code>p × q : Type</code>。<code>∧</code>和<code>×</code>之间的相似性是Curry-Howard同构的另一个例子，但与蕴涵和函数空间构造子不同，在Lean中<code>∧</code>和<code>×</code>是分开处理的。然而，通过类比，我们刚刚构造的证明类似于交换一对中的元素的函数。</p>
<p>我们将在<a href="./structures_and_records.html">结构体和记录</a>一章中看到Lean中的某些类型是<em>Structures</em>，也就是说，该类型是用单个规范的<em>构造子</em>定义的，该构造子从一系列合适的参数构建该类型的一个元素。对于每一组<code>p q : Prop</code>， <code>p ∧ q</code>就是一个例子:构造一个元素的规范方法是将<code>And.intro</code>应用于合适的参数<code>hp : p</code>和<code>hq : q</code>。Lean允许我们使用<em>匿名构造子</em>表示法<code>⟨arg1, arg2, ...⟩</code>在此类情况下，当相关类型是递归类型并可以从上下文推断时。特别地，我们经常可以写入<code>⟨hp, hq⟩</code>，而不是<code>And.intro hp hq</code>:</p>
<pre><code class="language-lean">variable (p q : Prop)
variable (hp : p) (hq : q)

#check (⟨hp, hq⟩ : p ∧ q)
</code></pre>
<p>尖括号可以用<code>\&lt;</code>和<code>\&gt;</code>打出来。</p>
<p>Lean提供了另一个有用的语法小工具。给定一个递归类型<code>Foo</code>的表达式<code>e</code>(可能应用于一些参数)，符号<code>e.bar</code>是<code>Foo.bar e</code>的缩写。这为访问函数提供了一种方便的方式，而无需打开名称空间。例如，下面两个表达的意思是相同的：</p>
<pre><code class="language-lean">variable (xs : List Nat)

#check List.length xs
#check xs.length
</code></pre>
<p>给定<code>h : p ∧ q</code>，我们可以写<code>h.left</code>来表示<code>And.left h</code>以及<code>h.right</code>来表示<code>And.right h</code>。因此我们可以简写上面的证明如下：</p>
<pre><code class="language-lean">variable (p q : Prop)
example (h : p ∧ q) : q ∧ p :=
  ⟨h.right, h.left⟩
</code></pre>
<p>在简洁和含混不清之间有一条微妙的界限，以这种方式省略信息有时会使证明更难阅读。但对于像上面这样简单的结构，当<code>h</code>的类型和结构的目标很突出时，符号是干净和有效的。</p>
<p>像<code>And.</code>这样的迭代结构是很常见的。Lean还允许你将嵌套的构造函数向右结合，这样这两个证明是等价的:</p>
<pre><code class="language-lean">variable (p q : Prop)

example (h : p ∧ q) : q ∧ p ∧ q:=
  ⟨h.right, ⟨h.left, h.right⟩⟩

example (h : p ∧ q) : q ∧ p ∧ q:=
  ⟨h.right, h.left, h.right⟩
</code></pre>
<p>这一点也很常用。</p>
<h3><a class="header" href="#析取" id="析取">析取</a></h3>
<p>表达式<code>Or.intro_left q hp</code>从证明<code>hp : p</code>建立了<code>p ∨ q</code>的证明。类似地，<code>Or.intro_right p hq</code>从证明<code>hq : q</code>建立了<code>p ∨ q</code>的证明。这是左右析取引入规则。</p>
<pre><code class="language-lean">variable (p q : Prop)
example (hp : p) : p ∨ q := Or.intro_left q hp
example (hq : q) : p ∨ q := Or.intro_right p hq
</code></pre>
<p>析取消去规则稍微复杂一点。这个想法是，我们可以从<code>p ∨ q</code>证明<code>r</code>，通过从<code>p</code>证明<code>r</code>，且从<code>q</code>证明<code>r</code>。换句话说，它是一种案例证明。在表达式<code>Or.elim hpq hpr hqr</code>中，<code>Or.elim</code>接受三个论证，<code>hpq : p ∨ q</code>，<code>hpr : p → r</code>和<code>hqr : q → r</code>，生成<code>r</code>的证明。在下面的例子中，我们使用<code>Or.elim</code>证明<code>p ∨ q → q ∨ p</code>。</p>
<pre><code class="language-lean">variable (p q r : Prop)

example (h : p ∨ q) : q ∨ p :=
  Or.elim h
    (fun hp : p =&gt;
      show q ∨ p from Or.intro_right q hp)
    (fun hq : q =&gt;
     show q ∨ p from Or.intro_left p hq)
</code></pre>
<p>在大多数情况下，<code>Or.intro_right</code>和<code>Or.intro_left</code>的第一个参数可以由Lean自动推断出来。因此，Lean提供了<code>Or.inr</code>和<code>Or.inl</code>作为<code>Or.intro_right _</code>和<code>Or.intro_left _</code>的缩写。因此，上面的证明项可以写得更简洁:</p>
<pre><code class="language-lean">variable (p q r : Prop)

example (h : p ∨ q) : q ∨ p :=
  Or.elim h (fun hp =&gt; Or.inr hp) (fun hq =&gt; Or.inl hq)
</code></pre>
<p>Lean的完整表达式中有足够的信息来推断<code>hp</code>和<code>hq</code>的类型。但是在较长的版本中使用类型注释可以使证明更具可读性，并有助于捕获和调试错误。</p>
<p>因为<code>Or</code>有两个构造子，所以不能使用匿名构造子表示法。但我们仍然可以写<code>h.elim</code>而不是<code>Or.elim h</code>，不过你需要注意这些缩写是增强还是降低了可读性：</p>
<pre><code class="language-lean">variable (p q r : Prop)

example (h : p ∨ q) : q ∨ p :=
  h.elim (fun hp =&gt; Or.inr hp) (fun hq =&gt; Or.inl hq)
</code></pre>
<h3><a class="header" href="#否定和假言" id="否定和假言">否定和假言</a></h3>
<p>否定<code>¬p</code>真正的定义是<code>p → False</code>，所以我们通过从<code>p</code>导出一个矛盾来获得<code>¬p</code>。类似地，表达式<code>hnp hp</code>从<code>hp : p</code>和<code>hnp : ¬p</code>产生一个<code>False</code>的证明。下一个例子用所有这些规则来证明<code>(p → q) → ¬q → ¬p</code>。（<code>¬</code>符号可以由<code>\not</code>或者<code>\neg</code>来写出。）</p>
<pre><code class="language-lean">variable (p q : Prop)

example (hpq : p → q) (hnq : ¬q) : ¬p :=
  fun hp : p =&gt;
  show False from hnq (hpq hp)
</code></pre>
<p>连接词<code>False</code>只有一个消去规则<code>False.elim</code>，它表达了一个事实，即矛盾能导出一切。这个规则有时被称为<em>ex falso</em> 【<em>ex falso sequitur quodlibet</em>（无稽之谈）的缩写】，或<em>爆炸原理</em>。</p>
<pre><code class="language-lean">variable (tp q : Prop)

example (hp : p) (hnp : ¬p) : q := False.elim (hnp hp)
</code></pre>
<p>假命题导出任意的事实<code>q</code>，是<code>False.elim</code>的一个隐参数，而且是自动推断出来的。这种从相互矛盾的假设中推导出任意事实的模式很常见，用<code>absurd</code>来表示。</p>
<pre><code class="language-lean">variable (p q : Prop)

example (hp : p) (hnp : ¬p) : q := absurd hp hnp
</code></pre>
<p>证明<code>¬p → q → (q → p) → r</code>：</p>
<pre><code class="language-lean">variable (p q r : Prop)

example (hnp : ¬p) (hq : q) (hqp : q → p) : r :=
  absurd (hqp hq) hnp
</code></pre>
<p>顺便说一句，就像<code>False</code>只有一个消去规则，<code>True</code>只有一个引入规则<code>True.intro : true</code>。换句话说，<code>True</code>就是真，并且有一个标准证明<code>True.intro</code>。</p>
<h3><a class="header" href="#逻辑等价" id="逻辑等价">逻辑等价</a></h3>
<p>表达式<code>Iff.intro h1 h2</code>从<code>h1 : p → q</code>和<code>h2 : q → p</code>生成了<code>p ↔ q</code>的证明。表达式<code>Iff.mp h</code>从<code>h : p ↔ q</code>生成了<code>p → q</code>的证明。表达式<code>Iff.mpr h</code>从<code>h : p ↔ q</code>生成了<code>q → p</code>的证明。下面是<code>p ∧ q ↔ q ∧ p</code>的证明：</p>
<pre><code class="language-lean">variable (p q : Prop)

theorem and_swap : p ∧ q ↔ q ∧ p :=
  Iff.intro
    (fun h : p ∧ q =&gt;
     show q ∧ p from And.intro (And.right h) (And.left h))
    (fun h : q ∧ p =&gt;
     show p ∧ q from And.intro (And.right h) (And.left h))

#check and_swap p q    -- p ∧ q ↔ q ∧ p

variable (h : p ∧ q)
example : q ∧ p := Iff.mp (and_swap p q) h
</code></pre>
<p>我们可以用匿名构造子表示法来，从正反两个方向的证明，来构建<code>p ↔ q</code>的证明。我们也可以使用<code>.</code>符号连接<code>mp</code>和<code>mpr</code>。因此，前面的例子可以简写如下：</p>
<pre><code class="language-lean">variable (p q : Prop)

theorem and_swap : p ∧ q ↔ q ∧ p :=
  ⟨ fun h =&gt; ⟨h.right, h.left⟩, fun h =&gt; ⟨h.right, h.left⟩ ⟩

example (h : p ∧ q) : q ∧ p := (and_swap p q).mp h
</code></pre>
<h2><a class="header" href="#引入辅助子目标" id="引入辅助子目标">引入辅助子目标</a></h2>
<p>这里介绍Lean提供的另一种帮助构造长证明的方法，即<code>have</code>结构，它在证明中引入了一个辅助的子目标。下面是一个小例子，改编自上一节:</p>
<pre><code class="language-lean">variable (p q : Prop)

example (h : p ∧ q) : q ∧ p :=
  have hp : p := h.left
  have hq : q := h.right
  show q ∧ p from And.intro hq hp
</code></pre>
<p>在内部，表达式<code>have h : p := s; t</code>产生项<code>(fun (h : p) =&gt; t) s</code>。换句话说，<code>s</code>是<code>p</code>的证明，<code>t</code>是假设<code>h : p</code>的期望结论的证明，并且这两个是由lambda抽象和应用组合在一起的。这个简单的方法在构建长证明时非常有用，因为我们可以使用中间的<code>have</code>作为通向最终目标的垫脚石。</p>
<p>Lean还支持从目标向后推理的结构化方法，它模仿了普通数学文献中“足以说明某某”（suffices to show）的构造。下一个例子简单地排列了前面证明中的最后两行。</p>
<pre><code class="language-lean">variable (p q : Prop)

example (h : p ∧ q) : q ∧ p :=
  have hp : p := h.left
  suffices hq : q from And.intro hq hp
  show q from And.right h
</code></pre>
<p><code>suffices hq : q</code>给出了两条目标。第一，我们需要证明，通过利用附加假设<code>hq : q</code>证明原目标<code>q ∧ p</code>，这样足以证明<code>q</code>，第二，我们需要证明<code>q</code>。</p>
<h2><a class="header" href="#经典逻辑" id="经典逻辑">经典逻辑</a></h2>
<p>到目前为止，我们看到的引入和消去规则都是构造主义的，也就是说，它们反映了基于命题即类型对应的逻辑连接词的计算理解。普通经典逻辑在此基础上加上了排中律<code>p ∨ ¬p</code>（excluded middle, em）。要使用这个原则，你必须打开经典逻辑命名空间。</p>
<pre><code class="language-lean">open Classical

variable (p : Prop)
#check em p
</code></pre>
<p>从直觉上看，构造主义的“或”非常强：断言<code>p ∨ q</code>等于知道哪个是真实情况。如果<code>RH</code>代表黎曼猜想，经典数学家愿意断言<code>RH ∨ ¬RH</code>，即使我们还不能断言析取式的任何一端。</p>
<p>排中律的一个结果是双重否定消去规则（double-negation elimination, dne）:</p>
<pre><code class="language-lean">open Classical

theorem dne {p : Prop} (h : ¬¬p) : p :=
  Or.elim (em p)
    (fun hp : p =&gt; hp)
    (fun hnp : ¬p =&gt; absurd hnp h)
</code></pre>
<p>双重否定消去规则给出了一种证明任何命题<code>p</code>的方法：通过假设<code>¬p</code>来推导出<code>false</code>，相当于证明了<code>p</code>。换句话说，双重否定消除允许反证法，这在构造主义逻辑中通常是不可能的。作为练习，你可以试着证明相反的情况，也就是说，证明<code>em</code>可以由<code>dne</code>证明。</p>
<p>经典公理还可以通过使用<code>em</code>让你获得额外的证明模式。例如，我们可以通过案例进行证明:</p>
<pre><code class="language-lean">open Classical
variable (p : Prop)

example (h : ¬¬p) : p :=
  byCases
    (fun h1 : p =&gt; h1)
    (fun h1 : ¬p =&gt; absurd h1 h)
</code></pre>
<p>或者你可以用反证法来证明：</p>
<pre><code class="language-lean">open Classical
variable (p : Prop)

example (h : ¬¬p) : p :=
  byContradiction
    (fun h1 : ¬p =&gt;
     show False from h h1)
</code></pre>
<p>如果你不习惯构造主义，你可能需要一些时间来了解经典推理在哪里使用。在下面的例子中，它是必要的，因为从一个构造主义的观点来看，知道<code>p</code>和<code>q</code>不同时真并不一定告诉你哪一个是假的：</p>
<pre><code class="language-lean">open Classical
variable (p q : Prop)

-- BEGIN
example (h : ¬(p ∧ q)) : ¬p ∨ ¬q :=
  Or.elim (em p)
    (fun hp : p =&gt;
      Or.inr
        (show ¬q from
          fun hq : q =&gt;
          h ⟨hp, hq⟩))
    (fun hp : ¬p =&gt;
      Or.inl hp)
</code></pre>
<p>稍后我们将看到，构造逻辑中<em>有</em>某些情况允许“排中律”和“双重否定消除律”等，而Lean支持在这种情况下使用经典推理，而不依赖于排中律。</p>
<p>Lean中使用的公理的完整列表见<a href="./axioms_and_computation.html">公理与计算</a>。</p>
<h2><a class="header" href="#逻辑命题的例子" id="逻辑命题的例子">逻辑命题的例子</a></h2>
<hr />
<p>Lean的标准库包含了许多命题逻辑的有效语句的证明，你可以自由地在自己的证明中使用这些证明。下面的列表包括一些常见的逻辑等价式。</p>
<p>交换律：</p>
<ol>
<li><code>p ∧ q ↔ q ∧ p</code></li>
<li><code>p ∨ q ↔ q ∨ p</code></li>
</ol>
<p>结合律：</p>
<ol start="3">
<li><code>(p ∧ q) ∧ r ↔ p ∧ (q ∧ r)</code></li>
<li><code>(p ∨ q) ∨ r ↔ p ∨ (q ∨ r)</code></li>
</ol>
<p>分配律：</p>
<ol start="5">
<li><code>p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r)</code></li>
<li><code>p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r)</code></li>
</ol>
<p>其他性质：</p>
<ol>
<li><code>(p → (q → r)) ↔ (p ∧ q → r)</code></li>
<li><code>((p ∨ q) → r) ↔ (p → r) ∧ (q → r)</code></li>
<li><code>¬(p ∨ q) ↔ ¬p ∧ ¬q</code></li>
<li><code>¬p ∨ ¬q → ¬(p ∧ q)</code></li>
<li><code>¬(p ∧ ¬p)</code></li>
<li><code>p ∧ ¬q → ¬(p → q)</code></li>
<li><code>¬p → (p → q)</code></li>
<li><code>(¬p ∨ q) → (p → q)</code></li>
<li><code>p ∨ False ↔ p</code></li>
<li><code>p ∧ False ↔ False</code></li>
<li><code>¬(p ↔ ¬p)</code></li>
<li><code>(p → q) → (¬q → ¬p)</code></li>
</ol>
<p>经典推理：</p>
<ol start="19">
<li><code>(p → r ∨ s) → ((p → r) ∨ (p → s))</code></li>
<li><code>¬(p ∧ q) → ¬p ∨ ¬q</code></li>
<li><code>¬(p → q) → p ∧ ¬q</code></li>
<li><code>(p → q) → (¬p ∨ q)</code></li>
<li><code>(¬q → ¬p) → (p → q)</code></li>
<li><code>p ∨ ¬p</code></li>
<li><code>(((p → q) → p) → p)</code></li>
</ol>
<p><code>sorry</code>标识符神奇地生成任何东西的证明，或者提供任何数据类型的对象。当然，作为一种证明方法，它是不可靠的——例如，你可以使用它来证明<code>False</code>——并且当文件使用或导入依赖于它的定理时，Lean会产生严重的警告。但它对于增量地构建长证明非常有用。从上到下写证明，用<code>sorry</code>来填子证明。确保Lean接受所有的<code>sorry</code>；如果不是，则有一些错误需要纠正。然后返回，用实际的证据替换每个<code>sorry</code>，直到做完。</p>
<p>有另一个有用的技巧。你可以使用下划线<code>_</code>作为占位符，而不是<code>sorry</code>。回想一下，这告诉Lean该参数是隐式的，应该自动填充。如果Lean尝试这样做并失败了，它将返回一条错误消息“不知道如何合成占位符”（Don't know how to synthesize placeholder），然后是它所期望的项的类型，以及上下文中可用的所有对象和假设。换句话说，对于每个未解决的占位符，Lean报告在那一点上需要填充的子目标。然后，你可以通过递增填充这些占位符来构造一个证明。</p>
<p>这里有两个简单的证明例子作为参考。</p>
<pre><code class="language-lean">open Classical

-- 分配律
example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) :=
  Iff.intro
    (fun h : p ∧ (q ∨ r) =&gt;
      have hp : p := h.left
      Or.elim (h.right)
        (fun hq : q =&gt;
          show (p ∧ q) ∨ (p ∧ r) from Or.inl ⟨hp, hq⟩)
        (fun hr : r =&gt;
          show (p ∧ q) ∨ (p ∧ r) from Or.inr ⟨hp, hr⟩))
    (fun h : (p ∧ q) ∨ (p ∧ r) =&gt;
      Or.elim h
        (fun hpq : p ∧ q =&gt;
          have hp : p := hpq.left
          have hq : q := hpq.right
          show p ∧ (q ∨ r) from ⟨hp, Or.inl hq⟩)
        (fun hpr : p ∧ r =&gt;
          have hp : p := hpr.left
          have hr : r := hpr.right
          show p ∧ (q ∨ r) from ⟨hp, Or.inr hr⟩))

-- 需要一点经典推理的例子
example (p q : Prop) : ¬(p ∧ ¬q) → (p → q) :=
  fun h : ¬(p ∧ ¬q) =&gt;
  fun hp : p =&gt;
  show q from
    Or.elim (em q)
      (fun hq : q =&gt; hq)
      (fun hnq : ¬q =&gt; absurd (And.intro hp hnq) h)
</code></pre>
<h2><a class="header" href="#练习" id="练习">练习</a></h2>
<p>证明以下等式，用真实证明取代“sorry”占位符。</p>
<pre><code class="language-lean">variable (p q r : Prop)

--  ∧ 和 ∨ 的交换律
example : p ∧ q ↔ q ∧ p := sorry
example : p ∨ q ↔ q ∨ p := sorry

-- ∧ 和 ∨ 的结合律
example : (p ∧ q) ∧ r ↔ p ∧ (q ∧ r) := sorry
example : (p ∨ q) ∨ r ↔ p ∨ (q ∨ r) := sorry

-- 分配律
example : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := sorry
example : p ∨ (q ∧ r) ↔ (p ∨ q) ∧ (p ∨ r) := sorry

-- 其他性质
example : (p → (q → r)) ↔ (p ∧ q → r) := sorry
example : ((p ∨ q) → r) ↔ (p → r) ∧ (q → r) := sorry
example : ¬(p ∨ q) ↔ ¬p ∧ ¬q := sorry
example : ¬p ∨ ¬q → ¬(p ∧ q) := sorry
example : ¬(p ∧ ¬p) := sorry
example : p ∧ ¬q → ¬(p → q) := sorry
example : ¬p → (p → q) := sorry
example : (¬p ∨ q) → (p → q) := sorry
example : p ∨ False ↔ p := sorry
example : p ∧ False ↔ False := sorry
example : (p → q) → (¬q → ¬p) := sorry
</code></pre>
<p>证明以下等式，用真实证明取代“sorry”占位符。这里需要一点经典逻辑。</p>
<pre><code class="language-lean">open Classical

variable (p q r s : Prop)

example : (p → r ∨ s) → ((p → r) ∨ (p → s)) := sorry
example : ¬(p ∧ q) → ¬p ∨ ¬q := sorry
example : ¬(p → q) → p ∧ ¬q := sorry
example : (p → q) → (¬p ∨ q) := sorry
example : (¬q → ¬p) → (p → q) := sorry
example : p ∨ ¬p := sorry
example : (((p → q) → p) → p) := sorry
</code></pre>
<p>证明<code>¬(p ↔ ¬p)</code>且不使用经典逻辑。</p>
<h1><a class="header" href="#量词与等价" id="量词与等价">量词与等价</a></h1>
<p>上一章介绍了构造包含命题连接词的证明方法。在本章中，我们扩展逻辑结构，包括全称量词和存在量词，以及等价关系。</p>
<h2><a class="header" href="#全称量词" id="全称量词">全称量词</a></h2>
<p>如果<code>α</code>是任何类型，我们可以将<code>α</code>上的一元谓词<code>p</code>作为<code>α → Prop</code>类型的对象。在这种情况下，给定<code>x : α</code>， <code>p x</code>表示断言<code>p</code>在<code>x</code>上成立。类似地，一个对象<code>r : α → α → Prop</code>表示<code>α</code>上的二元关系：给定<code>x y : α</code>，<code>r x y</code>表示断言<code>x</code>与<code>y</code>相关。</p>
<p>全称量词<code>∀ x : α, p x</code>表示，对于每一个<code>x : α</code>，<code>p x</code>成立。与命题连接词一样，在自然演绎系统中，“forall”有引入和消去规则。非正式地，引入规则是：</p>
<blockquote>
<p>给定<code>p x</code>的证明，在<code>x : α</code>是任意的情况下，我们得到<code>∀ x : α, p x</code>的证明。</p>
</blockquote>
<p>消去规则是：</p>
<blockquote>
<p>给定<code>∀ x : α, p x</code>的证明和任何项<code>t : α</code>，我们得到<code>p t</code>的证明。</p>
</blockquote>
<p>与蕴含的情况一样，命题即类型。回想依赖箭头类型的引入规则:</p>
<blockquote>
<p>给定类型为<code>β x</code>的项<code>t</code>，在<code>x : α</code>是任意的情况下，我们有<code>(fun x : α =&gt; t) : (x : α) → β x</code>。</p>
</blockquote>
<p>消去规则：</p>
<blockquote>
<p>给定项<code>s : (x : α) → β x</code>和任何项<code>t : α</code>，我们有<code>s t : β t</code>。</p>
</blockquote>
<p>在<code>p x</code>具有<code>Prop</code>类型的情况下，如果我们用<code>∀ x : α, p x</code>替换<code>(x : α) → β x</code>，就得到构建涉及全称量词的证明的规则。</p>
<p>因此，构造演算用全称表达式来识别依赖箭头类型。如果<code>p</code>是任何表达式，<code>∀ x : α, p</code>不过是<code>(x : α) → p</code>的替代符号，在<code>p</code>是命题的情况下，前者比后者更自然。通常，表达式<code>p</code>取决于<code>x : α</code>。回想一下，在普通函数空间中，我们可以将<code>α → β</code>解释为<code>(x : α) → β</code>的特殊情况，其中<code>β</code>不依赖于<code>x</code>。类似地，我们可以把命题之间的蕴涵<code>p → q</code>看作是<code>∀ x : p, q</code>的特殊情况，其中<code>q</code>不依赖于<code>x</code>。</p>
<p>下面是一个例子，说明了如何运用命题即类型对应规则。<code>∀</code>可以用<code>\forall</code>输入，也可以用前两个字母简写<code>\fo</code>。</p>
<pre><code class="language-lean">example (α : Type) (p q : α → Prop) : (∀ x : α, p x ∧ q x) → ∀ y : α, p y  :=
  fun h : ∀ x : α, p x ∧ q x =&gt;
  fun y : α =&gt;
  show p y from (h y).left
</code></pre>
<p>作为一种符号约定，我们给予全称量词尽可能最宽的优先级范围，因此上面例子中的假设中，需要用括号将<code>x</code>上的量词限制起来。证明<code>∀ y : α, p y</code>的标准方法是取任意的<code>y</code>，然后证明<code>p y</code>。这是引入规则。现在，给定<code>h</code>有类型<code>∀ x : α, p x ∧ q x</code>，表达式<code>h y</code>有类型<code>p y ∧ q y</code>。这是消去规则。取合取的左侧得到想要的结论<code>p y</code>。</p>
<p>只有约束变量名称不同的表达式被认为是等价的。因此，例如，我们可以在假设和结论中使用相同的变量<code>x</code>，并在证明中用不同的变量<code>z</code>实例化它:</p>
<pre><code class="language-lean">example (α : Type) (p q : α → Prop) : (∀ x : α, p x ∧ q x) → ∀ x : α, p x  :=
  fun h : ∀ x : α, p x ∧ q x =&gt;
  fun z : α =&gt;
  show p z from And.left (h z)
</code></pre>
<p>再举一个例子，下面是关系<code>r</code>的传递性：</p>
<pre><code class="language-lean">variable (α : Type) (r : α → α → Prop)
variable (trans_r : ∀ x y z, r x y → r y z → r x z)

variable (a b c : α)
variable (hab : r a b) (hbc : r b c)

#check trans_r    -- ∀ (x y z : α), r x y → r y z → r x z
#check trans_r a b c
#check trans_r a b c hab
#check trans_r a b c hab hbc
</code></pre>
<p>当我们在值<code>a b c</code>上实例化<code>trans_r</code>时，我们最终得到<code>r a b → r b c → r a c</code>的证明。将此应用于“假设”<code>hab : r a b</code>，我们得到了<code>r b c → r a c</code>的一个证明。最后将它应用到假设<code>hbc</code>中，得到结论<code>r a c</code>的证明。</p>
<pre><code class="language-lean">variable (α : Type) (r : α → α → Prop)
variable (trans_r : ∀ {x y z}, r x y → r y z → r x z)

variable (a b c : α)
variable (hab : r a b) (hbc : r b c)

#check trans_r
#check trans_r hab
#check trans_r hab hbc
</code></pre>
<p>优点是我们可以简单地写<code>trans_r hab hbc</code>作为<code>r a c</code>的证明。一个缺点是Lean没有足够的信息来推断表达式<code>trans_r</code>和<code>trans_r hab</code>中的参数类型。第一个<code>#check</code>命令的输出是<code>r ?m.1 ?m.2 → r ?m.2 ?m.3 → r ?m.1 ?m.3</code>，表示在本例中隐式参数未指定。</p>
<p>下面是一个用等价关系进行基本推理的例子:</p>
<pre><code class="language-lean">variable (α : Type) (r : α → α → Prop)

variable (refl_r : ∀ x, r x x)
variable (symm_r : ∀ {x y}, r x y → r y x)
variable (trans_r : ∀ {x y z}, r x y → r y z → r x z)

example (a b c d : α) (hab : r a b) (hcb : r c b) (hcd : r c d) : r a d :=
  trans_r (trans_r hab (symm_r hcb)) hcd
</code></pre>
<p>为了习惯使用全称量词，你应该尝试本节末尾的一些练习。</p>
<p>依赖箭头类型的类型规则，特别是全称量词，体现了<code>Prop</code>命题类型与其他对象的类型的不同。假设我们有<code>α : Sort i</code>和<code>β : Sort j</code>，其中表达式<code>β</code>可能依赖于变量<code>x : α</code>。那么<code>(x : α) → β</code>是<code>Sort (imax i j)</code>的一个元素，其中<code>imax i j</code>是<code>i</code>和<code>j</code>在<code>j</code>不为0时的最大值，否则为0。</p>
<p>其想法如下。如果<code>j</code>不是<code>0</code>，然后<code>(x : α) → β</code>是<code>Sort (max i j)</code>类型的一个元素。换句话说，从<code>α</code>到<code>β</code>的一类依赖函数存在于指数为<code>i</code>和<code>j</code>最大值的宇宙中。然而，假设<code>β</code>属于<code>Sort 0</code>，即<code>Prop</code>的一个元素。在这种情况下，<code>(x : α) → β</code>也是<code>Sort 0</code>的一个元素，无论<code>α</code>生活在哪种类型的宇宙中。换句话说，如果<code>β</code>是一个依赖于<code>α</code>的命题，那么<code>∀ x : α, β</code>又是一个命题。这反映出<code>Prop</code>作为一种命题类型而不是数据类型，这也使得<code>Prop</code>具有“非直谓性”（impredicative）。</p>
<p>“直谓性”一词起源于20世纪初的数学基础发展，当时逻辑学家如庞加莱和罗素将集合论的悖论归咎于“恶性循环”：当我们通过量化一个集合来定义一个属性时，这个集合包含了被定义的属性。注意，如果<code>α</code>是任何类型，我们可以在<code>α</code>上形成所有谓词的类型<code>α → Prop</code>(<code>α</code>的“幂”类型)。Prop的非直谓性意味着我们可以通过<code>α → Prop</code>形成量化命题。特别是，我们可以通过量化所有关于<code>α</code>的谓词来定义<code>α</code>上的谓词，这正是曾经被认为有问题的循环类型。</p>
<h2><a class="header" href="#等价" id="等价">等价</a></h2>
<p>现在让我们来看看在Lean库中定义的最基本的关系之一，即等价关系。在<a href="inductive_types.html">递归类型</a>一章中，我们将解释如何从Lean的逻辑框架中定义等价。在这里我们解释如何使用它。</p>
<p>等价关系的基本性质：反身性、对称性、传递性。</p>
<pre><code class="language-lean">#check Eq.refl    -- ∀ (a : ?m.1), a = a
#check Eq.symm    -- ?m.2 = ?m.3 → ?m.3 = ?m.2
#check Eq.trans   -- ?m.2 = ?m.3 → ?m.3 = ?m.4 → ?m.2 = ?m.4
</code></pre>
<p>通过告诉Lean不要插入隐参数(在这里显示为元变量)可以使输出更容易阅读。</p>
<pre><code class="language-lean">universe u

#check @Eq.refl.{u}   -- ∀ {α : Sort u} (a : α), a = a
#check @Eq.symm.{u}   -- ∀ {α : Sort u} {a b : α}, a = b → b = a
#check @Eq.trans.{u}  -- ∀ {α : Sort u} {a b c : α}, a = b → b = c → a = c
</code></pre>
<p><code>.{u}</code>告诉Lean实例化宇宙<code>u</code>上的常量。</p>
<p>因此，我们可以将上一节中的示例具体化为等价关系:</p>
<pre><code class="language-lean">variable (α : Type) (a b c d : α)
variable (hab : a = b) (hcb : c = b) (hcd : c = d)

example : a = d :=
  Eq.trans (Eq.trans hab (Eq.symm hcb)) hcd
</code></pre>
<p>我们也可以使用简写：</p>
<pre><code class="language-lean">example : a = d := (hab.trans hcb.symm).trans hcd
</code></pre>
<p>反身性比它看上去更强大。回想一下，在构造演算中，项有一个计算解释，可化简为相同形式的项会被逻辑框架视为相同的。因此，一些非平凡的恒等式可以通过自反性来证明：</p>
<pre><code class="language-lean">variable (α β : Type)

example (f : α → β) (a : α) : (fun x =&gt; f x) a = f a := Eq.refl _
example (a : α) (b : α) : (a, b).1 = a := Eq.refl _
example : 2 + 3 = 5 := Eq.refl _
</code></pre>
<p>框架的这个特性非常重要，以至于库中为<code>Eq.refl _</code>专门定义了一个符号<code>rfl</code>：</p>
<pre><code class="language-lean">variable (α β : Type)
example (f : α → β) (a : α) : (fun x =&gt; f x) a = f a := rfl
example (a : α) (b : α) : (a, b).1 = a := rfl
example : 2 + 3 = 5 := rfl
</code></pre>
<p>然而，等价不仅仅是一种关系。它有一个重要的性质，即每个断言都遵从等价性，即我们可以在不改变真值的情况下对表达式做等价代换。也就是说，给定<code>h1 : a = b</code>和<code>h2 : p a</code>，我们可以构造一个证明<code>p b</code>，只需要使用代换<code>Eq.subst h1 h2</code>。</p>
<pre><code class="language-lean">example (α : Type) (a b : α) (p : α → Prop)
        (h1 : a = b) (h2 : p a) : p b :=
  Eq.subst h1 h2

example (α : Type) (a b : α) (p : α → Prop)
    (h1 : a = b) (h2 : p a) : p b :=
  h1 ▸ h2
</code></pre>
<p>第二个例子中的三角形是建立在<code>Eq.subst</code>和<code>Eq.symm</code>之上的宏，它可以通过<code>\t</code>来输入。</p>
<p>规则<code>Eq.subst</code>定义了一些辅助规则，用来执行更显式的替换。它们是为处理应用型项，即形式为<code>s t</code>的项而设计的。这些辅助规则是，使用<code>congrArg</code>来替换参数，使用<code>congrFun</code>来替换正在应用的项，并且可以同时使用<code>congr</code>来替换两者。</p>
<pre><code class="language-lean">variable (α : Type)
variable (a b : α)
variable (f g : α → Nat)
variable (h₁ : a = b)
variable (h₂ : f = g)

example : f a = f b := congrArg f h₁
example : f a = g a := congrFun h₂ a
example : f a = g b := congr h₂ h₁
</code></pre>
<p>Lean的库包含大量通用的等式，例如：</p>
<pre><code class="language-lean">variable (a b c d : Nat)

example : a + 0 = a := Nat.add_zero a
example : 0 + a = a := Nat.zero_add a
example : a * 1 = a := Nat.mul_one a
example : 1 * a = a := Nat.one_mul a
example : a + b = b + a := Nat.add_comm a b
example : a + b + c = a + (b + c) := Nat.add_assoc a b c
example : a * b = b * a := Nat.mul_comm a b
example : a * b * c = a * (b * c) := Nat.mul_assoc a b c
example : a * (b + c) = a * b + a * c := Nat.mul_add a b c
example : a * (b + c) = a * b + a * c := Nat.left_distrib a b c
example : (a + b) * c = a * c + b * c := Nat.add_mul a b c
example : (a + b) * c = a * c + b * c := Nat.right_distrib a b c
</code></pre>
<p><code>Nat.mul_add</code>和<code>Nat.add_mul</code>是<code>Nat.left_distrib</code>和<code>Nat.right_distrib</code>的代称。上面的属性是为自然数类型<code>Nat</code>声明的。</p>
<p>这是一个使用代换以及结合律、交换律和分配律的自然数计算的例子。</p>
<pre><code class="language-lean">example (x y z : Nat) : x * (y + z) = x * y + x * z := Nat.mul_add x y z
example (x y z : Nat) : (x + y) * z = x * z + y * z := Nat.add_mul x y z
example (x y z : Nat) : x + y + z = x + (y + z) := Nat.add_assoc x y z

example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=
  have h1 : (x + y) * (x + y) = (x + y) * x + (x + y) * y :=
    Nat.mul_add (x + y) x y
  have h2 : (x + y) * (x + y) = x * x + y * x + (x * y + y * y) :=
    (Nat.add_mul x y x) ▸ (Nat.add_mul x y y) ▸ h1
  h2.trans (Nat.add_assoc (x * x + y * x) (x * y) (y * y)).symm
</code></pre>
<p>注意，<code>Eq.subst</code>的第二个隐式参数提供了将要发生代换的表达式上下文，其类型为<code>α → Prop</code>。因此，推断这个谓词需要一个<em>高阶合一</em>（higher-order unification）的实例。一般来说，确定高阶合一器是否存在的问题是无法确定的，而Lean充其量只能提供不完美的和近似的解决方案。因此，<code>Eq.subst</code>并不总是做你想要它做的事。宏<code>h ▸ e</code>使用了更有效的启发式方法来计算这个隐参数，并且在不能应用<code>Eq.subst</code>的情况下通常会成功。</p>
<p>因为等式推理是如此普遍和重要，Lean提供了许多机制来更有效地执行它。下一节将提供允许你以更自然和清晰的方式编写计算式证明的语法。但更重要的是，等式推理是由项重写器、简化器和其他种类的自动化方法支持的。术语重写器和简化器将在下一节中简要描述，然后在下一章中更详细地描述。</p>
<h2><a class="header" href="#计算式证明" id="计算式证明">计算式证明</a></h2>
<p>一个计算式证明是指一串使用诸如等式的传递性等基本规则得到的中间结果。在Lean中，计算式证明从关键字<code>calc</code>开始，语法如下：</p>
<pre><code>calc
  &lt;expr&gt;_0  'op_1'  &lt;expr&gt;_1  ':='  &lt;proof&gt;_1
    '_'     'op_2'  &lt;expr&gt;_2  ':='  &lt;proof&gt;_2
     ...
    '_'     'op_n'  &lt;expr&gt;_n  ':='  &lt;proof&gt;_n

</code></pre>
<p>每个<code>&lt;proof&gt;_i</code>是<code>&lt;expr&gt;_{i-1} op_i &lt;expr&gt;_i</code>的证明。</p>
<p>例子：</p>
<pre><code class="language-lean">variable (a b c d e : Nat)
variable (h1 : a = b)
variable (h2 : b = c + 1)
variable (h3 : c = d)
variable (h4 : e = 1 + d)

theorem T : a = e :=
  calc
    a = b      := h1
    _ = c + 1  := h2
    _ = d + 1  := congrArg Nat.succ h3
    _ = 1 + d  := Nat.add_comm d 1
    _ = e      := Eq.symm h4
</code></pre>
<p>这种写证明的风格在与<code>simp</code>和<code>rewrite</code>策略（tactic）结合使用时最为有效，这些策略将在下一章详细讨论。例如，用缩写`rw'表示重写，上面的证明可以写成如下。</p>
<pre><code class="language-lean">theorem T : a = e :=
  calc
    a = b      := by rw [h1]
    _ = c + 1  := by rw [h2]
    _ = d + 1  := by rw [h3]
    _ = 1 + d  := by rw [Nat.add_comm]
    _ =  e     := by rw [h4]
</code></pre>
<p>本质上，<code>rw</code>策略使用一个给定的等式(它可以是一个假设、一个定理名称或一个复杂的项)来“重写”目标。如果这样做将目标简化为一种等式<code>t = t</code>，那么该策略将使用反身性来证明这一点。</p>
<p>重写可以一次应用一系列，因此上面的证明可以缩写为：</p>
<pre><code class="language-lean">theorem T : a = e :=
  calc
    a = d + 1  := by rw [h1, h2, h3]
    _ = 1 + d  := by rw [Nat.add_comm]
    _ =  e     := by rw [h4]
</code></pre>
<p>甚至这样：</p>
<pre><code class="language-lean">theorem T : a = e :=
  by rw [h1, h2, h3, Nat.add_comm, h4]
</code></pre>
<p>相反，<code>simp</code>策略通过在项中以任意顺序在任何适用的地方重复应用给定的等式来重写目标。它还使用了之前声明给系统的其他规则，并明智地应用交换性以避免循环。因此，我们也可以如下证明定理:</p>
<pre><code class="language-lean">theorem T : a = e :=
  by simp [h1, h2, h3, Nat.add_comm, h4]
</code></pre>
<p>我们将在下一章讨论<code>rw</code>和<code>simp</code>的变体。
We will discuss variations of <code>rw</code> and <code>simp</code> in the next chapter.</p>
<p><code>calc</code>命令可以配置为任何支持某种形式的传递性的关系。它甚至可以结合不同的关系。</p>
<pre><code class="language-lean">example (a b c d : Nat) (h1 : a = b) (h2 : b ≤ c) (h3 : c + 1 &lt; d) : a &lt; d :=
  calc
    a = b     := h1
    _ &lt; b + 1 := Nat.lt_succ_self b
    _ ≤ c + 1 := Nat.succ_le_succ h2
    _ &lt; d     := h3
</code></pre>
<p>使用<code>calc</code>，我们可以以一种更自然、更清晰的方式写出上一节的证明。</p>
<pre><code class="language-lean">example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=
  calc
    (x + y) * (x + y) = (x + y) * x + (x + y) * y  := by rw [Nat.mul_add]
        _ = x * x + y * x + (x + y) * y            := by rw [Nat.add_mul]
        _ = x * x + y * x + (x * y + y * y)        := by rw [Nat.add_mul]
        _ = x * x + y * x + x * y + y * y          := by rw [←Nat.add_assoc]
</code></pre>
<p><code>Nat.add_assoc</code>之前的左箭头指挥重写以相反的方向使用等式。(你可以输入<code>\l</code>或ascii码<code>&lt;-</code>。)如果追求简洁，<code>rw</code>和<code>simp</code>可以一次性完成这项工作:</p>
<pre><code class="language-lean">example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=
  by rw [Nat.mul_add, Nat.add_mul, Nat.add_mul, ←Nat.add_assoc]

example (x y : Nat) : (x + y) * (x + y) = x * x + y * x + x * y + y * y :=
  by simp [Nat.mul_add, Nat.add_mul, Nat.add_assoc, Nat.add_left_comm]
</code></pre>
<h2><a class="header" href="#存在量词" id="存在量词">存在量词</a></h2>
<p>存在量词可以写成<code>exists x : α, p x</code>或<code>∃ x : α, p x</code>。这两个写法实际上在Lean的库中的定义为一个更冗长的表达式，<code>Exists (fun x : α =&gt; p x)</code>。</p>
<p>存在量词也有一个引入规则和一个消去规则。引入规则很简单：要证明<code>∃ x : α, p x</code>，只需提供一个合适的项<code>t</code>和对<code>p t</code>的证明即可。<code>∃</code>用<code>\exists</code>或简写<code>\ex</code>输入，下面是一些例子:</p>
<pre><code class="language-lean">example : ∃ x : Nat, x &gt; 0 :=
  have h : 1 &gt; 0 := Nat.zero_lt_succ 0
  Exists.intro 1 h

example (x : Nat) (h : x &gt; 0) : ∃ y, y &lt; x :=
  Exists.intro 0 h

example (x y z : Nat) (hxy : x &lt; y) (hyz : y &lt; z) : ∃ w, x &lt; w ∧ w &lt; z :=
  Exists.intro y (And.intro hxy hyz)

#check @Exists.intro
</code></pre>
<p>当类型可从上下文中推断时，我们可以使用匿名构造子表示法<code>⟨t, h⟩</code>替换<code>Exists.intro t h</code>。</p>
<pre><code class="language-lean">example : ∃ x : Nat, x &gt; 0 :=
  have h : 1 &gt; 0 := Nat.zero_lt_succ 0
  ⟨1, h⟩

example (x : Nat) (h : x &gt; 0) : ∃ y, y &lt; x :=
  ⟨0, h⟩

example (x y z : Nat) (hxy : x &lt; y) (hyz : y &lt; z) : ∃ w, x &lt; w ∧ w &lt; z :=
  ⟨y, hxy, hyz⟩
</code></pre>
<p>注意<code>Exists.intro</code>有隐参数：Lean必须在结论<code>∃ x, p x</code>中推断谓词<code>p : α → Prop</code>。这不是一件小事。例如，如果我们有<code>hg : g 0 0 = 0</code>和<code>Exists.intro 0 hg</code>，有许多可能的值的谓词<code>p</code>，对应定理<code>∃ x, g x x = x</code>，<code>∃ x, g x x = 0</code>，<code>∃ x, g x 0 = x</code>，等等。Lean使用上下文来推断哪个是合适的。下面的例子说明了这一点，在这个例子中，我们设置了选项<code>pp.explicit</code>为true，要求Lean打印隐参数。</p>
<pre><code class="language-lean">variable (g : Nat → Nat → Nat)
variable (hg : g 0 0 = 0)

theorem gex1 : ∃ x, g x x = x := ⟨0, hg⟩
theorem gex2 : ∃ x, g x 0 = x := ⟨0, hg⟩
theorem gex3 : ∃ x, g 0 0 = x := ⟨0, hg⟩
theorem gex4 : ∃ x, g x x = 0 := ⟨0, hg⟩

set_option pp.explicit true  -- 打印隐参数
#print gex1
#print gex2
#print gex3
#print gex4
</code></pre>
<p>我们可以将<code>Exists.intro</code>视为信息隐藏操作，因为它将断言的具体实例隐藏起来变成了存在量词。存在消去规则<code>Exists.elim</code>执行相反的操作。它允许我们从<code>∃ x : α, p x</code>证明一个命题<code>q</code>，通过证明对于任意值<code>w</code>时<code>p w</code>都能推出<code>q</code>。粗略地说，既然我们知道有一个<code>x</code>满足<code>p x</code>，我们可以给它起个名字，比如<code>w</code>。如果<code>q</code>没有提到<code>w</code>，那么表明<code>p w</code>能推出<code>q</code>就等同于表明<code>q</code>从任何这样的<code>x</code>的存在而推得。下面是一个例子:</p>
<pre><code class="language-lean">variable (α : Type) (p q : α → Prop)

example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
  Exists.elim h
    (fun w =&gt;
     fun hw : p w ∧ q w =&gt;
     show ∃ x, q x ∧ p x from ⟨w, hw.right, hw.left⟩)
</code></pre>
<p>把存在消去规则和析取消去规则作个比较可能会带来一些启发。命题<code>∃ x : α, p x</code>可以看成一个对所有<code>α</code>中的元素<code>a</code>所组成的命题<code>p a</code>的大型析取。注意到匿名构造子<code>⟨w, hw.right, hw.left⟩</code>是嵌套的构造子<code>⟨w, ⟨hw.right, hw.left⟩⟩</code>的缩写。</p>
<p>存在式命题类型很像依赖类型一节所述的sigma类型。给定<code>a : α</code>和<code>h : p a</code>时，项<code>Exists.intro a h</code>具有类型<code>(∃ x : α, p x) : Prop</code>，而<code>Sigma.mk a h</code>具有类型<code>(Σ x : α, p x) : Type</code>。<code>∃</code>和<code>Σ</code>之间的相似性是Curry-Howard同构的另一例子。</p>
<p>Lean提供一个更加方便的消去存在量词的途径，那就是通过<code>match</code>表达式。</p>
<pre><code class="language-lean">variable (α : Type) (p q : α → Prop)

example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
  match h with
  | ⟨w, hw⟩ =&gt; ⟨w, hw.right, hw.left⟩
</code></pre>
<p><code>match</code>表达式是Lean功能定义系统的一部分，它提供了复杂功能的方便且丰富的表达方式。再一次，正是Curry-Howard同构让我们能够采用这种机制来编写证明。<code>match</code>语句将存在断言“析构”到组件<code>w</code>和<code>hw</code>中，然后可以在语句体中使用它们来证明命题。我们可以对match中使用的类型进行注释，以提高清晰度：</p>
<pre><code class="language-lean"><span class="boring">variable (α : Type) (p q : α → Prop)
</span>example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
  match h with
  | ⟨(w : α), (hw : p w ∧ q w)⟩ =&gt; ⟨w, hw.right, hw.left⟩
</code></pre>
<p>我们甚至可以同时使用match语句来分解合取：</p>
<pre><code class="language-lean"><span class="boring">variable (α : Type) (p q : α → Prop)
</span>example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
  match h with
  | ⟨w, hpw, hqw⟩ =&gt; ⟨w, hqw, hpw⟩
</code></pre>
<p>Lean还提供了一个模式匹配的<code>let</code>表达式：</p>
<pre><code class="language-lean"><span class="boring">variable (α : Type) (p q : α → Prop)
</span>example (h : ∃ x, p x ∧ q x) : ∃ x, q x ∧ p x :=
  let ⟨w, hpw, hqw⟩ := h
  ⟨w, hqw, hpw⟩
</code></pre>
<p>这实际上是上面的<code>match</code>结构的替代表示法。Lean甚至允许我们在<code>fun</code>表达式中使用隐含的<code>match</code>：</p>
<pre><code class="language-lean"><span class="boring">variable (α : Type) (p q : α → Prop)
</span>example : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x :=
  fun ⟨w, hpw, hqw⟩ =&gt; ⟨w, hqw, hpw⟩
</code></pre>
<p>我们将在<a href="./induction_and_recursion.html">归纳和递归</a>一章看到所有这些变体都是更一般的模式匹配构造的实例。</p>
<p>在下面的例子中，我们将<code>even a</code>定义为<code>∃ b, a = 2*b</code>，然后我们证明两个偶数的和是偶数。</p>
<pre><code class="language-lean">def is_even (a : Nat) := ∃ b, a = 2 * b

theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
  Exists.elim h1 (fun w1 (hw1 : a = 2 * w1) =&gt;
  Exists.elim h2 (fun w2 (hw2 : b = 2 * w2) =&gt;
    Exists.intro (w1 + w2)
      (calc
        a + b = 2 * w1 + 2 * w2  := by rw [hw1, hw2]
          _   = 2*(w1 + w2)      := by rw [Nat.mul_add])))
</code></pre>
<p>使用本章描述的各种小工具——<code>match</code>语句、匿名构造子和<code>rewrite</code>策略，我们可以简洁地写出如下证明：</p>
<pre><code class="language-lean">def is_even (a : Nat) := ∃ b, a = 2 * b
theorem even_plus_even (h1 : is_even a) (h2 : is_even b) : is_even (a + b) :=
  match h1, h2 with
  | ⟨w1, hw1⟩, ⟨w2, hw2⟩ =&gt; ⟨w1 + w2, by rw [hw1, hw2, Nat.mul_add]⟩
</code></pre>
<p>就像构造主义的“或”比古典的“或”强，同样，构造的“存在”也比古典的“存在”强。例如，下面的推论需要经典推理，因为从构造的角度来看，知道并不是每一个<code>x</code>都满足<code>¬ p</code>，并不等于有一个特定的<code>x</code>满足<code>p</code>。</p>
<pre><code class="language-lean">open Classical
variable (p : α → Prop)

example (h : ¬ ∀ x, ¬ p x) : ∃ x, p x :=
  byContradiction
    (fun h1 : ¬ ∃ x, p x =&gt;
      have h2 : ∀ x, ¬ p x :=
        fun x =&gt;
        fun h3 : p x =&gt;
        have h4 : ∃ x, p x :=  ⟨x, h3⟩
        show False from h1 h4
      show False from h h2)
</code></pre>
<p>下面是一些涉及存在量词的常见等式。在下面的练习中，我们鼓励你尽可能多写出证明。你需要判断哪些是非构造主义的，因此需要一些经典推理。</p>
<pre><code class="language-lean">open Classical

variable (α : Type) (p q : α → Prop)
variable (r : Prop)

example : (∃ x : α, r) → r := sorry
example (a : α) : r → (∃ x : α, r) := sorry
example : (∃ x, p x ∧ r) ↔ (∃ x, p x) ∧ r := sorry
example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) := sorry

example : (∀ x, p x) ↔ ¬ (∃ x, ¬ p x) := sorry
example : (∃ x, p x) ↔ ¬ (∀ x, ¬ p x) := sorry
example : (¬ ∃ x, p x) ↔ (∀ x, ¬ p x) := sorry
example : (¬ ∀ x, p x) ↔ (∃ x, ¬ p x) := sorry

example : (∀ x, p x → r) ↔ (∃ x, p x) → r := sorry
example (a : α) : (∃ x, p x → r) ↔ (∀ x, p x) → r := sorry
example (a : α) : (∃ x, r → p x) ↔ (r → ∃ x, p x) := sorry
</code></pre>
<p>注意，第二个例子和最后两个例子要求假设至少有一个类型为<code>α</code>的元素<code>a</code>。</p>
<p>以下是两个比较困难的问题的解：</p>
<pre><code class="language-lean">open Classical

variable (α : Type) (p q : α → Prop)
variable (a : α)
variable (r : Prop)

example : (∃ x, p x ∨ q x) ↔ (∃ x, p x) ∨ (∃ x, q x) :=
  Iff.intro
    (fun ⟨a, (h1 : p a ∨ q a)⟩ =&gt;
      Or.elim h1
        (fun hpa : p a =&gt; Or.inl ⟨a, hpa⟩)
        (fun hqa : q a =&gt; Or.inr ⟨a, hqa⟩))
    (fun h : (∃ x, p x) ∨ (∃ x, q x) =&gt;
      Or.elim h
        (fun ⟨a, hpa⟩ =&gt; ⟨a, (Or.inl hpa)⟩)
        (fun ⟨a, hqa⟩ =&gt; ⟨a, (Or.inr hqa)⟩))

example : (∃ x, p x → r) ↔ (∀ x, p x) → r :=
  Iff.intro
    (fun ⟨b, (hb : p b → r)⟩ =&gt;
     fun h2 : ∀ x, p x =&gt;
     show r from  hb (h2 b))
    (fun h1 : (∀ x, p x) → r =&gt;
     show ∃ x, p x → r from
       byCases
         (fun hap : ∀ x, p x =&gt; ⟨a, λ h' =&gt; h1 hap⟩)
         (fun hnap : ¬ ∀ x, p x =&gt;
          byContradiction
            (fun hnex : ¬ ∃ x, p x → r =&gt;
              have hap : ∀ x, p x :=
                fun x =&gt;
                byContradiction
                  (fun hnp : ¬ p x =&gt;
                    have hex : ∃ x, p x → r := ⟨x, (fun hp =&gt; absurd hp hnp)⟩
                    show False from hnex hex)
              show False from hnap hap)))
</code></pre>
<h2><a class="header" href="#更多证明语言" id="更多证明语言">更多证明语言</a></h2>
<p>我们已经看到像<code>fun</code>、<code>have</code>和<code>show</code>这样的关键字使得写出反映非正式数学证明结构的正式证明项成为可能。在本节中，我们将讨论证明语言的一些通常很方便的附加特性。</p>
<p>首先，我们可以使用匿名的<code>have</code>表达式来引入一个辅助目标，而不需要标注它。我们可以使用关键字<code>this</code>'来引用最后一个以这种方式引入的表达式:</p>
<pre><code class="language-lean">variable (f : Nat → Nat)
variable (h : ∀ x : Nat, f x ≤ f (x + 1))

example : f 0 ≤ f 3 :=
  have : f 0 ≤ f 1 := h 0
  have : f 0 ≤ f 2 := Nat.le_trans this (h 1)
  show f 0 ≤ f 3 from Nat.le_trans this (h 2)
</code></pre>
<p>通常证明从一个事实转移到另一个事实，所以这可以有效地消除杂乱的大量标签。</p>
<p>当目标可以推断出来时，我们也可以让Lean写<code>by assumption</code>来填写证明：</p>
<pre><code class="language-lean"><span class="boring">variable (f : Nat → Nat)
</span><span class="boring">variable (h : ∀ x : Nat, f x ≤ f (x + 1))
</span>example : f 0 ≤ f 3 :=
  have : f 0 ≤ f 1 := h 0
  have : f 0 ≤ f 2 := Nat.le_trans (by assumption) (h 1)
  show f 0 ≤ f 3 from Nat.le_trans (by assumption) (h 2)
</code></pre>
<p>这告诉Lean使用<code>assumption</code>策略，反过来，通过在局部上下文中找到合适的假设来证明目标。我们将在下一章学习更多关于<code>assumption</code>策略的内容。</p>
<p>我们也可以通过写<code>‹p›</code>的形式要求Lean填写证明，其中<code>p</code>是我们希望Lean在上下文中找到的证明命题。你可以分别使用<code>\f&lt;</code>和<code>\f&gt;</code>输入这些角引号。字母“f”表示“French”，因为unicode符号也可以用作法语引号。事实上，这个符号在Lean中定义如下:</p>
<pre><code class="language-lean">notation &quot;‹&quot; p &quot;›&quot; =&gt; show p by assumption
</code></pre>
<p>这种方法比使用<code>by assumption</code>更稳健，因为需要推断的假设类型是显式给出的。它还使证明更具可读性。这里有一个更详细的例子:</p>
<pre><code class="language-lean">variable (f : Nat → Nat)
variable (h : ∀ x : Nat, f x ≤ f (x + 1))

example : f 0 ≥ f 1 → f 1 ≥ f 2 → f 0 = f 2 :=
  fun _ : f 0 ≥ f 1 =&gt;
  fun _ : f 1 ≥ f 2 =&gt;
  have : f 0 ≥ f 2 := Nat.le_trans ‹f 1 ≥ f 2› ‹f 0 ≥ f 1›
  have : f 0 ≤ f 2 := Nat.le_trans (h 0) (h 1)
  show f 0 = f 2 from Nat.le_antisymm this ‹f 0 ≥ f 2›
</code></pre>
<p>你可以这样使用法语引号来指代上下文中的“任何东西”，而不仅仅是匿名引入的东西。它的使用也不局限于命题，尽管将它用于数据有点奇怪：</p>
<pre><code class="language-lean">example (n : Nat) : Nat := ‹Nat›
</code></pre>
<p>稍后，我们将展示如何使用Lean中的宏系统扩展证明语言。</p>
<h2><a class="header" href="#练习-1" id="练习-1">练习</a></h2>
<ol>
<li>证明以下等式：</li>
</ol>
<pre><code class="language-lean">variable (α : Type) (p q : α → Prop)

example : (∀ x, p x ∧ q x) ↔ (∀ x, p x) ∧ (∀ x, q x) := sorry
example : (∀ x, p x → q x) → (∀ x, p x) → (∀ x, q x) := sorry
example : (∀ x, p x) ∨ (∀ x, q x) → ∀ x, p x ∨ q x := sorry
</code></pre>
<p>你还应该想想为什么在最后一个例子中反过来是不能证明的。</p>
<ol start="2">
<li>当一个公式的组成部分不依赖于被全称的变量时，通常可以把它提取出一个全称量词的范围。尝试证明这些(第二个命题中的一个方向需要经典逻辑)：</li>
</ol>
<pre><code class="language-lean">variable (α : Type) (p q : α → Prop)
variable (r : Prop)

example : α → ((∀ x : α, r) ↔ r) := sorry
example : (∀ x, p x ∨ r) ↔ (∀ x, p x) ∨ r := sorry
example : (∀ x, r → p x) ↔ (r → ∀ x, p x) := sorry
</code></pre>
<ol start="3">
<li>考虑“理发师悖论”：在一个小镇里，这里有一个（男性）理发师给所有不为自己刮胡子的人刮胡子。证明这里存在矛盾：</li>
</ol>
<pre><code class="language-lean">variable (men : Type) (barber : men)
variable  (shaves : men → men → Prop)

example (h : ∀ x : men, shaves barber x ↔ ¬ shaves x x) : false := sorry
</code></pre>
<ol start="4">
<li>如果没有任何参数，类型<code>Prop</code>的表达式只是一个断言。填入下面<code>prime</code>和<code>Fermat_prime</code>的定义，并构造每个给定的断言。例如，通过断言每个自然数<code>n</code>都有一个大于<code>n</code>的质数，你可以说有无限多个质数。哥德巴赫弱猜想指出，每一个大于5的奇数都是三个素数的和。如果有必要，请查阅费马素数的定义或其他任何资料。</li>
</ol>
<pre><code class="language-lean">def even (n : Nat) : Prop := sorry

def prime (n : Nat) : Prop := sorry

def infinitely_many_primes : Prop := sorry

def Fermat_prime (n : Nat) : Prop := sorry

def infinitely_many_Fermat_primes : Prop := sorry

def goldbach_conjecture : Prop := sorry

def Goldbach's_weak_conjecture : Prop := sorry

def Fermat's_last_theorem : Prop := sorry
</code></pre>
<ol start="5">
<li>尽可能多地证明存在量词一节列出的等式。</li>
</ol>
<h1><a class="header" href="#证明策略" id="证明策略">证明策略</a></h1>
<p>在本章中，我们描述了另一种构建证明的方法，即使用<em>策略</em>（tactics）。 一个证明项代表一个数学证明；策略是描述如何建立这样一个证明的命令或指令。你可以在数学证明开始时非正式地说：“为了证明条件的必要性，展开定义，应用前面的定理，并进行简化。”就像这些指令告诉读者如何找到相关的证明一样，策略告诉Lean如何构建一个证明。它们自然而然地支持增量式的证明书写，在这种写作方式中，你将分解一个证明，并一步步地实现目标。</p>
<p>我们将把由策略序列组成的证明描述为“策略式”证明，以便与我们迄今为止所看到的写证明的方式进行对比，我们将其称为“项式”证明。每种风格都有自己的优点和缺点。例如，策略式证明可能更难读，因为它们要求读者预测或猜测每条指令的结果。但它们也可以更短，更容易写。此外，策略提供了一个使用Lean自动化的途径，因为自动化程序本身就是策略。</p>
<h2><a class="header" href="#进入策略模式" id="进入策略模式">进入策略模式</a></h2>
<p>从概念上讲，陈述一个定理或引入一个<code>have</code>的声明会产生一个目标，即构造一个具有预期类型的项的目标。例如, 下面创建的目标是构建一个类型为<code>p ∧ q ∧ p</code>的项，条件有常量<code>p q : Prop</code>，<code>hp : p</code>和<code>hq : q</code>。</p>
<pre><code class="language-lean">theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p :=
  sorry
</code></pre>
<p>写成目标如下：</p>
<pre><code>    p : Prop, q : Prop, hp : p, hq : q ⊢ p ∧ q ∧ p
</code></pre>
<p>事实上，如果你把上面的例子中的&quot;sorry&quot;换成下划线，Lean会报告说，正是这个目标没有得到解决。</p>
<p>通常情况下，你会通过写一个明确的项来满足这样的目标。但在任何需要项的地方，Lean允许我们插入一个<code>by &lt;tactics&gt;</code>块，其中<code>&lt;tactics&gt;</code>是一串命令，用分号或换行符分开。你可以用下面这种方式来证明上面的定理：</p>
<pre><code class="language-lean">theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p :=
  by apply And.intro
     exact hp
     apply And.intro
     exact hq
     exact hp
</code></pre>
<p>我们经常将<code>by</code>关键字放在前一行，并将上面的例子写为</p>
<pre><code class="language-lean">theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p := by
  apply And.intro
  exact hp
  apply And.intro
  exact hq
  exact hp
</code></pre>
<p><code>apply</code>策略应用于一个表达式，被视为表示一个有零或多个参数的函数。它将结论与当前目标中的表达式统一起来，并为剩余的参数创建新的目标，只要后面的参数不依赖于它们。在上面的例子中，命令<code>apply And.intro</code>产生了两个子目标：</p>
<pre><code>    case left
    p : Prop,
    q : Prop,
    hp : p,
    hq : q
    ⊢ p

    case right
    p : Prop,
    q : Prop,
    hp : p,
    hq : q
    ⊢ q ∧ p
</code></pre>
<p>第一个目标是通过<code>exact hp</code>命令来实现的。<code>exact</code>命令只是<code>apply</code>的一个变体，它表示所给的表达式应该准确地填充目标。在策略证明中使用它很有益，因为它如果失败那么表明出了问题。它也比<code>apply</code>更稳健，因为阐示器在处理被应用的表达式时，会考虑到目标所预期的类型。然而，在这种情况下，<code>apply</code>也可以很好地工作。</p>
<p>你可以用<code>#print</code>命令查看所产生的证明项。</p>
<pre><code class="language-lean"><span class="boring">theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p := by
</span><span class="boring"> apply And.intro
</span><span class="boring"> exact hp
</span><span class="boring"> apply And.intro
</span><span class="boring"> exact hq
</span><span class="boring"> exact hp
</span>#print test
</code></pre>
<p>你可以循序渐进地写一个策略脚本。在VS Code中，你可以通过按<code>Ctrl-Shift-Enter</code>打开一个窗口来显示信息，然后只要光标在策略块中，该窗口就会显示当前的目标。在Emacs中，你可以通过按<code>C-c C-g</code>看到任何一行末尾的目标，或者通过把光标放在最后一个策略的第一个字符之后，看到一个不完整的证明中的剩余目标。如果证明是不完整的，标记<code>by</code>会被装饰成一条红色的斜线，错误信息中包含剩余的目标。</p>
<p>策略命令可以接受复合表达式，而不仅仅是单一标识符。下面是前面证明的一个简短版本。</p>
<pre><code class="language-lean">theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p := by
  apply And.intro hp
  exact And.intro hq hp
#print test
</code></pre>
<p>不出意外地，这个也生成出一样的证明。</p>
<p>多个策略应用可以通过用分号连接的方式写在一行中。</p>
<pre><code class="language-lean">theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p := by
  apply And.intro hp; exact And.intro hq hp
</code></pre>
<p>可能产生多个子目标的策略通常对子目标进行标记。例如，<code>apply And.intro</code>策略将第一个目标标记为<code>left</code>，将第二个目标标记为<code>right</code>。在<code>apply</code>策略的情况下，标签是从<code>And.intro</code>声明中使用的参数名称推断出来的。你可以使用符号<code>case &lt;tag&gt; =&gt; &lt;tactics&gt;</code>来结构化你的策略。下面是本章中我们的第一个策略证明的结构化版本。</p>
<pre><code class="language-lean">theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p := by
  apply And.intro
  case left =&gt; exact hp
  case right =&gt;
    apply And.intro
    case left =&gt; exact hq
    case right =&gt; exact hp
</code></pre>
<p>使用<code>case</code>标记，你也可以在<code>left</code>之前先解决子目标<code>right</code>：</p>
<pre><code class="language-lean">theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p := by
  apply And.intro
  case right =&gt;
    apply And.intro
    case left =&gt; exact hq
    case right =&gt; exact hp
  case left =&gt; exact hp
</code></pre>
<p>注意，Lean将其他目标隐藏在<code>case</code>块内。我们说它“专注”于选定的目标。 此外，如果所选目标在<code>case</code>块的末尾没有完全解决，Lean会标记一个错误。</p>
<p>对于简单的子目标，可能不值得使用其标签来选择一个子目标，但你可能仍然想要结构化证明。Lean还提供了“子弹”符号<code>. &lt;tactics&gt;</code>或<code>· &lt;tactics&gt;</code>。</p>
<pre><code class="language-lean">theorem test (p q : Prop) (hp : p) (hq : q) : p ∧ q ∧ p := by
  apply And.intro
  . exact hp
  . apply And.intro
    . exact hq
    . exact hp
</code></pre>
<h2><a class="header" href="#基本策略" id="基本策略">基本策略</a></h2>
<p>除了<code>apply</code>和<code>exact</code>之外，另一个有用的策略是<code>intro</code>，它引入了一个假设。下面是我们在前一章中证明的命题逻辑中的一个等价性的例子，现在用策略来证明。</p>
<pre><code class="language-lean">example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by
  apply Iff.intro
  . intro h
    apply Or.elim (And.right h)
    . intro hq
      apply Or.inl
      apply And.intro
      . exact And.left h
      . exact hq
    . intro hr
      apply Or.inr
      apply And.intro
      . exact And.left h
      . exact hr
  . intro h
    apply Or.elim h
    . intro hpq
      apply And.intro
      . exact And.left hpq
      . apply Or.inl
        exact And.right hpq
    . intro hpr
      apply And.intro
      . exact And.left hpr
      . apply Or.inr
        exact And.right hpr
</code></pre>
<p><code>intro</code>命令可以更普遍地用于引入任何类型的变量。</p>
<pre><code class="language-lean">example (α : Type) : α → α := by
  intro a
  exact a

example (α : Type) : ∀ x : α, x = x := by
  intro x
  exact Eq.refl x
</code></pre>
<p>你可以同时引入好几个变量：</p>
<pre><code class="language-lean">example : ∀ a b c : Nat, a = b → a = c → c = b := by
  intro a b c h₁ h₂
  exact Eq.trans (Eq.symm h₂) h₁
</code></pre>
<p>由于<code>apply</code>策略是一个用于交互式构造函数应用的命令，<code>intro</code>策略是一个用于交互式构造函数抽象的命令（即<code>fun x =&gt; e</code>形式的项）。 与lambda抽象符号一样，<code>intro</code>策略允许我们使用隐式的<code>match</code>。</p>
<pre><code class="language-lean">example (α : Type) (p q : α → Prop) : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x := by
  intro ⟨w, hpw, hqw⟩
  exact ⟨w, hqw, hpw⟩
</code></pre>
<p>就像<code>match</code>表达式一样，你也可以提供多个选项。</p>
<pre><code class="language-lean">example (α : Type) (p q : α → Prop) : (∃ x, p x ∨ q x) → ∃ x, q x ∨ p x := by
  intro
    | ⟨w, Or.inl h⟩ =&gt; exact ⟨w, Or.inr h⟩
    | ⟨w, Or.inr h⟩ =&gt; exact ⟨w, Or.inl h⟩
</code></pre>
<p><code>intros</code>策略可以在没有任何参数的情况下使用，在这种情况下，它选择名字并尽可能多地引入变量。稍后你会看到一个例子。</p>
<p><code>assumption</code>策略在当前目标的背景下查看假设，如果有一个与结论相匹配的假设，它就会应用这个假设。</p>
<pre><code class="language-lean">example (x y z w : Nat) (h₁ : x = y) (h₂ : y = z) (h₃ : z = w) : x = w := by
  apply Eq.trans h₁
  apply Eq.trans h₂
  assumption   -- applied h₃
</code></pre>
<p>若有必要，它会在结论中统一元变量。</p>
<pre><code class="language-lean">example (x y z w : Nat) (h₁ : x = y) (h₂ : y = z) (h₃ : z = w) : x = w := by
  apply Eq.trans
  assumption      -- solves x = ?b with h₁
  apply Eq.trans
  assumption      -- solves y = ?h₂.b with h₂
  assumption      -- solves z = w with h₃
</code></pre>
<p>下面的例子使用<code>intros</code>命令来自动引入三个变量和两个假设：</p>
<pre><code class="language-lean">example : ∀ a b c : Nat, a = b → a = c → c = b := by
  intros
  apply Eq.trans
  apply Eq.symm
  assumption
  assumption
</code></pre>
<p>请注意，由Lean自动生成的名称在默认情况下是不可访问的。其动机是为了确保你的策略证明不依赖于自动生成的名字，并因此而更加强大。然而，你可以使用组合子<code>unhygienic</code>来禁用这一限制。</p>
<pre><code class="language-lean">example : ∀ a b c : Nat, a = b → a = c → c = b := by unhygienic
  intros
  apply Eq.trans
  apply Eq.symm
  exact a_2
  exact a_1
</code></pre>
<p>你也可以使用<code>rename_i</code>策略来重命名你的上下文中最近的不能访问的名字。在下面的例子中，策略<code>rename_i h1 _ h2</code>在你的上下文中重命名了三个假设中的两个。</p>
<pre><code class="language-lean">example : ∀ a b c d : Nat, a = b → a = d → a = c → c = b := by
  intros
  rename_i h1 _ h2
  apply Eq.trans
  apply Eq.symm
  exact h2
  exact h1
</code></pre>
<p><code>rfl</code>策略是<code>exact rfl</code>的语法糖。</p>
<pre><code class="language-lean">example (y : Nat) : (fun x : Nat =&gt; 0) y = 0 :=
  by rfl
</code></pre>
<p><code>repeat</code>组合子可以多次使用一个策略。</p>
<pre><code class="language-lean">example : ∀ a b c : Nat, a = b → a = c → c = b := by
  intros
  apply Eq.trans
  apply Eq.symm
  repeat assumption
</code></pre>
<p>另一个有时很有用的策略是还原<code>revert</code>策略，从某种意义上说，它是对<code>intro</code>的逆。</p>
<pre><code class="language-lean">example (x : Nat) : x = x := by
  revert x
  -- goal is ⊢ ∀ (x : Nat), x = x
  intro y
  -- goal is y : Nat ⊢ y = y
  rfl
</code></pre>
<p>将一个假设还原到目标中会产生一个蕴含。</p>
<pre><code class="language-lean">example (x y : Nat) (h : x = y) : y = x := by
  revert h
  -- goal is x y : Nat ⊢ x = y → y = x
  intro h₁
  -- goal is x y : ℕ, h₁ : x = y ⊢ y = x
  apply Eq.symm
  assumption
</code></pre>
<p>但是<code>revert</code>更聪明，因为它不仅会还原上下文中的一个元素，还会还原上下文中所有依赖它的后续元素。例如，在上面的例子中，还原<code>x</code>会带来<code>h</code>。</p>
<pre><code class="language-lean">example (x y : Nat) (h : x = y) : y = x := by
  revert x
  -- goal is y : Nat ⊢ ∀ (x : Nat), x = y → y = x
  intros
  apply Eq.symm
  assumption
</code></pre>
<p>你还可以一次性还原多个元素：</p>
<pre><code class="language-lean">example (x y : Nat) (h : x = y) : y = x := by
  revert x y
  -- goal is ⊢ ∀ (x y : Nat), x = y → y = x
  intros
  apply Eq.symm
  assumption
</code></pre>
<p>你只能<code>revert</code>局部环境中的一个元素，也就是一个局部变量或假设。但是你可以使用泛化<code>generalize</code>策略将目标中的任意表达式替换为新的变量。</p>
<pre><code class="language-lean">example : 3 = 3 := by
  generalize 3 = x
  -- goal is x : Nat ⊢ x = x,
  revert x
  -- goal is ⊢ ∀ (x : Nat), x = x
  intro y
  -- goal is y : Nat ⊢ y = y
  rfl
</code></pre>
<p>上述符号的记忆法是，你通过将<code>3</code>设定为任意变量<code>x</code>来泛化目标。要注意：不是每一个泛化都能保留目标的有效性。这里，<code>generalize</code>用一个无法证明的目标取代了一个可以用<code>rfl</code>证明的目标。</p>
<pre><code class="language-lean">example : 2 + 3 = 5 := by
  generalize  3 = x
  -- goal is x : Nat ⊢ 2 + x = 5
  admit
</code></pre>
<p>在这个例子中，<code>admit</code>策略是<code>sorry</code>证明项的类似物。它关闭了当前的目标，产生了通常的警告：使用了<code>sorry</code>。为了保持之前目标的有效性，<code>generalize</code>策略允许我们记录<code>3</code>已经被<code>x</code>所取代的事实。你所需要做的就是提供一个标签，<code>generalize</code>使用它来存储局部上下文中的赋值。</p>
<pre><code class="language-lean">example : 2 + 3 = 5 := by
  generalize h : 3 = x
  -- goal is x : Nat, h : 3 = x ⊢ 2 + x = 5
  rw [← h]
</code></pre>
<p>这里<code>rewrite</code>策略，缩写为<code>rw</code>，用<code>h</code>把<code>x</code>用<code>3</code>换了回来。<code>rewrite</code>策略下文将继续讨论。</p>
<h2><a class="header" href="#更多策略" id="更多策略">更多策略</a></h2>
<p>一些额外的策略对于建构和析构命题以及数据很有用。例如，当应用于形式为<code>p ∨ q</code>的目标时，你可以使用<code>apply Or.inl</code>和<code>apply Or.inr</code>等策略。 反之，<code>cases</code>策略可以用来分解一个析取。</p>
<pre><code class="language-lean">example (p q : Prop) : p ∨ q → q ∨ p := by
  intro h
  cases h with
  | inl hp =&gt; apply Or.inr; exact hp
  | inr hq =&gt; apply Or.inl; exact hq
</code></pre>
<p>注意，该语法与<code>match</code>表达式中使用的语法相似。新的子目标可以按任何顺序解决。</p>
<pre><code class="language-lean">example (p q : Prop) : p ∨ q → q ∨ p := by
  intro h
  cases h with
  | inr hq =&gt; apply Or.inl; exact hq
  | inl hp =&gt; apply Or.inr; exact hp
</code></pre>
<p>你也可以使用一个（非结构化的）<code>cases</code>，而不使用<code>with</code>，并为每个备选情况制定一个策略。</p>
<pre><code class="language-lean">example (p q : Prop) : p ∨ q → q ∨ p := by
  intro h
  cases h
  apply Or.inr
  assumption
  apply Or.inl
  assumption
</code></pre>
<p>（非结构化的）<code>cases</code>在你可以用同一个策略来解决子任务时格外有用。</p>
<pre><code class="language-lean">example (p : Prop) : p ∨ p → p := by
  intro h
  cases h
  repeat assumption
</code></pre>
<p>你也可以使用组合子<code>tac1 &lt;;&gt; tac2</code>，将<code>tac2</code>应用于策略<code>tac1</code>产生的每个子目标。</p>
<pre><code class="language-lean">example (p : Prop) : p ∨ p → p := by
  intro h
  cases h &lt;;&gt; assumption
</code></pre>
<p>你可以与<code>.</code>符号相结合使用非结构化的<code>cases</code>策略。</p>
<pre><code class="language-lean">example (p q : Prop) : p ∨ q → q ∨ p := by
  intro h
  cases h
  . apply Or.inr
    assumption
  . apply Or.inl
    assumption

example (p q : Prop) : p ∨ q → q ∨ p := by
  intro h
  cases h
  case inr h =&gt;
    apply Or.inl
    assumption
  case inl h =&gt;
    apply Or.inr
    assumption

example (p q : Prop) : p ∨ q → q ∨ p := by
  intro h
  cases h
  case inr h =&gt;
    apply Or.inl
    assumption
  . apply Or.inr
    assumption
</code></pre>
<p><code>cases</code>策略也被用来分解一个析取。</p>
<pre><code class="language-lean">example (p q : Prop) : p ∧ q → q ∧ p := by
  intro h
  cases h with
  | intro hp hq =&gt; constructor; exact hq; exact hp
</code></pre>
<p>在这个例子中，应用<code>cases</code>策略后只有一个目标，<code>h : p ∧ q</code>被一对假设取代，<code>hp : p</code>和<code>hq : q</code>。<code>constructor</code>策略应用了唯一一个合取构造子<code>And.intro</code>。有了这些策略，上一节的一个例子可以改写如下。</p>
<pre><code class="language-lean">example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by
  apply Iff.intro
  . intro h
    cases h with
    | intro hp hqr =&gt;
      cases hqr
      . apply Or.inl; constructor &lt;;&gt; assumption
      . apply Or.inr; constructor &lt;;&gt; assumption
  . intro h
    cases h with
    | inl hpq =&gt;
      cases hpq with
      | intro hp hq =&gt; constructor; exact hp; apply Or.inl; exact hq
    | inr hpr =&gt;
      cases hpr with
      | intro hp hr =&gt; constructor; exact hp; apply Or.inr; exact hr
</code></pre>
<p>你将在<a href="./inductive_types.html">递归类型</a>一章中看到，这些策略是相当通用的。<code>cases</code>策略可以用来分解递归定义类型的任何元素；<code>constructor</code>总是应用递归定义类型的第一个适用构造子。例如，你可以使用<code>cases</code>和<code>constructor</code>与一个存在量词：</p>
<pre><code class="language-lean">example (p q : Nat → Prop) : (∃ x, p x) → ∃ x, p x ∨ q x := by
  intro h
  cases h with
  | intro x px =&gt; constructor; apply Or.inl; exact px
</code></pre>
<p>在这里，<code>constructor</code>策略将存在性断言的第一个组成部分，即<code>x</code>的值，保留为隐式的。它是由一个元变量表示的，这个元变量以后应该被实例化。在前面的例子中，元变量的正确值是由策略<code>exact px</code>决定的，因为<code>px</code>的类型是<code>p x</code>。如果你想明确指定存在量词的存在者，你可以使用<code>exists</code>策略来代替。</p>
<pre><code class="language-lean">example (p q : Nat → Prop) : (∃ x, p x) → ∃ x, p x ∨ q x := by
  intro h
  cases h with
  | intro x px =&gt; exists x; apply Or.inl; exact px
</code></pre>
<p>另一个例子：</p>
<pre><code class="language-lean">example (p q : Nat → Prop) : (∃ x, p x ∧ q x) → ∃ x, q x ∧ p x := by
  intro h
  cases h with
  | intro x hpq =&gt;
    cases hpq with
    | intro hp hq =&gt;
      exists x
      constructor &lt;;&gt; assumption
</code></pre>
<p>这些策略既可以用在命题上，也可以用在数上。在下面的两个例子中，它们被用来定义交换乘法和加法类型组件的函数：</p>
<pre><code class="language-lean">def swap_pair : α × β → β × α := by
  intro p
  cases p
  constructor &lt;;&gt; assumption
</code></pre>
<pre><code class="language-lean">def swap_sum : Sum α β → Sum β α := by
  intro p
  cases p
  . apply Sum.inr; assumption
  . apply Sum.inl; assumption
</code></pre>
<p>在我们为变量选择的名称之前，它们的定义与有关合取和析取的类似命题的证明是相同的。<code>cases</code>策略也会对自然数进行案例区分：</p>
<p>除了我们为变量选择的名称外，这些定义与合取和析取的类似命题的证明是相同的。<code>cases</code>策略也会在自然数上区分情况：</p>
<pre><code class="language-lean">open Nat
example (P : Nat → Prop) (h₀ : P 0) (h₁ : ∀ n, P (succ n)) (m : Nat) : P m := by
 cases m with
 | zero    =&gt; exact h₀
 | succ m' =&gt; exact h₁ m'
</code></pre>
<p><code>cases</code>策略伙同<code>induction</code>策略将在<a href="./inductive_types.html#_tactics_for_inductive_types">递归类型的策略</a>一节中详述。</p>
<p><code>contradiction</code>策略搜索当前目标的假设中的矛盾：</p>
<pre><code class="language-lean">example (p q : Prop) : p ∧ ¬ p → q := by
  intro h
  cases h
  contradiction
</code></pre>
<p>你也可以在策略块中使用<code>match</code>：</p>
<pre><code class="language-lean">example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by
  apply Iff.intro
  . intro h
    match h with
    | ⟨_, Or.inl _⟩ =&gt; apply Or.inl; constructor &lt;;&gt; assumption
    | ⟨_, Or.inr _⟩ =&gt; apply Or.inr; constructor &lt;;&gt; assumption
  . intro h
    match h with
    | Or.inl ⟨hp, hq⟩ =&gt; constructor; exact hp; apply Or.inl; exact hq
    | Or.inr ⟨hp, hr⟩ =&gt; constructor; exact hp; apply Or.inr; exact hr
</code></pre>
<p>你可以将<code>intro h</code>与<code>match h ...</code>结合起来，然后上例就可以如下地写出：</p>
<pre><code class="language-lean">example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by
  apply Iff.intro
  . intro
     | ⟨hp, Or.inl hq⟩ =&gt; apply Or.inl; constructor &lt;;&gt; assumption
     | ⟨hp, Or.inr hr⟩ =&gt; apply Or.inr; constructor &lt;;&gt; assumption
  . intro
     | Or.inl ⟨hp, hq⟩ =&gt; constructor; assumption; apply Or.inl; assumption
     | Or.inr ⟨hp, hr⟩ =&gt; constructor; assumption; apply Or.inr; assumption

</code></pre>
<h2><a class="header" href="#结构化策略证明" id="结构化策略证明">结构化策略证明</a></h2>
<p>策略通常提供了建立证明的有效方法，但一长串指令会掩盖论证的结构。在这一节中，我们将描述一些有助于为策略式证明提供结构的方法，使这种证明更易读，更稳健。</p>
<p>Lean的证明写作语法的一个优点是，它可以混合项式和策略式证明，并在两者之间自由转换。例如，策略<code>apply</code>和<code>exact</code>可以传入任意的项，你可以用<code>have</code>，<code>show</code>等等来写这些项。反之，当写一个任意的Lean项时，你总是可以通过插入一个<code>by</code>块来调用策略模式。下面是一个简易例子：</p>
<pre><code class="language-lean">example (p q r : Prop) : p ∧ (q ∨ r) → (p ∧ q) ∨ (p ∧ r) := by
  intro h
  exact
    have hp : p := h.left
    have hqr : q ∨ r := h.right
    show (p ∧ q) ∨ (p ∧ r) by
      cases hqr with
      | inl hq =&gt; exact Or.inl ⟨hp, hq⟩
      | inr hr =&gt; exact Or.inr ⟨hp, hr⟩
</code></pre>
<p>更自然一点：</p>
<pre><code class="language-lean">example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by
  apply Iff.intro
  . intro h
    cases h.right with
    | inl hq =&gt; exact Or.inl ⟨h.left, hq⟩
    | inr hr =&gt; exact Or.inr ⟨h.left, hr⟩
  . intro h
    cases h with
    | inl hpq =&gt; exact ⟨hpq.left, Or.inl hpq.right⟩
    | inr hpr =&gt; exact ⟨hpr.left, Or.inr hpr.right⟩
</code></pre>
<p>事实上，有一个<code>show</code>策略，它类似于证明项中的<code>show</code>表达式。它只是简单地声明即将被解决的目标的类型，同时保持策略模式。</p>
<pre><code class="language-lean">example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by
  apply Iff.intro
  . intro h
    cases h.right with
    | inl hq =&gt;
      show (p ∧ q) ∨ (p ∧ r)
      exact Or.inl ⟨h.left, hq⟩
    | inr hr =&gt;
      show (p ∧ q) ∨ (p ∧ r)
      exact Or.inr ⟨h.left, hr⟩
  . intro h
    cases h with
    | inl hpq =&gt;
      show p ∧ (q ∨ r)
      exact ⟨hpq.left, Or.inl hpq.right⟩
    | inr hpr =&gt;
      show p ∧ (q ∨ r)
      exact ⟨hpr.left, Or.inr hpr.right⟩
</code></pre>
<p><code>show</code>策略其实可以被用来重写一些定义等价的目标：</p>
<pre><code class="language-lean">example (n : Nat) : n + 1 = Nat.succ n := by
  show Nat.succ n = Nat.succ n
  rfl
</code></pre>
<p>还有一个<code>have</code>策略，它引入了一个新的子目标，就像写证明项时一样。</p>
<pre><code class="language-lean">example (p q r : Prop) : p ∧ (q ∨ r) → (p ∧ q) ∨ (p ∧ r) := by
  intro ⟨hp, hqr⟩
  show (p ∧ q) ∨ (p ∧ r)
  cases hqr with
  | inl hq =&gt;
    have hpq : p ∧ q := And.intro hp hq
    apply Or.inl
    exact hpq
  | inr hr =&gt;
    have hpr : p ∧ r := And.intro hp hr
    apply Or.inr
    exact hpr
</code></pre>
<p>与证明项一样，你可以省略<code>have</code>策略中的标签，在这种情况下，将使用默认标签<code>this</code>：</p>
<pre><code class="language-lean">example (p q r : Prop) : p ∧ (q ∨ r) → (p ∧ q) ∨ (p ∧ r) := by
  intro ⟨hp, hqr⟩
  show (p ∧ q) ∨ (p ∧ r)
  cases hqr with
  | inl hq =&gt;
    have : p ∧ q := And.intro hp hq
    apply Or.inl
    exact this
  | inr hr =&gt;
    have : p ∧ r := And.intro hp hr
    apply Or.inr
    exact this
</code></pre>
<p><code>have</code>策略中的类型可以省略，所以你可以写<code>have hp := h.left</code>和<code>have hqr := h.right</code>。 事实上，使用这种符号，你甚至可以省略类型和标签，在这种情况下，新的事实是用标签<code>this</code>引入的。</p>
<pre><code class="language-lean">example (p q r : Prop) : p ∧ (q ∨ r) → (p ∧ q) ∨ (p ∧ r) := by
  intro ⟨hp, hqr⟩
  cases hqr with
  | inl hq =&gt;
    have := And.intro hp hq
    apply Or.inl; exact this
  | inr hr =&gt;
    have := And.intro hp hr
    apply Or.inr; exact this
</code></pre>
<p>Lean还有一个<code>let</code>策略，与<code>have</code>策略类似，但用于引入局部定义而不是辅助事实。它是证明项中<code>let</code>的策略版。</p>
<pre><code class="language-lean">example : ∃ x, x + 2 = 8 := by
  let a : Nat := 3 * 2
  exists a
  rfl
</code></pre>
<p>和<code>have</code>一样，你可以通过写<code>let a := 3 * 2</code>来保留类型为隐式。<code>let</code>和<code>have</code>的区别在于，<code>let</code>在上下文中引入了一个局部定义，因此局部声明的定义可以在证明中展开。</p>
<p>我们使用了<code>.</code>来创建嵌套的策略块。 在一个嵌套块中，Lean专注于第一个目标，如果在该块结束时还没有完全解决，就会产生一个错误。这对于表明一个策略所引入的多个子目标的单独证明是有帮助的。符号<code>.</code>是对空格敏感的，并且依靠缩进来检测策略块是否结束。另外，你也可以用大括号和分号来定义策略块。</p>
<pre><code class="language-lean">example (p q r : Prop) : p ∧ (q ∨ r) ↔ (p ∧ q) ∨ (p ∧ r) := by
  apply Iff.intro
  { intro h;
    cases h.right;
    { show (p ∧ q) ∨ (p ∧ r);
      exact Or.inl ⟨h.left, ‹q›⟩ }
    { show (p ∧ q) ∨ (p ∧ r);
      exact Or.inr ⟨h.left, ‹r›⟩ } }
  { intro h;
    cases h;
    { show p ∧ (q ∨ r);
      rename_i hpq;
      exact ⟨hpq.left, Or.inl hpq.right⟩ }
    { show p ∧ (q ∨ r);
      rename_i hpr;
      exact ⟨hpr.left, Or.inr hpr.right⟩ } }
</code></pre>
<p>使用缩进来构造证明很有用：每次一个策略留下一个以上的子目标时，我们通过将它们封装在块中并缩进来分隔剩下的子目标。因此，如果将定理<code>foo</code>应用于一个目标产生了四个子目标，那么我们就可以期待这样的证明：</p>
<pre><code>  apply foo
  . &lt;proof of first goal&gt;
  . &lt;proof of second goal&gt;
  . &lt;proof of third goal&gt;
  . &lt;proof of final goal&gt;
</code></pre>
<p>或</p>
<pre><code>  apply foo
  case &lt;tag of first goal&gt;  =&gt; &lt;proof of first goal&gt;
  case &lt;tag of second goal&gt; =&gt; &lt;proof of second goal&gt;
  case &lt;tag of third goal&gt;  =&gt; &lt;proof of third goal&gt;
  case &lt;tag of final goal&gt;  =&gt; &lt;proof of final goal&gt;
</code></pre>
<p>或</p>
<pre><code>  apply foo
  { &lt;proof of first goal&gt;  }
  { &lt;proof of second goal&gt; }
  { &lt;proof of third goal&gt;  }
  { &lt;proof of final goal&gt;  }
</code></pre>
<h2><a class="header" href="#策略组合子" id="策略组合子">策略组合子</a></h2>
<p><em>策略组合子</em>是由旧策略形成新策略的操作。序列组合子已经隐含在<code>by</code>块中：</p>
<pre><code class="language-lean">example (p q : Prop) (hp : p) : p ∨ q :=
  by apply Or.inl; assumption
</code></pre>
<p>这里，<code>apply Or.inl; assumption</code>在功能上等同于一个单独的策略，它首先应用<code>apply Or.inl</code>，然后应用<code>assumption</code>。</p>
<p>在<code>t₁ &lt;;&gt; t₂</code>中，<code>&lt;;&gt;</code>操作符提供了一个<em>并行</em>的序列操作。<code>t₁</code>被应用于当前目标，然后<code>t₂</code>被应用于<em>所有</em>产生的子目标：</p>
<pre><code class="language-lean">example (p q : Prop) (hp : p) (hq : q) : p ∧ q :=
  by constructor &lt;;&gt; assumption
</code></pre>
<p>当所产生的目标能够以统一的方式完成时，或者，至少，当有可能以统一的方式在所有的目标上取得进展时，这就特别有用。</p>
<p><code>first | t₁ | t₂ | ... | tₙ</code>应用每个<code>tᵢ</code>，直到其中一个成功，否则就失败：</p>
<pre><code class="language-lean">example (p q : Prop) (hp : p) : p ∨ q := by
  first | apply Or.inl; assumption | apply Or.inr; assumption

--译者注：原文看上去少了一个例子，译者据文意补全了。
example (p q : Prop) (hq : q) : p ∨ q := by --(hq : q)条件变化了。
  first | apply Or.inl; assumption | apply Or.inr; assumption
</code></pre>
<p>在第一个例子中，左分支成功了，而在第二个例子中，右分支成功了。在接下来的三个例子中，同样的复合策略在每种情况下都能成功。</p>
<pre><code class="language-lean">example (p q r : Prop) (hp : p) : p ∨ q ∨ r :=
  by repeat (first | apply Or.inl; assumption | apply Or.inr | assumption)

example (p q r : Prop) (hq : q) : p ∨ q ∨ r :=
  by repeat (first | apply Or.inl; assumption | apply Or.inr | assumption)

example (p q r : Prop) (hr : r) : p ∨ q ∨ r :=
  by repeat (first | apply Or.inl; assumption | apply Or.inr | assumption)
</code></pre>
<p>该策略试图通过假设立即解决左边的析取项；如果失败，它就试图关注右边的析取项；如果不成功，它就调用假设策略。</p>
<p>毫无疑问，策略可能会失败。事实上，正是这种“失败”状态导致<em>第一</em>组合子回溯并尝试下一个策略。<code>try</code>组合子建立了一个总是成功的策略，尽管可能是以一种平凡的方式：<code>try t</code>执行<code>t</code>并报告成功，即使<code>t</code>失败。它等同于<code>first | t | skip</code>，其中<code>skip</code>是一个什么都不做的策略（并且成功地做到了）。在下一个例子中，第二个<code>constructor</code>在右边的合取项<code>q ∧ r</code>上成功了（注意，合取和析取是右结合的），但在第一个合取项上失败。<code>try</code>策略保证了序列组合的成功。</p>
<pre><code class="language-lean">example (p q r : Prop) (hp : p) (hq : q) (hr : r) : p ∧ q ∧ r := by
  constructor &lt;;&gt; (try constructor) &lt;;&gt; assumption
</code></pre>
<p>小心：<code>repeat (try t)</code>将永远循环，因为内部策略永远不会失败。</p>
<p>在一个证明中，往往有多个目标未完成。并行序列是一种布置方式，以便将一个策略应用于多个目标，但也有其他的方式可以做到这一点。例如，<code>all_goals t</code>将<code>t</code>应用于所有未完成的目标：</p>
<pre><code class="language-lean">example (p q r : Prop) (hp : p) (hq : q) (hr : r) : p ∧ q ∧ r := by
  constructor
  all_goals (try constructor)
  all_goals assumption
</code></pre>
<p>在这种情况下，<code>any_goals</code>策略提供了一个更稳健的解决方案。它与<code>all_goals</code>类似，只是除非它的参数至少在一个目标上成功，否则就会失败。</p>
<pre><code class="language-lean">example (p q r : Prop) (hp : p) (hq : q) (hr : r) : p ∧ q ∧ r := by
  constructor
  any_goals constructor
  any_goals assumption
</code></pre>
<p>下面<code>by</code>块中的第一个策略是反复拆分合取：</p>
<pre><code class="language-lean">example (p q r : Prop) (hp : p) (hq : q) (hr : r) :
      p ∧ ((p ∧ q) ∧ r) ∧ (q ∧ r ∧ p) := by
  repeat (any_goals constructor)
  all_goals assumption
</code></pre>
<p>其实可以将整个策略压缩成一行：</p>
<pre><code class="language-lean">example (p q r : Prop) (hp : p) (hq : q) (hr : r) :
      p ∧ ((p ∧ q) ∧ r) ∧ (q ∧ r ∧ p) := by
  repeat (any_goals (first | constructor | assumption))
</code></pre>
<p>组合子<code>focus t</code>确保<code>t</code>只影响当前的目标，暂时将其他目标从作用范围中隐藏。因此，如果<code>t</code>通常只影响当前目标，<code>focus (all_goals t)</code>与<code>t</code>具有相同的效果。</p>
<h2><a class="header" href="#重写" id="重写">重写</a></h2>
<p>在<a href="./quantifiers_and_equality.html#%E8%AE%A1%E7%AE%97%E5%BC%8F%E8%AF%81%E6%98%8E">计算式证明</a>一节中简要介绍了<code>rewrite</code>策略（简称<code>rw</code>）和 <code>simp</code>策略。在本节和下一节中，我们将更详细地讨论它们。</p>
<p><code>rewrite</code>策略提供了一种基本的机制，可以将替换应用于目标和假设，在处理等式时非常方便。该策略的最基本形式是<code>rewrite [t]</code>，其中<code>t</code>是一个类型断定为等式的项。例如，<code>t</code>可以是上下文中的一个假设<code>h : x = y</code>；可以是一个一般的法则，如<code>add_comm : ∀ x y, x + y = y + x</code>，在这个法则中，重写策略试图找到<code>x</code>和<code>y</code>的合适实例；或者可以是任何断言具体或一般等式的复合项。在下面的例子中，我们使用这种基本形式，用一个假设重写目标。</p>
<pre><code class="language-lean">example (f : Nat → Nat) (k : Nat) (h₁ : f 0 = 0) (h₂ : k = 0) : f k = 0 := by
  rw [h₂] -- replace k with 0
  rw [h₁] -- replace f 0 with 0
</code></pre>
<p>在上面的例子中，第一次使用<code>rw</code>将目标<code>f k = 0</code>中的<code>k</code>替换成<code>0</code>。然后，第二次用<code>0</code>替换<code>f 0</code>。该策略自动关闭任何形式的目标<code>t = t</code>。下面是一个使用复合表达式进行重写的例子。</p>
<pre><code class="language-lean">example (x y : Nat) (p : Nat → Prop) (q : Prop) (h : q → x = y)
        (h' : p y) (hq : q) : p x := by
  rw [h hq]; assumption
</code></pre>
<p>这里，<code>h hq</code>建立了等式<code>x = y</code>。<code>h hq</code>周围的括号是不必要的，但为了清楚起见，还是加上了括号。</p>
<p>多个重写可以使用符号<code>rw [t_1, ..., t_n]</code>来组合，这只是<code>rw t_1; ...; rw t_n</code>的缩写。前面的例子可以写成如下：</p>
<pre><code class="language-lean">example (f : Nat → Nat) (k : Nat) (h₁ : f 0 = 0) (h₂ : k = 0) : f k = 0 := by
  rw [h₂, h₁]
</code></pre>
<p>默认情况下，<code>rw</code>正向使用一个等式，用一个表达式匹配左边的等式，然后用右边的等式替换它。符号<code>←t</code>可以用来指示策略在反方向上使用等式<code>t</code>。</p>
<pre><code class="language-lean">example (f : Nat → Nat) (a b : Nat) (h₁ : a = b) (h₂ : f a = 0) : f b = 0 := by
  rw [←h₁, h₂]
</code></pre>
<p>在这个例子中，项<code>←h₁</code>指示重写器用<code>a</code>替换<code>b</code>。在编辑器中，你可以用<code>\l</code>输入反箭头。你也可以使用ascii替代品<code>&lt;-</code>。</p>
<p>有时一个等式的左侧可以匹配模式中的多个子项，在这种情况下，<code>rw</code>策略会在遍历项时选择它发现的第一个匹配。如果这不是你想要的，你可以使用附加参数来指定适当的子项。</p>
<pre><code class="language-lean">example (a b c : Nat) : a + b + c = a + c + b := by
  rw [Nat.add_assoc, Nat.add_comm b, ← Nat.add_assoc]

example (a b c : Nat) : a + b + c = a + c + b := by
  rw [Nat.add_assoc, Nat.add_assoc, Nat.add_comm b]

example (a b c : Nat) : a + b + c = a + c + b := by
  rw [Nat.add_assoc, Nat.add_assoc, Nat.add_comm _ b]
</code></pre>
<p>在上面的第一个例子中，第一步将<code>a + b + c</code>重写为<code>a + (b + c)</code>。然后，接下来对项<code>b + c</code>使用交换律；如果不指定参数，该策略将把<code>a + (b + c)</code>重写为<code>(b + c) + a</code>。最后一步以相反的方向应用结合律，将<code>a + (c + b)</code>改写为<code>a + c + b</code>。接下来的两个例子则是应用结合律将两边的小括号移到右边，然后将<code>b</code>和<code>c</code>调换。注意最后一个例子通过指定<code>Nat.add_comm</code>的第二个参数来指定重写应该在右侧进行。</p>
<p>默认情况下，<code>rewrite</code>策略只影响目标。符号<code>rw [t] at h</code>在假设<code>h</code>处应用重写<code>t</code>。</p>
<pre><code class="language-lean">example (f : Nat → Nat) (a : Nat) (h : a + 0 = 0) : f a = f 0 := by
  rw [Nat.add_zero] at h
  rw [h]
</code></pre>
<p>第一步，<code>rw [Nat.add_zero] at h</code>将假设<code>a + 0 = 0</code>改写为<code>a = 0</code>。然后，新的假设<code>a = 0</code>被用来把目标重写为<code>f 0 = f 0</code>。</p>
<p><code>rewrite</code>策略不限于命题。在下面的例子中，我们用<code>rw [h] at t</code>来重写假设<code>t : Tuple α n</code>为<code>t : Tuple α 0</code>。</p>
<pre><code class="language-lean">def Tuple (α : Type) (n : Nat) :=
  { as : List α // as.length = n }

example (n : Nat) (h : n = 0) (t : Tuple α n) : Tuple α 0 := by
  rw [h] at t
  exact t
</code></pre>
<h2><a class="header" href="#简化" id="简化">简化</a></h2>
<p><code>rewrite</code>被设计为操纵目标的手术工具，而简化器提供了一种更强大的自动化形式。Lean库中的一些特性已经被标记为<code>[simp]</code>属性，<code>simp</code>策略使用它们来反复重写表达式中的子项。</p>
<pre><code class="language-lean">example (x y z : Nat) (p : Nat → Prop) (h : p (x * y))
        : (x + 0) * (0 + y * 1 + z * 0) = x * y := by
  simp

example (x y z : Nat) (p : Nat → Prop) (h : p (x * y))
        : p ((x + 0) * (0 + y * 1 + z * 0)) := by
  simp; assumption
</code></pre>
<p>在第一个例子中，目标中等式的左侧被简化，使用涉及0和1的通常的同义词，将目标简化为<code>x * y = x * y'</code>。此时<code>simp'</code>应用反身性（rfl）来完成它。在第二个例子中，<code>simp</code>将目标化简为<code>p (x * y)</code>，这时假设<code>h</code>完成了它。下面是一些关于列表的例子。</p>
<pre><code class="language-lean">open List

example (xs : List Nat)
        : reverse (xs ++ [1, 2, 3]) = [3, 2, 1] ++ reverse xs := by
 simp

example (xs ys : List α)
        : length (reverse (xs ++ ys)) = length xs + length ys := by
 simp [Nat.add_comm]
</code></pre>
<p>就像<code>rw</code>，你也可以用关键字<code>at</code>来简化一个假设：</p>
<pre><code class="language-lean">example (x y z : Nat) (p : Nat → Prop)
        (h : p ((x + 0) * (0 + y * 1 + z * 0))) : p (x * y) := by
  simp at h; assumption
</code></pre>
<p>此外，你可以使用一个“通配符”星号来简化所有的假设和目标：</p>
<pre><code class="language-lean">attribute [local simp] Nat.mul_comm Nat.mul_assoc Nat.mul_left_comm
attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm

example (w x y z : Nat) (p : Nat → Prop)
        (h : p (x * y + z * w  * x)) : p (x * w * z + y * x) := by
  simp at *; assumption

example (x y z : Nat) (p : Nat → Prop)
        (h₁ : p (1 * x + y)) (h₂ : p  (x * z * 1))
        : p (y + 0 + x) ∧ p (z * x) := by
  simp at * &lt;;&gt; constructor &lt;;&gt; assumption
</code></pre>
<p>上例中前两行的意思是，对于具有交换律和结合律的运算（如自然数的加法和乘法），简化器使用这两个定律来重写表达式，同时还使用<em>左交换律</em>。在乘法的情况下，左交换律表达如下：<code>x * (y * z) = y * (x * z)</code>。<code>local</code>修饰符告诉简化器在当前文件（或小节或命名空间，视情况而定）中使用这些规则。交换律和左交换律是有一个问题是，重复应用其中一个会导致循环。但是简化器检测到了对其参数进行置换的特性，并使用了一种被称为<em>有序重写</em>的技术。这意味着系统保持着项的内部次序，只有在这样做会降低次序的情况下才会应用等式。对于上面提到的三个等式，其效果是表达式中的所有小括号都被结合到右边，并且表达式以一种规范的（尽管有些随意）方式排序。两个在交换律和结合律上等价的表达式然后被改写成相同的规范形式。</p>
<pre><code class="language-lean"><span class="boring">attribute [local simp] Nat.mul_comm Nat.mul_assoc Nat.mul_left_comm
</span><span class="boring">attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm
</span>example (w x y z : Nat) (p : Nat → Prop)
        : x * y + z * w  * x = x * w * z + y * x := by
  simp

example (w x y z : Nat) (p : Nat → Prop)
        (h : p (x * y + z * w  * x)) : p (x * w * z + y * x) := by
  simp; simp at h; assumption
</code></pre>
<p>与<code>rewrite</code>一样，你可以向<code>simp</code>提供一个要使用的事实列表，包括一般引理、局部假设、要展开的定义和复合表达式。<code>simp</code>策略也能识别<code>rewrite</code>的<code>←t</code>语法。在任何情况下，额外的规则都会被添加到用于简化项的等式集合中。</p>
<pre><code class="language-lean">def f (m n : Nat) : Nat :=
  m + n + m

example {m n : Nat} (h : n = 1) (h' : 0 = m) : (f m n) = n := by
  simp [h, ←h', f]
</code></pre>
<p>一个常见的习惯是用局部假设来简化一个目标：</p>
<pre><code class="language-lean">example (f : Nat → Nat) (k : Nat) (h₁ : f 0 = 0) (h₂ : k = 0) : f k = 0 := by
  simp [h₁, h₂]
</code></pre>
<p>为了在简化时使用局部环境中存在的所有假设，我们可以使用通配符<code>*</code>：</p>
<pre><code class="language-lean">example (f : Nat → Nat) (k : Nat) (h₁ : f 0 = 0) (h₂ : k = 0) : f k = 0 := by
  simp [*]
</code></pre>
<p>另一例：</p>
<pre><code class="language-lean">example (u w x y z : Nat) (h₁ : x = y + z) (h₂ : w = u + x)
        : w = z + y + u := by
  simp [*, Nat.add_assoc, Nat.add_comm, Nat.add_left_comm]
</code></pre>
<p>简化器也会进行命题重写。例如，使用假设<code>p</code>，它把<code>p ∧ q</code>改写为<code>q</code>，把<code>p ∨ q</code>改写为<code>true</code>，然后以普通方式证明。迭代这样的重写，会生成非平凡的命题推理。</p>
<pre><code class="language-lean">example (p q : Prop) (hp : p) : p ∧ q ↔ q := by
  simp [*]

example (p q : Prop) (hp : p) : p ∨ q := by
  simp [*]

example (p q r : Prop) (hp : p) (hq : q) : p ∧ (q ∨ r) := by
  simp [*]
</code></pre>
<p>下一个例子简化了所有的假设，然后用这些假设来证明目标。</p>
<pre><code class="language-lean">example (u w x x' y y' z : Nat) (p : Nat → Prop)
        (h₁ : x + 0 = x') (h₂ : y + 0 = y')
        : x + y + 0 = x' + y' := by
  simp at *
  simp [*]
</code></pre>
<p>使得简化器特别有用的一点是，它的能力可以随着规则库的发展而增强。例如，假设我们定义了一个列表操作，该操作通过拼接其反转来对称其输入：</p>
<pre><code class="language-lean">def mk_symm (xs : List α) :=
  xs ++ xs.reverse
</code></pre>
<p>那么对于任何列表<code>xs</code>，<code>reverse (mk_symm xs)</code>等于<code>mk_symm xs</code>，这可以通过展开定义轻松证明：</p>
<pre><code class="language-lean">def mk_symm (xs : List α) :=
  xs ++ xs.reverse
theorem reverse_mk_symm (xs : List α)
        : (mk_symm xs).reverse = mk_symm xs := by
  simp [mk_symm]
</code></pre>
<p>你可以使用这个定理来证明一些新结果：</p>
<pre><code class="language-lean">example (xs ys : List Nat)
        : (xs ++ mk_symm ys).reverse = mk_symm ys ++ xs.reverse := by
  simp [reverse_mk_symm]

example (xs ys : List Nat) (p : List Nat → Prop)
        (h : p (xs ++ mk_symm ys).reverse)
        : p (mk_symm ys ++ xs.reverse) := by
  simp [reverse_mk_symm] at h; assumption
</code></pre>
<p>但是使用<code>reverse_mk_symm</code>通常是正确的，如果用户不需要明确地调用它，那就更好了。你可以通过在定义该定理时将其标记为简化规则来实现这一点：</p>
<pre><code class="language-lean"><span class="boring">def mk_symm (xs : List α) :=
</span><span class="boring"> xs ++ xs.reverse
</span>@[simp] theorem reverse_mk_symm (xs : List α)
        : (mk_symm xs).reverse = mk_symm xs := by
  simp [mk_symm]

example (xs ys : List Nat)
        : (xs ++ mk_symm ys).reverse = mk_symm ys ++ xs.reverse := by
  simp

example (xs ys : List Nat) (p : List Nat → Prop)
        (h : p (xs ++ mk_symm ys).reverse)
        : p (mk_symm ys ++ xs.reverse) := by
  simp at h; assumption
</code></pre>
<p>符号<code>@[simp]</code>宣布<code>reverse_mk_symm</code>具有<code>[simp]</code>属性，可以更明确地说明：</p>
<pre><code class="language-lean"><span class="boring">def mk_symm (xs : List α) :=
</span><span class="boring"> xs ++ xs.reverse
</span>theorem reverse_mk_symm (xs : List α)
        : (mk_symm xs).reverse = mk_symm xs := by
  simp [mk_symm]

attribute [simp] reverse_mk_symm

example (xs ys : List Nat)
        : (xs ++ mk_symm ys).reverse = mk_symm ys ++ xs.reverse := by
  simp

example (xs ys : List Nat) (p : List Nat → Prop)
        (h : p (xs ++ mk_symm ys).reverse)
        : p (mk_symm ys ++ xs.reverse) := by
  simp at h; assumption
</code></pre>
<p>该属性也可以在定理声明后的任何时候应用：</p>
<pre><code class="language-lean"><span class="boring">def mk_symm (xs : List α) :=
</span><span class="boring"> xs ++ xs.reverse
</span>theorem reverse_mk_symm (xs : List α)
        : (mk_symm xs).reverse = mk_symm xs := by
  simp [mk_symm]

example (xs ys : List Nat)
        : (xs ++ mk_symm ys).reverse = mk_symm ys ++ xs.reverse := by
  simp[reverse_mk_symm]

attribute [simp] reverse_mk_symm

example (xs ys : List Nat) (p : List Nat → Prop)
        (h : p (xs ++ mk_symm ys).reverse)
        : p (mk_symm ys ++ xs.reverse) := by
  simp at h; assumption
</code></pre>
<p>然而，一旦属性被应用，就没有办法永久地删除它；它将在任何导入该属性的文件中持续存在。正如我们将在[属性]（未完成）一章中进一步讨论的那样，我们可以使用<code>local</code>修饰符将属性的范围限制在当前文件或章节中：</p>
<pre><code class="language-lean"><span class="boring">def mk_symm (xs : List α) :=
</span><span class="boring"> xs ++ xs.reverse
</span>theorem reverse_mk_symm (xs : List α)
        : (mk_symm xs).reverse = mk_symm xs := by
  simp [mk_symm]

section
attribute [local simp] reverse_mk_symm

example (xs ys : List Nat)
        : (xs ++ mk_symm ys).reverse = mk_symm ys ++ xs.reverse := by
  simp

example (xs ys : List Nat) (p : List Nat → Prop)
        (h : p (xs ++ mk_symm ys).reverse)
        : p (mk_symm ys ++ xs.reverse) := by
  simp at h; assumption
end
</code></pre>
<p>在该部分之外，简化器将不再默认使用``reverse_mk_symm`。</p>
<p>请注意，我们讨论过的各种<code>simp</code>选项----给出一个明确的规则列表，并使用<code>at</code>指定位置----可以合并，但它们的排列顺序是严格的。你可以在编辑器中看到正确的顺序，把光标放在<code>simp</code>标识符上，查看与之相关的文档。</p>
<p>有两个额外的修饰符是有用的。默认情况下，<code>simp</code>包括所有被标记为<code>[simp]</code>属性的定理。写<code>simp only</code>排除了这些默认值，允许你使用一个更明确的规则列表。在下面的例子中，减号和<code>only</code>被用来阻止<code>reverse_mk_symm</code>的应用：</p>
<pre><code class="language-lean">def mk_symm (xs : List α) :=
  xs ++ xs.reverse
@[simp] theorem reverse_mk_symm (xs : List α)
        : (mk_symm xs).reverse = mk_symm xs := by
  simp [mk_symm]

example (xs ys : List Nat) (p : List Nat → Prop)
        (h : p (xs ++ mk_symm ys).reverse)
        : p (mk_symm ys ++ xs.reverse) := by
  simp at h; assumption

example (xs ys : List Nat) (p : List Nat → Prop)
        (h : p (xs ++ mk_symm ys).reverse)
        : p ((mk_symm ys).reverse ++ xs.reverse) := by
  simp [-reverse_mk_symm] at h; assumption

example (xs ys : List Nat) (p : List Nat → Prop)
        (h : p (xs ++ mk_symm ys).reverse)
        : p ((mk_symm ys).reverse ++ xs.reverse) := by
  simp only [List.reverse_append] at h; assumption
</code></pre>
<h2><a class="header" href="#扩展策略" id="扩展策略">扩展策略</a></h2>
<p>在下面的例子中，我们使用<code>syntax</code>命令定义符号<code>triv</code>。然后，我们使用<code>macro_rules</code>命令来指定使用<code>triv</code>时应该做什么。你可以提供不同的扩展，策略解释器将尝试所有的扩展，直到有一个成功。</p>
<pre><code class="language-lean">-- 定义一个新策略符号
syntax &quot;triv&quot; : tactic

macro_rules
  | `(tactic| triv) =&gt; `(tactic| assumption)

example (h : p) : p := by
  triv

-- 你不能用`triv`解决下面的定理：
-- example (x : α) : x = x := by
--  triv

-- 扩展`triv`。策略解释器会尝试所有可能的扩展宏，直到有一个成功。
macro_rules
  | `(tactic| triv) =&gt; `(tactic| rfl)

example (x : α) : x = x := by
  triv

example (x : α) (h : p) : x = x ∧ p := by
  apply And.intro &lt;;&gt; triv

-- 加一个递归扩展
macro_rules | `(tactic| triv) =&gt; `(tactic| apply And.intro &lt;;&gt; triv)

example (x : α) (h : p) : x = x ∧ p := by
  triv
</code></pre>
<h2><a class="header" href="#练习-2" id="练习-2">练习</a></h2>
<ol>
<li>
<p>用策略式证明重做<a href="./propositions_and_proofs.html">命题与证明</a>和<a href="./quantifiers_and_equality.html">量词与等价</a>两章的练习。适当使用<code>rw</code>和<code>simp</code>。</p>
</li>
<li>
<p>用策略组合子给下面的例子用一行写一个证明：</p>
</li>
</ol>
<pre><code class="language-lean"> example (p q r : Prop) (hp : p)
         : (p ∨ q ∨ r) ∧ (q ∨ p ∨ r) ∧ (q ∨ r ∨ p) := by
   admit
</code></pre>
<h1><a class="header" href="#interacting-with-lean" id="interacting-with-lean">Interacting with Lean</a></h1>
<p>You are now familiar with the fundamentals of dependent type theory,
both as a language for defining mathematical objects and a language
for constructing proofs. The one thing you are missing is a mechanism
for defining new data types. We will fill this gap in the next
chapter, which introduces the notion of an <em>inductive data type</em>. But
first, in this chapter, we take a break from the mechanics of type
theory to explore some pragmatic aspects of interacting with Lean.</p>
<p>Not all of the information found here will be useful to you right
away. We recommend skimming this section to get a sense of Lean's
features, and then returning to it as necessary.</p>
<h2><a class="header" href="#a-name_importing_filesa-importing-files" id="a-name_importing_filesa-importing-files"><a name="_importing_files"></a> Importing Files</a></h2>
<p>The goal of Lean's front end is to interpret user input, construct
formal expressions, and check that they are well formed and type
correct. Lean also supports the use of various editors, which provide
continuous checking and feedback. More information can be found on the
Lean <a href="http://leanprover.github.io/documentation/">documentation pages</a>.</p>
<p>The definitions and theorems in Lean's standard library are spread
across multiple files. Users may also wish to make use of additional
libraries, or develop their own projects across multiple files. When
Lean starts, it automatically imports the contents of the library
<code>Init</code> folder, which includes a number of fundamental definitions
and constructions. As a result, most of the examples we present here
work &quot;out of the box.&quot;</p>
<p>If you want to use additional files, however, they need to be imported
manually, via an <code>import</code> statement at the beginning of a file. The
command</p>
<pre><code>import Bar.Baz.Blah
</code></pre>
<p>imports the file <code>Bar/Baz/Blah.olean</code>, where the descriptions are
interpreted relative to the Lean <em>search path</em>. Information as to how
the search path is determined can be found on the
<a href="http://leanprover.github.io/documentation/">documentation pages</a>.
By default, it includes the standard library directory, and (in some contexts)
the root of the user's local project. One can also specify imports relative to the current directory; for example,
Importing is transitive. In other words, if you import <code>Foo</code> and <code>Foo</code> imports <code>Bar</code>,
then you also have access to the contents of <code>Bar</code>, and do not need to import it explicitly.</p>
<h2><a class="header" href="#more-on-sections" id="more-on-sections">More on Sections</a></h2>
<p>Lean provides various sectioning mechanisms to help structure a
theory. You saw in <a href="./dependent_type_theory.html#_variables_and_sections">Variables and Sections</a> that the
<code>section</code> command makes it possible not only to group together
elements of a theory that go together, but also to declare variables
that are inserted as arguments to theorems and definitions, as
necessary. Remember that the point of the <code>variable</code> command is to
declare variables for use in theorems, as in the following example:</p>
<pre><code class="language-lean">section
variable (x y : Nat)

def double := x + x

#check double y
#check double (2 * x)

attribute [local simp] Nat.add_assoc Nat.add_comm Nat.add_left_comm

theorem t1 : double (x + y) = double x + double y := by
  simp [double]

#check t1 y
#check t1 (2 * x)

theorem t2 : double (x * y) = double x * y := by
  simp [double, Nat.add_mul]

end
</code></pre>
<p>The definition of <code>double</code> does not have to declare <code>x</code> as an
argument; Lean detects the dependence and inserts it
automatically. Similarly, Lean detects the occurrence of <code>x</code> in
<code>t1</code> and <code>t2</code>, and inserts it automatically there, too.
Note that double does <em>not</em> have <code>y</code> as argument. Variables are only
included in declarations where they are actually used.</p>
<h2><a class="header" href="#more-on-namespaces" id="more-on-namespaces">More on Namespaces</a></h2>
<p>In Lean, identifiers are given by hierarchical <em>names</em> like
<code>Foo.Bar.baz</code>. We saw in <a href="./dependent_type_theory.html#_namespaces">Namespaces</a> that Lean provides
mechanisms for working with hierarchical names. The command
<code>namespace foo</code> causes <code>foo</code> to be prepended to the name of each
definition and theorem until <code>end foo</code> is encountered. The command
<code>open foo</code> then creates temporary <em>aliases</em> to definitions and
theorems that begin with prefix <code>foo</code>.</p>
<pre><code class="language-lean">namespace Foo
def bar : Nat := 1
end Foo

open Foo

#check bar
#check Foo.bar
</code></pre>
<p>The following definition</p>
<pre><code class="language-lean">def Foo.bar : Nat := 1
</code></pre>
<p>is treated as a macro, and expands to</p>
<pre><code class="language-lean">namespace Foo
def bar : Nat := 1
end Foo
</code></pre>
<p>Although the names of theorems and definitions have to be unique, the
aliases that identify them do not. When we open a namespace, an
identifier may be ambiguous. Lean tries to use type information to
disambiguate the meaning in context, but you can always disambiguate
by giving the full name. To that end, the string <code>_root_</code> is an
explicit description of the empty prefix.</p>
<pre><code class="language-lean">def String.add (a b : String) : String :=
  a ++ b

def Bool.add (a b : Bool) : Bool :=
  a != b

def add (α β : Type) : Type := Sum α β

open Bool
open String
-- #check add -- ambiguous
#check String.add           -- String → String → String
#check Bool.add             -- Bool → Bool → Bool
#check _root_.add           -- Type → Type → Type

#check add &quot;hello&quot; &quot;world&quot;  -- String
#check add true false       -- Bool
#check add Nat Nat          -- Type
</code></pre>
<p>We can prevent the shorter alias from being created by using the <code>protected</code> keyword:</p>
<pre><code class="language-lean">protected def Foo.bar : Nat := 1

open Foo

-- #check bar -- error
#check Foo.bar
</code></pre>
<p>This is often used for names like <code>Nat.rec</code> and <code>Nat.recOn</code>, to prevent
overloading of common names.</p>
<p>The <code>open</code> command admits variations. The command</p>
<pre><code class="language-lean">open Nat (succ zero gcd)
#check zero     -- Nat
#eval gcd 15 6  -- 3
</code></pre>
<p>creates aliases for only the identifiers listed. The command</p>
<pre><code class="language-lean">open Nat hiding succ gcd
#check zero     -- Nat
-- #eval gcd 15 6  -- error
#eval Nat.gcd 15 6  -- 3
</code></pre>
<p>creates aliases for everything in the <code>Nat</code> namespace <em>except</em> the identifiers listed.</p>
<pre><code class="language-lean">open Nat renaming mul → times, add → plus
#eval plus (times 2 2) 3  -- 7
</code></pre>
<p>creates aliases renaming <code>Nat.mul</code> to <code>times</code> and <code>Nat.add</code> to <code>plus</code>.</p>
<p>It is sometimes useful to <code>export</code> aliases from one namespace to another, or to the top level. The command</p>
<pre><code class="language-lean">export Nat (succ add sub)
</code></pre>
<p>creates aliases for <code>succ</code>, <code>add</code>, and <code>sub</code> in the current
namespace, so that whenever the namespace is open, these aliases are
available. If this command is used outside a namespace, the aliases
are exported to the top level.</p>
<h2><a class="header" href="#attributes" id="attributes">Attributes</a></h2>
<p>The main function of Lean is to translate user input to formal
expressions that are checked by the kernel for correctness and then
stored in the environment for later use. But some commands have other
effects on the environment, either assigning attributes to objects in
the environment, defining notation, or declaring instances of type
classes, as described in <a href="./type_classes.html">Chapter Type Classes</a>. Most of
these commands have global effects, which is to say, that they remain
in effect not only in the current file, but also in any file that
imports it. However, such commands often support the <code>local</code> modifier,
which indicates that they only have effect until
the current <code>section</code> or <code>namespace</code> is closed, or until the end
of the current file.</p>
<p>In <a href="./tactics.html#_using_the_simp">Section Using the Simplifier</a>,
we saw that theorems can be annotated with the <code>[simp]</code> attribute,
which makes them available for use by the simplifier.
The following example defines the prefix relation on lists,
proves that this relation is reflexive, and assigns the <code>[simp]</code> attribute to that theorem.</p>
<pre><code class="language-lean">def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
  ∃ t, l₁ ++ t = l₂

@[simp] theorem List.isPrefix_self (as : List α) : isPrefix as as :=
  ⟨[], by simp⟩

example : isPrefix [1, 2, 3] [1, 2, 3] := by
  simp
</code></pre>
<p>The simplifier then proves <code>isPrefix [1, 2, 3] [1, 2, 3]</code> by rewriting it to <code>True</code>.</p>
<p>One can also assign the attribute any time after the definition takes place:</p>
<pre><code class="language-lean"><span class="boring">def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
</span><span class="boring"> ∃ t, l₁ ++ t = l₂
</span>theorem List.isPrefix_self (as : List α) : isPrefix as as :=
  ⟨[], by simp⟩

attribute [simp] List.isPrefix_self
</code></pre>
<p>In all these cases, the attribute remains in effect in any file that
imports the one in which the declaration occurs. Adding the <code>local</code>
modifier restricts the scope:</p>
<pre><code class="language-lean"><span class="boring">def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
</span><span class="boring"> ∃ t, l₁ ++ t = l₂
</span>section

theorem List.isPrefix_self (as : List α) : isPrefix as as :=
  ⟨[], by simp⟩

attribute [local simp] List.isPrefix_self

example : isPrefix [1, 2, 3] [1, 2, 3] := by
  simp

end

-- Error:
-- example : isPrefix [1, 2, 3] [1, 2, 3] := by
--  simp
</code></pre>
<p>For another example, we can use the <code>instance</code> command to assign the
notation <code>≤</code> to the <code>isPrefix</code> relation. That command, which will
be explained in <a href="./type_classes.html">Chapter Type Classes</a>, works by
assigning an <code>[instance]</code> attribute to the associated definition.</p>
<pre><code class="language-lean">def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
  ∃ t, l₁ ++ t = l₂

instance : LE (List α) where
  le := isPrefix

theorem List.isPrefix_self (as : List α) : as ≤ as :=
  ⟨[], by simp⟩
</code></pre>
<p>That assignment can also be made local:</p>
<pre><code class="language-lean"><span class="boring">def isPrefix (l₁ : List α) (l₂ : List α) : Prop :=
</span><span class="boring">  ∃ t, l₁ ++ t = l₂
</span>def instLe : LE (List α) :=
  { le := isPrefix }

section
attribute [local instance] instLe

example (as : List α) : as ≤ as :=
  ⟨[], by simp⟩

end

-- Error:
-- example (as : List α) : as ≤ as :=
--  ⟨[], by simp⟩
</code></pre>
<p>In <a href="interacting_with_lean.html#notation">Section Notation</a> below, we will discuss Lean's
mechanisms for defining notation, and see that they also support the
<code>local</code> modifier. However, in <a href="interacting_with_lean.html#setting_options">Section Setting Options</a>, we will
discuss Lean's mechanisms for setting options, which does <em>not</em> follow
this pattern: options can <em>only</em> be set locally, which is to say,
their scope is always restricted to the current section or current
file.</p>
<h2><a class="header" href="#more-on-implicit-arguments" id="more-on-implicit-arguments">More on Implicit Arguments</a></h2>
<p>In <a href="./dependent_type_theory.html#_implicit_args">Section Implicit Arguments</a>,
we saw that if Lean displays the type
of a term <code>t</code> as <code>{x : α} → β x</code>, then the curly brackets
indicate that <code>x</code> has been marked as an <em>implicit argument</em> to
<code>t</code>. This means that whenever you write <code>t</code>, a placeholder, or
&quot;hole,&quot; is inserted, so that <code>t</code> is replaced by <code>@t _</code>. If you
don't want that to happen, you have to write <code>@t</code> instead.</p>
<p>Notice that implicit arguments are inserted eagerly. Suppose we define
a function <code>f (x : Nat) {y : Nat} (z : Nat)</code> with the arguments
shown. Then, when we write the expression <code>f 7</code> without further
arguments, it is parsed as <code>f 7 _</code>. Lean offers a weaker annotation,
<code>{{y : ℕ}}</code>, which specifies that a placeholder should only be added
<em>before</em> a subsequent explicit argument. This annotation can also be
written using as <code>⦃y : Nat⦄</code>, where the unicode brackets are entered
as <code>\{{</code> and <code>\}}</code>, respectively. With this annotation, the
expression <code>f 7</code> would be parsed as is, whereas <code>f 7 3</code> would be
parsed as <code>f 7 _ 3</code>, just as it would be with the strong annotation.</p>
<p>To illustrate the difference, consider the following example, which
shows that a reflexive euclidean relation is both symmetric and
transitive.</p>
<pre><code class="language-lean">def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
  ∀ (a : α), r a a

def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
  ∀ {a b : α}, r a b → r b a

def transitive {α : Type u} (r : α → α → Prop) : Prop :=
  ∀ {a b c : α}, r a b → r b c → r a c

def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
  ∀ {a b c : α}, r a b → r a c → r b c

theorem th1 {α : Type u} {r : α → α → Prop}
            (reflr : reflexive r) (euclr : euclidean r)
            : symmetric r :=
  fun {a b : α} =&gt;
  fun (h : r a b) =&gt;
  show r b a from euclr h (reflr _)

theorem th2 {α : Type u} {r : α → α → Prop}
            (symmr : symmetric r) (euclr : euclidean r)
            : transitive r :=
  fun {a b c : α} =&gt;
  fun (rab : r a b) (rbc : r b c) =&gt;
  euclr (symmr rab) rbc

theorem th3 {α : Type u} {r : α → α → Prop}
            (reflr : reflexive r) (euclr : euclidean r)
            : transitive r :=
 @th2 _ _ (@th1 _ _ reflr @euclr) @euclr

variable (r : α → α → Prop)
variable (euclr : euclidean r)

#check euclr  -- r ?m1 ?m2 → r ?m1 ?m3 → r ?m2 ?m3
</code></pre>
<p>The results are broken down into small steps: <code>th1</code> shows that a
relation that is reflexive and euclidean is symmetric, and <code>th2</code>
shows that a relation that is symmetric and euclidean is
transitive. Then <code>th3</code> combines the two results. But notice that we
have to manually disable the implicit arguments in <code>th1</code>, <code>th2</code>,
and <code>euclr</code>, because otherwise too many implicit arguments are
inserted. The problem goes away if we use weak implicit arguments:</p>
<pre><code class="language-lean">def reflexive {α : Type u} (r : α → α → Prop) : Prop :=
  ∀ (a : α), r a a

def symmetric {α : Type u} (r : α → α → Prop) : Prop :=
  ∀ {{a b : α}}, r a b → r b a

def transitive {α : Type u} (r : α → α → Prop) : Prop :=
  ∀ {{a b c : α}}, r a b → r b c → r a c

def euclidean {α : Type u} (r : α → α → Prop) : Prop :=
  ∀ {{a b c : α}}, r a b → r a c → r b c

theorem th1 {α : Type u} {r : α → α → Prop}
            (reflr : reflexive r) (euclr : euclidean r)
            : symmetric r :=
  fun {a b : α} =&gt;
  fun (h : r a b) =&gt;
  show r b a from euclr h (reflr _)

theorem th2 {α : Type u} {r : α → α → Prop}
            (symmr : symmetric r) (euclr : euclidean r)
            : transitive r :=
  fun {a b c : α} =&gt;
  fun (rab : r a b) (rbc : r b c) =&gt;
  euclr (symmr rab) rbc

theorem th3 {α : Type u} {r : α → α → Prop}
            (reflr : reflexive r) (euclr : euclidean r)
            : transitive r :=
  th2 (th1 reflr euclr) euclr

variable (r : α → α → Prop)
variable (euclr : euclidean r)

#check euclr  -- euclidean r
</code></pre>
<p>There is a third kind of implicit argument that is denoted with square
brackets, <code>[</code> and <code>]</code>. These are used for type classes, as
explained in <a href="./type_classes.html">Chapter Type Classes</a>.</p>
<h2><a class="header" href="#notation" id="notation">Notation</a></h2>
<p>Identifiers in Lean can include any alphanumeric characters, including
Greek characters (other than ∀ , Σ , and λ , which, as we have seen,
have a special meaning in the dependent type theory). They can also
include subscripts, which can be entered by typing <code>\_</code> followed by
the desired subscripted character.</p>
<p>Lean's parser is extensible, which is to say, we can define new notation.</p>
<p>Lean's syntax can be extended and customized by users at every level,
ranging from basic &quot;mixfix&quot; notations to custom elaborators.  In fact,
all builtin syntax is parsed and processed using the same mechanisms
and APIs open to users.  In this section, we will describe and explain
the various extension points.</p>
<p>While introducing new notations is a relatively rare feature in
programming languages and sometimes even frowned upon because of its
potential to obscure code, it is an invaluable tool in formalization
for expressing established conventions and notations of the respective
field succinctly in code.  Going beyond basic notations, Lean's
ability to factor out common boilerplate code into (well-behaved)
macros and to embed entire custom domain specific languages (DSLs) to
textually encode subproblems efficiently and readably can be of great
benefit to both programmers and proof engineers alike.</p>
<h3><a class="header" href="#notations-and-precedence" id="notations-and-precedence">Notations and Precedence</a></h3>
<p>The most basic syntax extension commands allow introducing new (or
overloading existing) prefix, infix, and postfix operators.</p>
<pre><code class="language-lean">infixl:65   &quot; + &quot; =&gt; HAdd.hAdd  -- left-associative
infix:50    &quot; = &quot; =&gt; Eq         -- non-associative
infixr:80   &quot; ^ &quot; =&gt; HPow.hPow  -- right-associative
prefix:100  &quot;-&quot;   =&gt; Neg.neg
<span class="boring">set_option quotPrecheck false
</span>postfix:max &quot;⁻¹&quot;  =&gt; Inv.inv
</code></pre>
<p>After the initial command name describing the operator kind (its
&quot;fixity&quot;), we give the <em>parsing precedence</em> of the operator preceded
by a colon <code>:</code>, then a new or existing token surrounded by double
quotes (the whitespace is used for pretty printing), then the function
this operator should be translated to after the arrow <code>=&gt;</code>.</p>
<p>The precedence is a natural number describing how &quot;tightly&quot; an
operator binds to its arguments, encoding the order of operations.  We
can make this more precise by looking at the commands the above unfold to:</p>
<pre><code class="language-lean">notation:65 lhs:65 &quot; + &quot; rhs:66 =&gt; HAdd.hAdd lhs rhs
notation:50 lhs:51 &quot; = &quot; rhs:51 =&gt; Eq lhs rhs
notation:80 lhs:81 &quot; ^ &quot; rhs:80 =&gt; HPow.hPow lhs rhs
notation:100 &quot;-&quot; arg:100 =&gt; Neg.neg arg
<span class="boring">set_option quotPrecheck false
</span>notation:1024 arg:1024 &quot;⁻¹&quot; =&gt; Inv.inv arg  -- `max` is a shorthand for precedence 1024
</code></pre>
<p>It turns out that all commands from the first code block are in fact
command <em>macros</em> translating to the more general <code>notation</code> command.
We will learn about writing such macros below.  Instead of a single
token, the <code>notation</code> command accepts a mixed sequence of tokens and
named term placeholders with precedences, which can be referenced on
the right-hand side of <code>=&gt;</code> and will be replaced by the respective
term parsed at that position.  A placeholder with precedence <code>p</code>
accepts only notations with precedence at least <code>p</code> in that place.
Thus the string <code>a + b + c</code> cannot be parsed as the equivalent of
<code>a + (b + c)</code> because the right-hand side operand of an <code>infixl</code> notation
has precedence one greater than the notation itself.  In contrast,
<code>infixr</code> reuses the notation's precedence for the right-hand side
operand, so <code>a ^ b ^ c</code> <em>can</em> be parsed as <code>a ^ (b ^ c)</code>.  Note that
if we used <code>notation</code> directly to introduce an infix notation like</p>
<pre><code class="language-lean"><span class="boring">set_option quotPrecheck false
</span>notation:65 lhs:65 &quot; ~ &quot; rhs:65 =&gt; wobble lhs rhs
</code></pre>
<p>where the precedences do not sufficiently determine associativity,
Lean's parser will default to right associativity.  More precisely,
Lean's parser follows a local <em>longest parse</em> rule in the presence of
ambiguous grammars: when parsing the right-hand side of <code>a ~</code> in
<code>a ~ b ~ c</code>, it will continue parsing as long as possible (as the current
precedence allows), not stopping after <code>b</code> but parsing <code>~ c</code> as well.
Thus the term is equivalent to <code>a ~ (b ~ c)</code>.</p>
<p>As mentioned above, the <code>notation</code> command allows us to define
arbitrary <em>mixfix</em> syntax freely mixing tokens and placeholders.</p>
<pre><code class="language-lean"><span class="boring">set_option quotPrecheck false
</span>notation:max &quot;(&quot; e &quot;)&quot; =&gt; e
notation:10 Γ &quot; ⊢ &quot; e &quot; : &quot; τ =&gt; Typing Γ e τ
</code></pre>
<p>Placeholders without precedence default to <code>0</code>, i.e. they accept notations of any precedence in their place.
If two notations overlap, we again apply the longest parse rule:</p>
<pre><code class="language-lean">notation:65 a &quot; + &quot; b:66 &quot; + &quot; c:66 =&gt; a + b - c
#eval 1 + 2 + 3  -- 0
</code></pre>
<p>The new notation is preferred to the binary notation since the latter,
before chaining, would stop parsing after <code>1 + 2</code>.  If there are
multiple notations accepting the same longest parse, the choice will
be delayed until elaboration, which will fail unless exactly one
overload is type correct.</p>
<h2><a class="header" href="#coercions" id="coercions">Coercions</a></h2>
<p>In Lean, the type of natural numbers, <code>Nat</code>, is different from the
type of integers, <code>Int</code>. But there is a function <code>Int.ofNat</code> that
embeds the natural numbers in the integers, meaning that we can view
any natural number as an integer, when needed. Lean has mechanisms to
detect and insert <em>coercions</em> of this sort.</p>
<pre><code class="language-lean">variable (m n : Nat)
variable (i j : Int)

#check i + m      -- i + Int.ofNat m : Int
#check i + m + j  -- i + Int.ofNat m + j : Int
#check i + m + n  -- i + Int.ofNat m + Int.ofNat n : Int
</code></pre>
<h2><a class="header" href="#displaying-information" id="displaying-information">Displaying Information</a></h2>
<p>There are a number of ways in which you can query Lean for information
about its current state and the objects and theorems that are
available in the current context. You have already seen two of the
most common ones, <code>#check</code> and <code>#eval</code>. Remember that <code>#check</code>
is often used in conjunction with the <code>@</code> operator, which makes all
of the arguments to a theorem or definition explicit. In addition, you
can use the <code>#print</code> command to get information about any
identifier. If the identifier denotes a definition or theorem, Lean
prints the type of the symbol, and its definition. If it is a constant
or an axiom, Lean indicates that fact, and shows the type.</p>
<pre><code class="language-lean">-- examples with equality
#check Eq
#check @Eq
#check Eq.symm
#check @Eq.symm

#print Eq.symm

-- examples with And
#check And
#check And.intro
#check @And.intro

-- a user-defined function
def foo {α : Type u} (x : α) : α := x

#check foo
#check @foo
#print foo
</code></pre>
<h2><a class="header" href="#setting-options" id="setting-options">Setting Options</a></h2>
<p>Lean maintains a number of internal variables that can be set by users
to control its behavior. The syntax for doing so is as follows:</p>
<pre><code>set_option &lt;name&gt; &lt;value&gt;
</code></pre>
<p>One very useful family of options controls the way Lean's <em>pretty- printer</em> displays terms. The following options take an input of true or false:</p>
<pre><code>pp.explicit  : display implicit arguments
pp.universes : display hidden universe parameters
pp.notation  : display output using defined notations
</code></pre>
<p>As an example, the following settings yield much longer output:</p>
<pre><code class="language-lean">set_option pp.explicit true
set_option pp.universes true
set_option pp.notation false

#check 2 + 2 = 4
#reduce (fun x =&gt; x + 2) = (fun x =&gt; x + 3)
#check (fun x =&gt; x + 1) 1
</code></pre>
<p>The command <code>set_option pp.all true</code> carries out these settings all
at once, whereas <code>set_option pp.all false</code> reverts to the previous
values. Pretty printing additional information is often very useful
when you are debugging a proof, or trying to understand a cryptic
error message. Too much information can be overwhelming, though, and
Lean's defaults are generally sufficient for ordinary interactions.</p>
<!--
Elaboration Hints
-----------------

When you ask Lean to process an expression like ``λ x y z, f (x + y) z``, you are leaving information implicit. For example, the types of ``x``, ``y``, and ``z`` have to be inferred from the context, the notation ``+`` may be overloaded, and there may be implicit arguments to ``f`` that need to be filled in as well. Moreover, we will see in :numref:`Chapter %s <type_classes>` that some implicit arguments are synthesized by a process known as *type class resolution*. And we have also already seen in the last chapter that some parts of an expression can be constructed by the tactic framework.

Inferring some implicit arguments is straightforward. For example, suppose a function ``f`` has type ``Π {α : Type*}, α → α → α`` and Lean is trying to parse the expression ``f n``, where ``n`` can be inferred to have type ``nat``. Then it is clear that the implicit argument ``α`` has to be ``nat``. However, some inference problems are *higher order*. For example, the substitution operation for equality, ``eq.subst``, has the following type:

.. code-block:: text

    eq.subst : ∀ {α : Sort u} {p : α → Prop} {a b : α},
                 a = b → p a → p b

Now suppose we are given ``a b : ℕ`` and ``h₁ : a = b`` and ``h₂ : a * b > a``. Then, in the expression ``eq.subst h₁ h₂``, ``P`` could be any of the following:

-  ``λ x, x * b > x``
-  ``λ x, x * b > a``
-  ``λ x, a * b > x``
-  ``λ x, a * b > a``

In other words, our intent may be to replace either the first or second ``a`` in ``h₂``, or both, or neither. Similar ambiguities arise in inferring induction predicates, or inferring function arguments. Even second-order unification is known to be undecidable. Lean therefore relies on heuristics to fill in such arguments, and when it fails to guess the right ones, they need to be provided explicitly.

To make matters worse, sometimes definitions need to be unfolded, and sometimes expressions need to be reduced according to the computational rules of the underlying logical framework. Once again, Lean has to rely on heuristics to determine what to unfold or reduce, and when.

There are attributes, however, that can be used to provide hints to the elaborator. One class of attributes determines how eagerly definitions are unfolded: constants can be marked with the attribute ``[reducible]``, ``[semireducible]``, or ``[irreducible]``. Definitions are marked ``[semireducible]`` by default. A definition with the ``[reducible]`` attribute is unfolded eagerly; if you think of a definition as serving as an abbreviation, this attribute would be appropriate. The elaborator avoids unfolding definitions with the ``[irreducible]`` attribute. Theorems are marked ``[irreducible]`` by default, because typically proofs are not relevant to the elaboration process.

It is worth emphasizing that these attributes are only hints to the elaborator. When checking an elaborated term for correctness, Lean's kernel will unfold whatever definitions it needs to unfold. As with other attributes, the ones above can be assigned with the ``local`` modifier, so that they are in effect only in the current section or file.

Lean also has a family of attributes that control the elaboration strategy. A definition or theorem can be marked ``[elab_with_expected_type]``, ``[elab_simple]``. or ``[elab_as_eliminator]``. When applied to a definition ``f``, these bear on elaboration of an expression ``f a b c ...`` in which ``f`` is applied to arguments. With the default attribute, ``[elab_with_expected_type]``, the arguments ``a``, ``b``, ``c``, ... are elaborating using information about their expected type, inferred from ``f`` and the previous arguments. In contrast, with ``[elab_simple]``, the arguments are elaborated from left to right without propagating information about their types. The last attribute, ``[elab_as_eliminator]``, is commonly used for eliminators like recursors, induction principles, and ``eq.subst``. It uses a separate heuristic to infer higher-order parameters. We will consider such operations in more detail in the next chapter.

Once again, these attributes can be assigned and reassigned after an object is defined, and you can use the ``local`` modifier to limit their scope. Moreover, using the ``@`` symbol in front of an identifier in an expression instructs the elaborator to use the ``[elab_simple]`` strategy; the idea is that, when you provide the tricky parameters explicitly, you want the elaborator to weigh that information heavily. In fact, Lean offers an alternative annotation, ``@@``, which leaves parameters before the first higher-order parameter implicit. For example, ``@@eq.subst`` leaves the type of the equation implicit, but makes the context of the substitution explicit.

-->
<h2><a class="header" href="#using-the-library" id="using-the-library">Using the Library</a></h2>
<p>To use Lean effectively you will inevitably need to make use of
definitions and theorems in the library. Recall that the <code>import</code>
command at the beginning of a file imports previously compiled results
from other files, and that importing is transitive; if you import
<code>Foo</code> and <code>Foo</code> imports <code>Bar</code>, then the definitions and theorems
from <code>Bar</code> are available to you as well. But the act of opening a
namespace, which provides shorter names, does not carry over. In each
file, you need to open the namespaces you wish to use.</p>
<p>In general, it is important for you to be familiar with the library
and its contents, so you know what theorems, definitions, notations,
and resources are available to you. Below we will see that Lean's
editor modes can also help you find things you need, but studying the
contents of the library directly is often unavoidable. Lean's standard
library can be found online, on GitHub:</p>
<ul>
<li>
<p><a href="https://github.com/leanprover/lean4/tree/master/src/Init">https://github.com/leanprover/lean4/tree/master/src/Init</a></p>
</li>
<li>
<p><a href="https://github.com/leanprover/lean4/tree/master/src/Std">https://github.com/leanprover/lean4/tree/master/src/Std</a></p>
</li>
</ul>
<p>You can see the contents of these directories and files using GitHub's
browser interface. If you have installed Lean on your own computer,
you can find the library in the <code>lean</code> folder, and explore it with
your file manager. Comment headers at the top of each file provide
additional information.</p>
<p>Lean's library developers follow general naming guidelines to make it
easier to guess the name of a theorem you need, or to find it using
tab completion in editors with a Lean mode that supports this, which
is discussed in the next section. Identifiers are generally
<code>camelCase</code>, and types are <code>CamelCase</code>. For theorem names,
we rely on descriptive names where the different components are separated
by <code>_</code>s. Often the name of theorem simply describes the conclusion:</p>
<pre><code class="language-lean">#check Nat.succ_ne_zero
#check Nat.zero_add
#check Nat.mul_one
#check Nat.le_of_succ_le_succ
</code></pre>
<p>Remember that identifiers in Lean can be organized into hierarchical
namespaces. For example, the theorem named <code>le_of_succ_le_succ</code> in the
namespace <code>Nat</code> has full name <code>Nat.le_of_succ_le_succ</code>, but the shorter
name is made available by the command <code>open Nat</code> (for names not marked as
<code>protected</code>). We will see in <a href="./inductive_types.html">Chapter Inductive Types</a>
and <a href="./structures_and_records.html">Chapter Structures and Records</a>
that defining structures and inductive data types in Lean generates
associated operations, and these are stored in
a namespace with the same name as the type under definition. For
example, the product type comes with the following operations:</p>
<pre><code class="language-lean">#check @Prod.mk
#check @Prod.fst
#check @Prod.snd
#check @Prod.rec
</code></pre>
<p>The first is used to construct a pair, whereas the next two,
<code>Prod.fst</code> and <code>Prod.snd</code>, project the two elements. The last,
<code>Prod.rec</code>, provides another mechanism for defining functions on a
product in terms of a function on the two components. Names like
<code>Prod.rec</code> are <em>protected</em>, which means that one has to use the full
name even when the <code>Prod</code> namespace is open.</p>
<p>With the propositions as types correspondence, logical connectives are
also instances of inductive types, and so we tend to use dot notation
for them as well:</p>
<pre><code class="language-lean">#check @And.intro
#check @And.casesOn
#check @And.left
#check @And.right
#check @Or.inl
#check @Or.inr
#check @Or.elim
#check @Exists.intro
#check @Exists.elim
#check @Eq.refl
#check @Eq.subst
</code></pre>
<h2><a class="header" href="#auto-bound-implicit-arguments" id="auto-bound-implicit-arguments">Auto Bound Implicit Arguments</a></h2>
<p>In the previous section, we have shown how implicit arguments make functions more convenient to use.
However, functions such as <code>compose</code> are still quite verbose to define. Note that the universe
polymorphic <code>compose</code> is even more verbose than the one previously defined.</p>
<pre><code class="language-lean">universe u v w
def compose {α : Type u} {β : Type v} {γ : Type w}
            (g : β → γ) (f : α → β) (x : α) : γ :=
  g (f x)
</code></pre>
<p>You can avoid the <code>universe</code> command by providing the universe parameters when defining <code>compose</code>.</p>
<pre><code class="language-lean">def compose.{u, v, w}
            {α : Type u} {β : Type v} {γ : Type w}
            (g : β → γ) (f : α → β) (x : α) : γ :=
  g (f x)
</code></pre>
<p>Lean 4 supports a new feature called <em>auto bound implicit arguments</em>. It makes functions such as
<code>compose</code> much more convenient to write. When Lean processes the header of a declaration,
any unbound identifier is automatically added as an implicit argument <em>if</em> it is a single lower case or
greek letter. With this feature we can write <code>compose</code> as</p>
<pre><code class="language-lean">def compose (g : β → γ) (f : α → β) (x : α) : γ :=
  g (f x)

#check @compose
-- {β : Sort u_1} → {γ : Sort u_2} → {α : Sort u_3} → (β → γ) → (α → β) → α → γ
</code></pre>
<p>Note that Lean inferred a more general type using <code>Sort</code> instead of <code>Type</code>.</p>
<p>Although we love this feature and use it extensively when implementing Lean,
we realize some users may feel uncomfortable with it. Thus, you can disable it using
the command <code>set_option autoBoundImplicitLocal false</code>.</p>
<pre><code class="language-lean">set_option autoBoundImplicitLocal false
/- The following definition produces `unknown identifier` errors -/
-- def compose (g : β → γ) (f : α → β) (x : α) : γ :=
--   g (f x)
</code></pre>
<h2><a class="header" href="#implicit-lambdas" id="implicit-lambdas">Implicit Lambdas</a></h2>
<p>In Lean 3 stdlib, we find many
<a href="https://github.com/leanprover/lean/blob/master/library/init/category/reader.lean#L39">instances</a> of the dreadful <code>@</code>+<code>_</code> idiom.
It is often used when we the expected type is a function type with implicit arguments,
and we have a constant (<code>reader_t.pure</code> in the example) which also takes implicit arguments. In Lean 4, the elaborator automatically introduces lambdas
for consuming implicit arguments. We are still exploring this feature and analyzing its impact, but the experience so far has been very positive. Here is the example from the link above using Lean 4 implicit lambdas.</p>
<pre><code class="language-lean"><span class="boring">variable (ρ : Type) (m : Type → Type) [Monad m]
</span>instance : Monad (ReaderT ρ m) where
  pure := ReaderT.pure
  bind := ReaderT.bind
</code></pre>
<p>Users can disable the implicit lambda feature by using <code>@</code> or writing
a lambda expression with <code>{}</code> or <code>[]</code> binder annotations.  Here are
few examples</p>
<pre><code class="language-lean"><span class="boring">namespace ex2
</span>def id1 : {α : Type} → α → α :=
  fun x =&gt; x

def listId : List ({α : Type} → α → α) :=
  (fun x =&gt; x) :: []

-- In this example, implicit lambda introduction has been disabled because
-- we use `@` before `fun`
def id2 : {α : Type} → α → α :=
  @fun α (x : α) =&gt; id1 x

def id3 : {α : Type} → α → α :=
  @fun α x =&gt; id1 x

def id4 : {α : Type} → α → α :=
  fun x =&gt; id1 x

-- In this example, implicit lambda introduction has been disabled
-- because we used the binder annotation `{...}`
def id5 : {α : Type} → α → α :=
  fun {α} x =&gt; id1 x
<span class="boring">end ex2
</span></code></pre>
<h2><a class="header" href="#sugar-for-simple-functions" id="sugar-for-simple-functions">Sugar for Simple Functions</a></h2>
<p>In Lean 3, we can create simple functions from infix operators by
using parentheses. For example, <code>(+1)</code> is sugar for <code>fun x, x + 1</code>. In
Lean 4, we generalize this notation using <code>·</code> As a placeholder. Here
are a few examples:</p>
<pre><code class="language-lean"><span class="boring">namespace ex3
</span>#check (· + 1)
-- fun a =&gt; a + 1
#check (2 - ·)
-- fun a =&gt; 2 - a
#eval [1, 2, 3, 4, 5].foldl (·*·) 1
-- 120

def f (x y z : Nat) :=
  x + y + z

#check (f · 1 ·)
-- fun a b =&gt; f a 1 b

#eval [(1, 2), (3, 4), (5, 6)].map (·.1)
-- [1, 3, 5]
<span class="boring">end ex3
</span></code></pre>
<p>As in Lean 3, the notation is activated using parentheses, and the lambda abstraction is created by collecting the nested <code>·</code>s.
The collection is interrupted by nested parentheses. In the following example, two different lambda expressions are created.</p>
<pre><code class="language-lean">#check (Prod.mk · (· + 1))
-- fun a =&gt; (a, fun b =&gt; b + 1)
</code></pre>
<h2><a class="header" href="#named-arguments" id="named-arguments">Named Arguments</a></h2>
<p>Named arguments enable you to specify an argument for a parameter by
matching the argument with its name rather than with its position in
the parameter list.  If you don't remember the order of the parameters
but know their names, you can send the arguments in any order. You may
also provide the value for an implicit parameter when Lean failed to
infer it. Named arguments also improve the readability of your code by
identifying what each argument represents.</p>
<pre><code class="language-lean">def sum (xs : List Nat) :=
  xs.foldl (init := 0) (·+·)

#eval sum [1, 2, 3, 4]
-- 10

example {a b : Nat} {p : Nat → Nat → Nat → Prop} (h₁ : p a b b) (h₂ : b = a)
    : p a a b :=
  Eq.subst (motive := fun x =&gt; p a x b) h₂ h₁
</code></pre>
<p>In the following examples, we illustrate the interaction between named
and default arguments.</p>
<pre><code class="language-lean">def f (x : Nat) (y : Nat := 1) (w : Nat := 2) (z : Nat) :=
  x + y + w - z

example (x z : Nat) : f (z := z) x = x + 1 + 2 - z := rfl

example (x z : Nat) : f x (z := z) = x + 1 + 2 - z := rfl

example (x y : Nat) : f x y = fun z =&gt; x + y + 2 - z := rfl

example : f = (fun x z =&gt; x + 1 + 2 - z) := rfl

example (x : Nat) : f x = fun z =&gt; x + 1 + 2 - z := rfl

example (y : Nat) : f (y := 5) = fun x z =&gt; x + 5 + 2 - z := rfl

def g {α} [Add α] (a : α) (b? : Option α := none) (c : α) : α :=
  match b? with
  | none   =&gt; a + c
  | some b =&gt; a + b + c

variable {α} [Add α]

example : g = fun (a c : α) =&gt; a + c := rfl

example (x : α) : g (c := x) = fun (a : α) =&gt; a + x := rfl

example (x : α) : g (b? := some x) = fun (a c : α) =&gt; a + x + c := rfl

example (x : α) : g x = fun (c : α) =&gt; x + c := rfl

example (x y : α) : g x y = fun (c : α) =&gt; x + y + c := rfl
</code></pre>
<p>You can use <code>..</code> to provide missing explicit arguments as <code>_</code>.
This feature combined with named arguments is useful for writing patterns. Here is an example:</p>
<pre><code class="language-lean">inductive Term where
  | var    (name : String)
  | num    (val : Nat)
  | add    (fn : Term) (arg : Term)
  | lambda (name : String) (type : Term) (body : Term)

def getBinderName : Term → Option String
  | Term.lambda (name := n) .. =&gt; some n
  | _ =&gt; none

def getBinderType : Term → Option Term
  | Term.lambda (type := t) .. =&gt; some t
  | _ =&gt; none
</code></pre>
<p>Ellipses are also useful when explicit argument can be automatically
inferred by Lean, and we want to avoid a sequence of <code>_</code>s.</p>
<pre><code class="language-lean">example (f : Nat → Nat) (a b c : Nat) : f (a + b + c) = f (a + (b + c)) :=
  congrArg f (Nat.add_assoc ..)
</code></pre>
<h1><a class="header" href="#inductive-types" id="inductive-types">Inductive Types</a></h1>
<p>We have seen that Lean's formal foundation includes basic types,
<code>Prop, Type 0, Type 1, Type 2, ...</code>, and allows for the formation of
dependent function types, <code>(x : α) → β</code>. In the examples, we have
also made use of additional types like <code>Bool</code>, <code>Nat</code>, and <code>Int</code>,
and type constructors, like <code>List</code>, and product, <code>×</code>. In fact, in
Lean's library, every concrete type other than the universes and every
type constructor other than dependent arrows is an instance of a general family of
type constructions known as <em>inductive types</em>. It is remarkable that
it is possible to construct a substantial edifice of mathematics based
on nothing more than the type universes, dependent arrow types, and inductive
types; everything else follows from those.</p>
<p>Intuitively, an inductive type is built up from a specified list of
constructors. In Lean, the syntax for specifying such a type is as
follows:</p>
<pre><code>    inductive Foo where
      | constructor₁ : ... → Foo
      | constructor₂ : ... → Foo
      ...
      | constructorₙ : ... → Foo
</code></pre>
<p>The intuition is that each constructor specifies a way of building new
objects of <code>Foo</code>, possibly from previously constructed values. The
type <code>Foo</code> consists of nothing more than the objects that are
constructed in this way. The first character <code>|</code> in an inductive
declaration is optional. We can also separate constructors using a
comma instead of <code>|</code>.</p>
<p>We will see below that the arguments of the constructors can include
objects of type <code>Foo</code>, subject to a certain &quot;positivity&quot; constraint,
which guarantees that elements of <code>Foo</code> are built from the bottom
up. Roughly speaking, each <code>...</code> can be any arrow type constructed from
<code>Foo</code> and previously defined types, in which <code>Foo</code> appears, if at
all, only as the &quot;target&quot; of the dependent arrow type.</p>
<p>We will provide a number of examples of inductive types. We will also
consider slight generalizations of the scheme above, to mutually
defined inductive types, and so-called <em>inductive families</em>.</p>
<p>As with the logical connectives, every inductive type comes with
introduction rules, which show how to construct an element of the
type, and elimination rules, which show how to &quot;use&quot; an element of the
type in another construction. The analogy to the logical connectives
should not come as a surprise; as we will see below, they, too, are
examples of inductive type constructions. You have already seen the
introduction rules for an inductive type: they are just the
constructors that are specified in the definition of the type. The
elimination rules provide for a principle of recursion on the type,
which includes, as a special case, a principle of induction as well.</p>
<p>In the next chapter, we will describe Lean's function definition
package, which provides even more convenient ways to define functions
on inductive types and carry out inductive proofs. But because the
notion of an inductive type is so fundamental, we feel it is important
to start with a low-level, hands-on understanding. We will start with
some basic examples of inductive types, and work our way up to more
elaborate and complex examples.</p>
<h2><a class="header" href="#enumerated-types" id="enumerated-types">Enumerated Types</a></h2>
<p>The simplest kind of inductive type is simply a type with a finite, enumerated list of elements.</p>
<pre><code class="language-lean">inductive Weekday where
  | sunday : Weekday
  | monday : Weekday
  | tuesday : Weekday
  | wednesday : Weekday
  | thursday : Weekday
  | friday : Weekday
  | saturday : Weekday
</code></pre>
<p>The <code>inductive</code> command creates a new type, <code>Weekday</code>. The
constructors all live in the <code>Weekday</code> namespace.</p>
<pre><code class="language-lean"><span class="boring">inductive Weekday where
</span><span class="boring"> | sunday : Weekday
</span><span class="boring"> | monday : Weekday
</span><span class="boring"> | tuesday : Weekday
</span><span class="boring"> | wednesday : Weekday
</span><span class="boring"> | thursday : Weekday
</span><span class="boring"> | friday : Weekday
</span><span class="boring"> | saturday : Weekday
</span>#check Weekday.sunday
#check Weekday.monday

open Weekday

#check sunday
#check monday
</code></pre>
<p>You can omit <code>: Weekday</code> when declaring the <code>Weekday</code> inductive type.</p>
<pre><code class="language-lean">inductive Weekday where
  | sunday
  | monday
  | tuesday
  | wednesday
  | thursday
  | friday
  | saturday
</code></pre>
<p>Think of <code>sunday</code>, <code>monday</code>, ... , <code>saturday</code> as
being distinct elements of <code>Weekday</code>, with no other distinguishing
properties. The elimination principle, <code>Weekday.rec</code>, is defined
along with the type <code>Weekday</code> and its constructors. It is also known
as a <em>recursor</em>, and it is what makes the type &quot;inductive&quot;: it allows
us to define a function on <code>Weekday</code> by assigning values
corresponding to each constructor. The intuition is that an inductive
type is exhaustively generated by the constructors, and has no
elements beyond those they construct.</p>
<p>We will use the <code>match</code> expression to define a function from <code>Weekday</code>
to the natural numbers:</p>
<pre><code class="language-lean"><span class="boring">inductive Weekday where
</span><span class="boring"> | sunday : Weekday
</span><span class="boring"> | monday : Weekday
</span><span class="boring"> | tuesday : Weekday
</span><span class="boring"> | wednesday : Weekday
</span><span class="boring"> | thursday : Weekday
</span><span class="boring"> | friday : Weekday
</span><span class="boring"> | saturday : Weekday
</span>open Weekday

def numberOfDay (d : Weekday) : Nat :=
  match d with
  | sunday    =&gt; 1
  | monday    =&gt; 2
  | tuesday   =&gt; 3
  | wednesday =&gt; 4
  | thursday  =&gt; 5
  | friday    =&gt; 6
  | saturday  =&gt; 7

#eval numberOfDay Weekday.sunday  -- 1
#eval numberOfDay Weekday.monday  -- 2
#eval numberOfDay Weekday.tuesday -- 3
</code></pre>
<p>Note that the <code>match</code> expression is compiled using the <em>recursor</em> <code>Weekday.rec</code> generated when
you declare the inductive type.</p>
<pre><code class="language-lean"><span class="boring">inductive Weekday where
</span><span class="boring"> | sunday : Weekday
</span><span class="boring"> | monday : Weekday
</span><span class="boring"> | tuesday : Weekday
</span><span class="boring"> | wednesday : Weekday
</span><span class="boring"> | thursday : Weekday
</span><span class="boring"> | friday : Weekday
</span><span class="boring"> | saturday : Weekday
</span>open Weekday

def numberOfDay (d : Weekday) : Nat :=
  match d with
  | sunday    =&gt; 1
  | monday    =&gt; 2
  | tuesday   =&gt; 3
  | wednesday =&gt; 4
  | thursday  =&gt; 5
  | friday    =&gt; 6
  | saturday  =&gt; 7

set_option pp.all true
#print numberOfDay
-- ... numberOfDay.match_1
#print numberOfDay.match_1
-- ... Weekday.casesOn ...
#print Weekday.casesOn
-- ... Weekday.rec ...
#check @Weekday.rec
/-
@Weekday.rec.{u}
 : {motive : Weekday → Sort u} →
    motive Weekday.sunday →
    motive Weekday.monday →
    motive Weekday.tuesday →
    motive Weekday.wednesday →
    motive Weekday.thursday →
    motive Weekday.friday →
    motive Weekday.saturday →
    (t : Weekday) → motive t
-/
</code></pre>
<p>When declaring an inductive datatype, you can use <code>deriving Repr</code> to instruct
Lean to generate a fuction that converts <code>Weekday</code> objects into text.
This function is used by the <code>#eval</code> command to display <code>Weekday</code> objects.</p>
<pre><code class="language-lean">inductive Weekday where
  | sunday
  | monday
  | tuesday
  | wednesday
  | thursday
  | friday
  | saturday
  deriving Repr

open Weekday

#eval tuesday   -- Weekday.tuesday
</code></pre>
<p>It is often useful to group definitions and theorems related to a
structure in a namespace with the same name. For example, we can put
the <code>numberOfDay</code> function in the <code>Weekday</code> namespace. We are
then allowed to use the shorter name when we open the namespace.</p>
<p>We can define functions from <code>Weekday</code> to <code>Weekday</code>:</p>
<pre><code class="language-lean"><span class="boring">inductive Weekday where
</span><span class="boring"> | sunday : Weekday
</span><span class="boring"> | monday : Weekday
</span><span class="boring"> | tuesday : Weekday
</span><span class="boring"> | wednesday : Weekday
</span><span class="boring"> | thursday : Weekday
</span><span class="boring"> | friday : Weekday
</span><span class="boring"> | saturday : Weekday
</span><span class="boring"> deriving Repr
</span>
namespace Weekday
def next (d : Weekday) : Weekday :=
  match d with
  | sunday    =&gt; monday
  | monday    =&gt; tuesday
  | tuesday   =&gt; wednesday
  | wednesday =&gt; thursday
  | thursday  =&gt; friday
  | friday    =&gt; saturday
  | saturday  =&gt; sunday

def previous (d : Weekday) : Weekday :=
  match d with
  | sunday    =&gt; saturday
  | monday    =&gt; sunday
  | tuesday   =&gt; monday
  | wednesday =&gt; tuesday
  | thursday  =&gt; wednesday
  | friday    =&gt; thursday
  | saturday  =&gt; friday

#eval next (next tuesday)      -- Weekday.thursday
#eval next (previous tuesday)  -- Weekday.tuesday

example : next (previous tuesday) = tuesday :=
  rfl

end Weekday
</code></pre>
<p>How can we prove the general theorem that <code>next (previous d) = d</code>
for any Weekday <code>d</code>? You can use <code>match</code> to provide a proof of the claim for each
constructor:</p>
<pre><code class="language-lean"><span class="boring">inductive Weekday where
</span><span class="boring"> | sunday : Weekday
</span><span class="boring"> | monday : Weekday
</span><span class="boring"> | tuesday : Weekday
</span><span class="boring"> | wednesday : Weekday
</span><span class="boring"> | thursday : Weekday
</span><span class="boring"> | friday : Weekday
</span><span class="boring"> | saturday : Weekday
</span><span class="boring"> deriving Repr
</span><span class="boring">namespace Weekday
</span><span class="boring">def next (d : Weekday) : Weekday :=
</span><span class="boring"> match d with
</span><span class="boring"> | sunday    =&gt; monday
</span><span class="boring"> | monday    =&gt; tuesday
</span><span class="boring"> | tuesday   =&gt; wednesday
</span><span class="boring"> | wednesday =&gt; thursday
</span><span class="boring"> | thursday  =&gt; friday
</span><span class="boring"> | friday    =&gt; saturday
</span><span class="boring"> | saturday  =&gt; sunday
</span><span class="boring">def previous (d : Weekday) : Weekday :=
</span><span class="boring"> match d with
</span><span class="boring"> | sunday    =&gt; saturday
</span><span class="boring"> | monday    =&gt; sunday
</span><span class="boring"> | tuesday   =&gt; monday
</span><span class="boring"> | wednesday =&gt; tuesday
</span><span class="boring"> | thursday  =&gt; wednesday
</span><span class="boring"> | friday    =&gt; thursday
</span><span class="boring"> | saturday  =&gt; friday
</span>def next_previous (d : Weekday) : next (previous d) = d :=
  match d with
  | sunday    =&gt; rfl
  | monday    =&gt; rfl
  | tuesday   =&gt; rfl
  | wednesday =&gt; rfl
  | thursday  =&gt; rfl
  | friday    =&gt; rfl
  | saturday  =&gt; rfl
</code></pre>
<p>Using a tactic proof, we can be even more concise:</p>
<pre><code class="language-lean"><span class="boring">inductive Weekday where
</span><span class="boring"> | sunday : Weekday
</span><span class="boring"> | monday : Weekday
</span><span class="boring"> | tuesday : Weekday
</span><span class="boring"> | wednesday : Weekday
</span><span class="boring"> | thursday : Weekday
</span><span class="boring"> | friday : Weekday
</span><span class="boring"> | saturday : Weekday
</span><span class="boring"> deriving Repr
</span><span class="boring">namespace Weekday
</span><span class="boring">def next (d : Weekday) : Weekday :=
</span><span class="boring"> match d with
</span><span class="boring"> | sunday    =&gt; monday
</span><span class="boring"> | monday    =&gt; tuesday
</span><span class="boring"> | tuesday   =&gt; wednesday
</span><span class="boring"> | wednesday =&gt; thursday
</span><span class="boring"> | thursday  =&gt; friday
</span><span class="boring"> | friday    =&gt; saturday
</span><span class="boring"> | saturday  =&gt; sunday
</span><span class="boring">def previous (d : Weekday) : Weekday :=
</span><span class="boring"> match d with
</span><span class="boring"> | sunday    =&gt; saturday
</span><span class="boring"> | monday    =&gt; sunday
</span><span class="boring"> | tuesday   =&gt; monday
</span><span class="boring"> | wednesday =&gt; tuesday
</span><span class="boring"> | thursday  =&gt; wednesday
</span><span class="boring"> | friday    =&gt; thursday
</span><span class="boring"> | saturday  =&gt; friday
</span>def next_previous (d : Weekday) : next (previous d) = d := by
  cases d &lt;;&gt; rfl
</code></pre>
<p><a href="inductive_types.html#_tactics_for_inductive_types">Tactics for Inductive Types</a> below will introduce additional
tactics that are specifically designed to make use of inductive types.</p>
<p>Notice that, under the propositions-as-types correspondence, we can
use <code>match</code> to prove theorems as well as define functions.  In other
words, under the propositions-as-types correspondence, the proof by
cases is a kind of definition by cases, where what is being &quot;defined&quot;
is a proof instead of a piece of data.</p>
<p>The <code>Bool</code> type in the Lean library is an instance of
enumerated type.</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>inductive Bool where
  | false : Bool
  | true  : Bool
<span class="boring">end Hidden
</span></code></pre>
<p>(To run these examples, we put them in a namespace called <code>Hidden</code>,
so that a name like <code>Bool</code> does not conflict with the <code>Bool</code> in
the standard library. This is necessary because these types are part
of the Lean &quot;prelude&quot; that is automatically imported when the system
is started.)</p>
<p>As an exercise, you should think about what the introduction and
elimination rules for these types do. As a further exercise, we
suggest defining boolean operations <code>and</code>, <code>or</code>, <code>not</code> on the
<code>Bool</code> type, and verifying common identities. Note that you can define a
binary operation like <code>and</code> using <code>match</code>:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>def and (a b : Bool) : Bool :=
  match a with
  | true  =&gt; b
  | false =&gt; false
<span class="boring">end Hidden
</span></code></pre>
<p>Similarly, most identities can be proved by introducing suitable <code>match</code>, and then using <code>rfl</code>.</p>
<h2><a class="header" href="#constructors-with-arguments" id="constructors-with-arguments">Constructors with Arguments</a></h2>
<p>Enumerated types are a very special case of inductive types, in which
the constructors take no arguments at all. In general, a
&quot;construction&quot; can depend on data, which is then represented in the
constructed argument. Consider the definitions of the product type and
sum type in the library:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>inductive Prod (α : Type u) (β : Type v)
  | mk : α → β → Prod α β

inductive Sum (α : Type u) (β : Type v) where
  | inl : α → Sum α β
  | inr : β → Sum α β
<span class="boring">end Hidden
</span></code></pre>
<p>Notice that we do not include the types <code>α</code> and <code>β</code> in the target
of the constructors. In the meanwhile, think about what is going on in
these examples. The product type has one constructor, <code>Prod.mk</code>,
which takes two arguments. To define a function on <code>Prod α β</code>, we
can assume the input is of the form <code>Prod.mk a b</code>, and we have to
specify the output, in terms of <code>a</code> and <code>b</code>. We can use this to
define the two projections for <code>Prod</code>. Remember that the standard
library defines notation <code>α × β</code> for <code>Prod α β</code> and <code>(a, b)</code> for
<code>Prod.mk a b</code>.</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span><span class="boring">inductive Prod (α : Type u) (β : Type v)
</span><span class="boring">  | mk : α → β → Prod α β
</span>def fst {α : Type u} {β : Type v} (p : Prod α β) : α :=
  match p with
  | Prod.mk a b =&gt; a

def snd {α : Type u} {β : Type v} (p : Prod α β) : β :=
  match p with
  | Prod.mk a b =&gt; b
<span class="boring">end Hidden
</span></code></pre>
<p>The function <code>fst</code> takes a pair, <code>p</code>. The <code>match</code> interprets
<code>p</code> as a pair, <code>Prod.mk a b</code>. Recall also from <a href="./dependent_type_theory.html">Dependent Type Theory</a>
that to give these definitions the greatest generality possible, we allow
the types <code>α</code> and <code>β</code> to belong to any universe.</p>
<p>Here is another example where we use the recursor <code>Prod.casesOn</code> instead
of <code>match</code>.</p>
<pre><code class="language-lean">def prod_example (p : Bool × Nat) : Nat :=
  Prod.casesOn (motive := fun _ =&gt; Nat) p (fun b n =&gt; cond b (2 * n) (2 * n + 1))

#eval prod_example (true, 3)
#eval prod_example (false, 3)
</code></pre>
<p>The argument <code>motive</code> is used to specify the type of the object you want to
construct, and it is a function because it may depend on the pair.
The <code>cond</code> function is a boolean conditional: <code>cond b t1 t2</code>
returns <code>t1</code> if <code>b</code> is true, and <code>t2</code> otherwise.
The function <code>prod_example</code> takes a pair consisting of a boolean,
<code>b</code>, and a number, <code>n</code>, and returns either <code>2 * n</code> or <code>2 * n + 1</code>
according to whether <code>b</code> is true or false.</p>
<p>In contrast, the sum type has <em>two</em> constructors, <code>inl</code> and <code>inr</code>
(for &quot;insert left&quot; and &quot;insert right&quot;), each of which takes <em>one</em>
(explicit) argument. To define a function on <code>Sum α β</code>, we have to
handle two cases: either the input is of the form <code>inl a</code>, in which
case we have to specify an output value in terms of <code>a</code>, or the
input is of the form <code>inr b</code>, in which case we have to specify an
output value in terms of <code>b</code>.</p>
<pre><code class="language-lean">def sum_example (s : Sum Nat Nat) : Nat :=
Sum.casesOn (motive := fun _ =&gt; Nat) s
   (fun n =&gt; 2 * n)
   (fun n =&gt; 2 * n + 1)

#eval sum_example (Sum.inl 3)
#eval sum_example (Sum.inr 3)
</code></pre>
<p>This example is similar to the previous one, but now an input to
<code>sum_example</code> is implicitly either of the form <code>inl n</code> or <code>inr n</code>.
In the first case, the function returns <code>2 * n</code>, and the second
case, it returns <code>2 * n + 1</code>.</p>
<p>Notice that the product type depends on parameters <code>α β : Type</code>
which are arguments to the constructors as well as <code>Prod</code>. Lean
detects when these arguments can be inferred from later arguments to a
constructor or the return type, and makes them implicit in that case.</p>
<p>In the section after next we will see what happens when the
constructor of an inductive type takes arguments from the inductive
type itself. What characterizes the examples we consider in this
section is that this is not the case: each constructor relies only on
previously specified types.</p>
<p>Notice that a type with multiple constructors is disjunctive: an
element of <code>Sum α β</code> is either of the form <code>inl a</code> <em>or</em> of the
form <code>inl b</code>. A constructor with multiple arguments introduces
conjunctive information: from an element <code>Prod.mk a b</code> of
<code>Prod α β</code> we can extract <code>a</code> <em>and</em> <code>b</code>. An arbitrary inductive type can
include both features, by having any number of constructors, each of
which takes any number of arguments.</p>
<p>As with function definitions, Lean's inductive definition syntax will
let you put named arguments to the constructors before the colon:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>inductive Prod (α : Type u) (β : Type v) where
  | mk (fst : α) (snd : β) : Prod α β

inductive Sum (α : Type u) (β : Type v) where
  | inl (a : α) : Sum α β
  | inr (b : β) : Sum α β
<span class="boring">end Hidden
</span></code></pre>
<p>The results of these definitions are essentially the same as the ones given earlier in this section.</p>
<p>A type, like <code>Prod</code>, that has only one constructor is purely
conjunctive: the constructor simply packs the list of arguments into a
single piece of data, essentially a tuple where the type of subsequent
arguments can depend on the type of the initial argument. We can also
think of such a type as a &quot;record&quot; or a &quot;structure&quot;. In Lean, the
keyword <code>structure</code> can be used to define such an inductive type as
well as its projections, at the same time.</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>structure Prod (α : Type u) (β : Type v) where
  mk :: (fst : α) (snd : β)
<span class="boring">end Hidden
</span></code></pre>
<p>This example simultaneously introduces the inductive type, <code>Prod</code>,
its constructor, <code>mk</code>, the usual eliminators (<code>rec</code> and
<code>recOn</code>), as well as the projections, <code>fst</code> and <code>snd</code>, as
defined above.</p>
<p>If you do not name the constructor, Lean uses <code>mk</code> as a default. For
example, the following defines a record to store a color as a triple
of RGB values:</p>
<pre><code class="language-lean">structure Color where
  (red : Nat) (green : Nat) (blue : Nat)
  deriving Repr

def yellow := Color.mk 255 255 0

#eval Color.red yellow
</code></pre>
<p>The definition of <code>yellow</code> forms the record with the three values
shown, and the projection <code>Color.red</code> returns the red component.</p>
<p>You can avoid the parentheses if you add a line break between each field.</p>
<pre><code class="language-lean">structure Color where
  red : Nat
  green : Nat
  blue : Nat
  deriving Repr
</code></pre>
<p>The <code>structure</code> command is especially useful for defining algebraic
structures, and Lean provides substantial infrastructure to support
working with them. Here, for example, is the definition of a
semigroup:</p>
<pre><code class="language-lean">structure Semigroup where
  carrier : Type u
  mul : carrier → carrier → carrier
  mul_assoc : ∀ a b c, mul (mul a b) c = mul a (mul b c)
</code></pre>
<p>We will see more examples in <a href="./structures_and_records.html">Chapter Structures and Records</a>.</p>
<p>We have already discussed the dependent product type <code>Sigma</code>:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>inductive Sigma {α : Type u} (β : α → Type v) where
  | mk : (a : α) → β a → Sigma β
<span class="boring">end Hidden
</span></code></pre>
<p>Two more examples of inductive types in the library are the following:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>inductive Option (α : Type u) where
  | none : Option α
  | some : α → Option α

inductive Inhabited (α : Type u) where
  | mk : α → Inhabited α
<span class="boring">end Hidden
</span></code></pre>
<p>In the semantics of dependent type theory, there is no built-in notion
of a partial function. Every element of a function type <code>α → β</code> or a
dependent function type <code>(a : α) → β</code> is assumed to have a value
at every input. The <code>Option</code> type provides a way of representing partial functions. An
element of <code>Option β</code> is either <code>none</code> or of the form <code>some b</code>,
for some value <code>b : β</code>. Thus we can think of an element <code>f</code> of the
type <code>α → Option β</code> as being a partial function from <code>α</code> to <code>β</code>:
for every <code>a : α</code>, <code>f a</code> either returns <code>none</code>, indicating the
<code>f a</code> is &quot;undefined&quot;, or <code>some b</code>.</p>
<p>An element of <code>Inhabited α</code> is simply a witness to the fact that
there is an element of <code>α</code>. Later, we will see that <code>Inhabited</code> is
an example of a <em>type class</em> in Lean: Lean can be instructed that
suitable base types are inhabited, and can automatically infer that
other constructed types are inhabited on that basis.</p>
<p>As exercises, we encourage you to develop a notion of composition for
partial functions from <code>α</code> to <code>β</code> and <code>β</code> to <code>γ</code>, and show
that it behaves as expected. We also encourage you to show that
<code>Bool</code> and <code>Nat</code> are inhabited, that the product of two inhabited
types is inhabited, and that the type of functions to an inhabited
type is inhabited.</p>
<h2><a class="header" href="#inductively-defined-propositions" id="inductively-defined-propositions">Inductively Defined Propositions</a></h2>
<p>Inductively defined types can live in any type universe, including the
bottom-most one, <code>Prop</code>. In fact, this is exactly how the logical
connectives are defined.</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>inductive False : Prop

inductive True : Prop where
  | intro : True

inductive And (a b : Prop) : Prop where
  | intro : a → b → And a b

inductive Or (a b : Prop) : Prop where
  | inl : a → Or a b
  | inr : b → Or a b
<span class="boring">end Hidden
</span></code></pre>
<p>You should think about how these give rise to the introduction and
elimination rules that you have already seen. There are rules that
govern what the eliminator of an inductive type can eliminate <em>to</em>,
that is, what kinds of types can be the target of a recursor. Roughly
speaking, what characterizes inductive types in <code>Prop</code> is that one
can only eliminate to other types in <code>Prop</code>. This is consistent with
the understanding that if <code>p : Prop</code>, an element <code>hp : p</code> carries
no data. There is a small exception to this rule, however, which we
will discuss below, in the section on inductive families.</p>
<p>Even the existential quantifier is inductively defined:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>inductive Exists {α : Type u} (q : α → Prop) : Prop where
  | intro : ∀ (a : α), q a → Exists q
<span class="boring">end Hidden
</span></code></pre>
<p>Keep in mind that the notation <code>∃ x : α, p</code> is syntactic sugar for <code>Exists (fun x : α =&gt; p)</code>.</p>
<p>The definitions of <code>False</code>, <code>True</code>, <code>And</code>, and <code>Or</code> are
perfectly analogous to the definitions of <code>Empty</code>, <code>Unit</code>,
<code>Prod</code>, and <code>Sum</code>. The difference is that the first group yields
elements of <code>Prop</code>, and the second yields elements of <code>Type u</code> for
some <code>u</code>. In a similar way, <code>∃ x : α, p</code> is a <code>Prop</code>-valued
variant of <code>Σ x : α, p</code>.</p>
<p>This is a good place to mention another inductive type, denoted
<code>{x : α // p}</code>, which is sort of a hybrid between
<code>∃ x : α, P</code> and <code>Σ x : α, P</code>.</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>inductive Subtype {α : Type u} (p : α → Prop) where
  | mk : (x : α) → p x → Subtype p
<span class="boring">end Hidden
</span></code></pre>
<p>In fact, in Lean, <code>Subtype</code> is defined using the structure command:</p>
<p>The notation <code>{x : α // p x}</code> is syntactic sugar for <code>Subtype (fun x : α =&gt; p x)</code>.
It is modeled after subset notation in set theory: the idea is that <code>{x : α // p x}</code>
denotes the collection of elements of <code>α</code> that have property <code>p</code>.</p>
<h2><a class="header" href="#defining-the-natural-numbers" id="defining-the-natural-numbers">Defining the Natural Numbers</a></h2>
<p>The inductively defined types we have seen so far are &quot;flat&quot;:
constructors wrap data and insert it into a type, and the
corresponding recursor unpacks the data and acts on it. Things get
much more interesting when the constructors act on elements of the
very type being defined. A canonical example is the type <code>Nat</code> of
natural numbers:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>inductive Nat where
  | zero : Nat
  | succ : Nat → Nat
<span class="boring">end Hidden
</span></code></pre>
<p>There are two constructors. We start with <code>zero : Nat</code>; it takes
no arguments, so we have it from the start. In contrast, the
constructor <code>succ</code> can only be applied to a previously constructed
<code>Nat</code>. Applying it to <code>zero</code> yields <code>succ zero : Nat</code>. Applying
it again yields <code>succ (succ zero) : Nat</code>, and so on. Intuitively,
<code>Nat</code> is the &quot;smallest&quot; type with these constructors, meaning that
it is exhaustively (and freely) generated by starting with <code>zero</code>
and applying <code>succ</code> repeatedly.</p>
<p>As before, the recursor for <code>Nat</code> is designed to define a dependent
function <code>f</code> from <code>Nat</code> to any domain, that is, an element <code>f</code>
of <code>(n : nat) → motive n</code> for some <code>motive : Nat → Sort u</code>.
It has to handle two cases: the case where the input is <code>zero</code>, and the case where
the input is of the form <code>succ n</code> for some <code>n : Nat</code>. In the first
case, we simply specify a target value with the appropriate type, as
before. In the second case, however, the recursor can assume that a
value of <code>f</code> at <code>n</code> has already been computed. As a result, the
next argument to the recursor specifies a value for <code>f (succ n)</code> in
terms of <code>n</code> and <code>f n</code>. If we check the type of the recursor,</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span><span class="boring">inductive Nat where
</span><span class="boring"> | zero : Nat
</span><span class="boring"> | succ : Nat → Nat
</span>#check @Nat.rec
<span class="boring">end Hidden
</span></code></pre>
<p>you find the following:</p>
<pre><code>  {motive : Nat → Sort u}
  → motive Nat.zero
  → ((n : Nat) → motive n → motive (Nat.succ n))
  → (t : Nat) → motive t
</code></pre>
<p>The implicit argument, <code>motive</code>, is the codomain of the function being defined.
In type theory it is common to say <code>motive</code> is the <em>motive</em> for the elimination/recursion,
since it describes the kind of object we wish to construct.
The next two arguments specify how to compute the zero and successor cases, as described above.
They are also known as the <code>minor premises</code>.
Finally, the <code>t : Nat</code>, is the input to the function. It is also known as the <code>major premise</code>.</p>
<p>The <code>Nat.recOn</code> is similar to <code>Nat.rec</code> but the major premise occurs before the minor premises.</p>
<pre><code>@Nat.recOn :
  {motive : Nat → Sort u}
  → (t : Nat)
  → motive Nat.zero
  → ((n : Nat) → motive n → motive (Nat.succ n))
  → motive t
</code></pre>
<p>Consider, for example, the addition function <code>add m n</code> on the
natural numbers. Fixing <code>m</code>, we can define addition by recursion on
<code>n</code>. In the base case, we set <code>add m zero</code> to <code>m</code>. In the
successor step, assuming the value <code>add m n</code> is already determined,
we define <code>add m (succ n)</code> to be <code>succ (add m n)</code>.</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>inductive Nat where
  | zero : Nat
  | succ : Nat → Nat
  deriving Repr

def add (m n : Nat) : Nat :=
  match n with
  | Nat.zero   =&gt; m
  | Nat.succ n =&gt; Nat.succ (add m n)

open Nat

#eval add (succ (succ zero)) (succ zero)
<span class="boring">end Hidden
</span></code></pre>
<p>It is useful to put such definitions into a namespace, <code>Nat</code>. We can
then go on to define familiar notation in that namespace. The two
defining equations for addition now hold definitionally:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span><span class="boring">inductive Nat where
</span><span class="boring"> | zero : Nat
</span><span class="boring"> | succ : Nat → Nat
</span><span class="boring"> deriving Repr
</span>namespace Nat

def add (m n : Nat) : Nat :=
  match n with
  | Nat.zero   =&gt; m
  | Nat.succ n =&gt; Nat.succ (add m n)

instance : Add Nat where
  add := add

theorem add_zero (m : Nat) : m + zero = m := rfl
theorem add_succ (m n : Nat) : m + succ n = succ (m + n) := rfl

end Nat
<span class="boring">end Hidden
</span></code></pre>
<p>We will explain how the <code>instance</code> command works in
<a href="./type_classes.html">Chapter Type Classes</a>. In the examples below, we will henceforth use
Lean's version of the natural numbers.</p>
<p>Proving a fact like <code>zero + m = m</code>, however, requires a proof by induction.
As observed above, the induction principle is just a special case of the recursion principle,
when the codomain <code>motive n</code> is an element of <code>Prop</code>. It represents the familiar
pattern of an inductive proof: to prove <code>∀ n, motive n</code>, first prove <code>motive 0</code>,
and then, for arbitrary <code>n</code>, assume <code>ih : motive n</code> and prove <code>motive (succ n)</code>.</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>open Nat

theorem zero_add (n : Nat) : 0 + n = n :=
  Nat.recOn (motive := fun x =&gt; 0 + x = x)
   n
   (show 0 + 0 = 0 from rfl)
   (fun (n : Nat) (ih : 0 + n = n) =&gt;
    show 0 + succ n = succ n from
    calc
       0 + succ n = succ (0 + n) := rfl
                _ = succ n       := by rw [ih])
<span class="boring">end Hidden
</span></code></pre>
<p>Notice that, once again, when <code>Nat.recOn</code> is used in the context of
a proof, it is really the induction principle in disguise. The
<code>rewrite</code> and <code>simp</code> tactics tend to be very effective in proofs
like these. In this case, each can be used to reduce the proof to:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>open Nat

theorem zero_add (n : Nat) : 0 + n = n :=
  Nat.recOn (motive := fun x =&gt; 0 + x = x) n
    rfl
    (fun n ih =&gt; by simp [add_succ, ih])
<span class="boring">end Hidden
</span></code></pre>
<p>For another example, let us prove the associativity of addition,
<code>∀ m n k, m + n + k = m + (n + k)</code>.
(The notation <code>+</code>, as we have defined it, associates to the left, so <code>m + n + k</code> is really <code>(m + n) + k</code>.)
The hardest part is figuring out which variable to do the induction on. Since addition is defined by recursion on the second argument,
<code>k</code> is a good guess, and once we make that choice the proof almost writes itself:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>open Nat
theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) :=
  Nat.recOn (motive := fun k =&gt; m + n + k = m + (n + k)) k
    (show m + n + 0 = m + (n + 0) from rfl)
    (fun k (ih : m + n + k = m + (n + k)) =&gt;
      show m + n + succ k = m + (n + succ k) from
      calc
          m + n + succ k = succ (m + n + k) := rfl
            _ = succ (m + (n + k)) := by rw [ih]
            _ = m + succ (n + k) := rfl
            _ = m + (n + succ k) := rfl)
<span class="boring">end Hidden
</span></code></pre>
<p>One again, you can reduce the proof to:</p>
<pre><code class="language-lean">open Nat
theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) :=
  Nat.recOn (motive := fun k =&gt; m + n + k = m + (n + k)) k
    rfl
    (fun k ih =&gt; by simp [Nat.add_succ, ih]; done)
</code></pre>
<p>Suppose we try to prove the commutativity of addition. Choosing induction on the second argument, we might begin as follows:</p>
<pre><code class="language-lean">open Nat
theorem add_comm (m n : Nat) : m + n = n + m :=
  Nat.recOn (motive := fun x =&gt; m + x = x + m) n
   (show m + 0 = 0 + m by rw [Nat.zero_add, Nat.add_zero])
   (fun (n : Nat) (ih : m + n = n + m) =&gt;
    show m + succ n = succ n + m from
    calc m + succ n = succ (m + n) := rfl
                  _ = succ (n + m) := by rw [ih]
                  _ = succ n +  m  := sorry)
</code></pre>
<p>At this point, we see that we need another supporting fact, namely, that <code>succ (n + m) = succ n + m</code>.
You can prove this by induction on <code>m</code>:</p>
<pre><code class="language-lean">open Nat

theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=
  Nat.recOn (motive := fun x =&gt; succ n + x = succ (n + x)) m
    (show succ n + 0 = succ (n + 0) from rfl)
    (fun (m : Nat) (ih : succ n + m = succ (n + m)) =&gt;
     show succ n + succ m = succ (n + succ m) from
     calc succ n + succ m = succ (succ n + m) := rfl
           _  = succ (succ (n + m))           := by rw [ih]
           _  = succ (n + succ m)             := rfl)
</code></pre>
<p>You can then replace the <code>sorry</code> in the previous proof with <code>succ_add</code>. Yet again, the proofs can be compressed:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>open Nat
theorem succ_add (n m : Nat) : succ n + m = succ (n + m) :=
  Nat.recOn (motive := fun x =&gt; succ n + x = succ (n + x)) m
    rfl
    (fun m ih =&gt; by simp only [add_succ, ih])

theorem add_comm (m n : Nat) : m + n = n + m :=
  Nat.recOn (motive := fun x =&gt; m + x = x + m) n
    (by simp)
    (fun m ih =&gt; by simp only [add_succ, succ_add, ih])
<span class="boring">end Hidden
</span></code></pre>
<h2><a class="header" href="#other-recursive-data-types" id="other-recursive-data-types">Other Recursive Data Types</a></h2>
<p>Let us consider some more examples of inductively defined types. For
any type, <code>α</code>, the type <code>List α</code> of lists of elements of <code>α</code> is
defined in the library.</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>inductive List (α : Type u) where
| nil  : List α
| cons : α → List α → List α

namespace List

def append (as bs : List α) : List α :=
  match as with
  | nil       =&gt; bs
  | cons a as =&gt; cons a (append as bs)

theorem nil_append (as : List α) : append nil as = as :=
  rfl

theorem cons_append (a : α) (as bs : List α)
                    : append (cons a as) bs = cons a (append as bs) :=
  rfl

end List
<span class="boring">end Hidden
</span></code></pre>
<p>A list of elements of type <code>α</code> is either the empty list, <code>nil</code>, or
an element <code>h : α</code> followed by a list <code>t : List α</code>.
The first element, <code>h</code>, is commonly known as the &quot;head&quot; of the list,
and the remainder, <code>t</code>, is known as the &quot;tail.&quot;</p>
<p>As an exercise, prove the following:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span><span class="boring">inductive List (α : Type u) where
</span><span class="boring">| nil  : List α
</span><span class="boring">| cons : α → List α → List α
</span><span class="boring">namespace List
</span><span class="boring">def append (as bs : List α) : List α :=
</span><span class="boring"> match as with
</span><span class="boring"> | nil       =&gt; bs
</span><span class="boring"> | cons a as =&gt; cons a (append as bs)
</span><span class="boring">theorem nil_append (as : List α) : append nil as = as :=
</span><span class="boring"> rfl
</span><span class="boring">theorem cons_append (a : α) (as bs : List α)
</span><span class="boring">                    : append (cons a as) bs = cons a (append as bs) :=
</span><span class="boring"> rfl
</span>theorem append_nil (as : List α) : append as nil = as :=
  sorry

theorem append_assoc (as bs cs : List α)
        : append (append as bs) cs = append as (append bs cs) :=
  sorry
<span class="boring">end List
</span><span class="boring">end Hidden
</span></code></pre>
<p>Try also defining the function <code>length : {α : Type u} → List α → Nat</code> that returns the length of a list,
and prove that it behaves as expected (for example, <code>length (append as bs) = length as + length bs</code>).</p>
<p>For another example, we can define the type of binary trees:</p>
<pre><code class="language-lean">inductive BinaryTree where
  | leaf : BinaryTree
  | node : BinaryTree → BinaryTree → BinaryTree
</code></pre>
<p>In fact, we can even define the type of countably branching trees:</p>
<pre><code class="language-lean">inductive CBTree where
  | leaf : CBTree
  | sup : (Nat → CBTree) → CBTree

namespace CBTree

def succ (t : CBTree) : CBTree :=
  sup (fun _ =&gt; t)

def toCBTree : Nat → CBTree
  | 0 =&gt; leaf
  | n+1 =&gt; succ (toCBTree n)

def omega : CBTree :=
  sup toCBTree

end CBTree
</code></pre>
<h2><a class="header" href="#a-name_tactics_for_inductive_typesatactics-for-inductive-types" id="a-name_tactics_for_inductive_typesatactics-for-inductive-types"><a name="_tactics_for_inductive_types"></a>Tactics for Inductive Types</a></h2>
<p>Given the fundamental importance of inductive types in Lean, it should
not be surprising that there are a number of tactics designed to work
with them effectively. We describe some of them here.</p>
<p>The <code>cases</code> tactic works on elements of an inductively defined type,
and does what the name suggests: it decomposes the element according
to each of the possible constructors. In its most basic form, it is
applied to an element <code>x</code> in the local context. It then reduces the
goal to cases in which <code>x</code> is replaced by each of the constructions.</p>
<pre><code class="language-lean">example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (Nat.succ n)) : ∀ n, p n := by
  intro n
  cases n
  . exact hz  -- goal is p 0
  . apply hs  -- goal is a : ℕ ⊢ p (succ a)
</code></pre>
<p>There are extra bells and whistles. For one thing, <code>cases</code> allows
you to choose the names for each alternative using a
<code>with</code> clause. In the next example, for example, we choose the name
<code>m</code> for the argument to <code>succ</code>, so that the second case refers to
<code>succ m</code>. More importantly, the cases tactic will detect any items
in the local context that depend on the target variable. It reverts
these elements, does the split, and reintroduces them. In the example
below, notice that the hypothesis <code>h : n ≠ 0</code> becomes <code>h : 0 ≠ 0</code>
in the first branch, and <code>h : succ m ≠ 0</code> in the second.</p>
<pre><code class="language-lean">open Nat

example (n : Nat) (h : n ≠ 0) : succ (pred n) = n := by
  cases n with
  | zero =&gt;
    -- goal: h : 0 ≠ 0 ⊢ succ (pred 0) = 0
    apply absurd rfl h
  | succ m =&gt;
    -- second goal: h : succ m ≠ 0 ⊢ succ (pred (succ m)) = succ m
    rfl
</code></pre>
<p>Notice that <code>cases</code> can be used to produce data as well as prove propositions.</p>
<pre><code class="language-lean">def f (n : Nat) : Nat := by
  cases n; exact 3; exact 7

example : f 0 = 3 := rfl
example : f 5 = 7 := rfl
</code></pre>
<p>Once again, cases will revert, split, and then reintroduce depedencies in the context.</p>
<pre><code class="language-lean">def Tuple (α : Type) (n : Nat) :=
  { as : List α // as.length = n }

def f {n : Nat} (t : Tuple α n) : Nat := by
  cases n; exact 3; exact 7

def myTuple : Tuple Nat 3 :=
  ⟨[0, 1, 2], rfl⟩

example : f myTuple = 7 :=
  rfl
</code></pre>
<p>Here is an example with multiple constructors with arguments.</p>
<pre><code class="language-lean">inductive Foo where
  | bar1 : Nat → Nat → Foo
  | bar2 : Nat → Nat → Nat → Foo

def silly (x : Foo) : Nat := by
  cases x with
  | bar1 a b =&gt; exact b
  | bar2 c d e =&gt; exact e
</code></pre>
<p>The alternatives for each constructor don't need to be solved
in the order the constructors were declared.</p>
<pre><code class="language-lean">inductive Foo where
  | bar1 : Nat → Nat → Foo
  | bar2 : Nat → Nat → Nat → Foo

def silly (x : Foo) : Nat := by
  cases x with
  | bar2 c d e =&gt; exact e
  | bar1 a b =&gt; exact b
</code></pre>
<p>The syntax of the <code>with</code> is convenient for writing structured proofs.
Lean also provides a complementary <code>case</code> tactic, which allows you to focus on goal
assign variable names.</p>
<pre><code class="language-lean">inductive Foo where
  | bar1 : Nat → Nat → Foo
  | bar2 : Nat → Nat → Nat → Foo

def silly (x : Foo) : Nat := by
  cases x
  case bar2 c d e =&gt; exact e
  case bar1 a b =&gt; exact b
</code></pre>
<p>The <code>case</code> tactic is clever, in that it will match the constructor to the appropriate goal. For example, we can fill the goals above in the opposite order:</p>
<pre><code class="language-lean">inductive Foo where
  | bar1 : Nat → Nat → Foo
  | bar2 : Nat → Nat → Nat → Foo

def silly (x : Foo) : Nat := by
  cases x
  case bar1 a b =&gt; exact b
  case bar2 c d e =&gt; exact e
</code></pre>
<p>You can also use <code>cases</code> with an arbitrary expression. Assuming that
expression occurs in the goal, the cases tactic will generalize over
the expression, introduce the resulting universally quantified
variable, and case on that.</p>
<pre><code class="language-lean">open Nat

example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)
        : p (m + 3 * k) := by
  cases m + 3 * k
  exact hz   -- goal is p 0
  apply hs   -- goal is a : ℕ ⊢ p (succ a)
</code></pre>
<p>Think of this as saying &quot;split on cases as to whether <code>m + 3 * k</code> is
zero or the successor of some number.&quot; The result is functionally
equivalent to the following:</p>
<pre><code class="language-lean">open Nat

example (p : Nat → Prop) (hz : p 0) (hs : ∀ n, p (succ n)) (m k : Nat)
        : p (m + 3 * k) := by
  generalize m + 3 * k = n
  cases n
  exact hz   -- goal is p 0
  apply hs   -- goal is a : ℕ ⊢ p (succ a)
</code></pre>
<p>Notice that the expression <code>m + 3 * k</code> is erased by <code>generalize</code>; all
that matters is whether it is of the form <code>0</code> or <code>succ a</code>. This
form of <code>cases</code> will <em>not</em> revert any hypotheses that also mention
the expression in the equation (in this case, <code>m + 3 * k</code>). If such a
term appears in a hypothesis and you want to generalize over that as
well, you need to <code>revert</code> it explicitly.</p>
<p>If the expression you case on does not appear in the goal, the
<code>cases</code> tactic uses <code>have</code> to put the type of the expression into
the context. Here is an example:</p>
<pre><code class="language-lean">example (p : Prop) (m n : Nat)
        (h₁ : m &lt; n → p) (h₂ : m ≥ n → p) : p := by
  cases Nat.lt_or_ge m n
  case inl hlt =&gt; exact h₁ hlt
  case inr hge =&gt; exact h₂ hge
</code></pre>
<p>The theorem <code>Nat.lt_or_ge m n</code> says <code>m &lt; n ∨ m ≥ n</code>, and it is
natural to think of the proof above as splitting on these two
cases. In the first branch, we have the hypothesis <code>h₁ : m &lt; n</code>, and
in the second we have the hypothesis <code>h₂ : m ≥ n</code>. The proof above
is functionally equivalent to the following:</p>
<pre><code class="language-lean">example (p : Prop) (m n : Nat)
        (h₁ : m &lt; n → p) (h₂ : m ≥ n → p) : p := by
  have h : m &lt; n ∨ m ≥ n := Nat.lt_or_ge m n
  cases h
  case inl hlt =&gt; exact h₁ hlt
  case inr hge =&gt; exact h₂ hge
</code></pre>
<p>After the first two lines, we have <code>h : m &lt; n ∨ m ≥ n</code> as a
hypothesis, and we simply do cases on that.</p>
<p>Here is another example, where we use the decidability of equality on
the natural numbers to split on the cases <code>m = n</code> and <code>m ≠ n</code>.</p>
<pre><code class="language-lean">#check Nat.sub_self

example (m n : Nat) : m - n = 0 ∨ m ≠ n := by
  cases Decidable.em (m = n) with
  | inl heq =&gt; rw [heq]; apply Or.inl; exact Nat.sub_self n
  | inr hne =&gt; apply Or.inr; exact hne
</code></pre>
<p>Remember that if you <code>open Classical</code>, you can use the law of the
excluded middle for any proposition at all. But using type class
inference (see <a href="./type_classes.html">Chapter Type Classes</a>), Lean can actually
find the relevant decision procedure, which means that you can use the
case split in a computable function.</p>
<p>Just as the <code>cases</code> tactic can be used to carry out proof by cases,
the <code>induction</code> tactic can be used to carry out proofs by
induction. The syntax is similar to that of <code>cases</code>, except that the
argument can only be a term in the local context. Here is an example:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>theorem zero_add (n : Nat) : 0 + n = n := by
  induction n with
  | zero =&gt; rfl
  | succ n ih =&gt; rw [Nat.add_succ, ih]
<span class="boring">end Hidden
</span></code></pre>
<p>As with <code>cases</code>, we can use the <code>case</code> tactic instead of <code>with</code>.</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>theorem zero_add (n : Nat) : 0 + n = n := by
  induction n
  case zero =&gt; rfl
  case succ n ih =&gt; rw [Nat.add_succ, ih]
<span class="boring">end Hidden
</span></code></pre>
<p>Here are some additional examples:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>open Nat

theorem zero_add (n : Nat) : 0 + n = n := by
  induction n &lt;;&gt; simp [*, add_zero, add_succ]

theorem succ_add (m n : Nat) : succ m + n = succ (m + n) := by
  induction n &lt;;&gt; simp [*, add_zero, add_succ]

theorem add_comm (m n : Nat) : m + n = n + m := by
  induction n &lt;;&gt; simp [*, add_zero, add_succ, succ_add, zero_add]

theorem add_assoc (m n k : Nat) : m + n + k = m + (n + k) := by
  induction k &lt;;&gt; simp [*, add_zero, add_succ]
<span class="boring">end Hidden
</span></code></pre>
<p>The <code>induction</code> tactic also supports user-defined induction principles with
multiple targets (aka major premises).</p>
<pre><code class="language-lean">/-
theorem Nat.mod.inductionOn
      {motive : Nat → Nat → Sort u}
      (x y  : Nat)
      (ind  : ∀ x y, 0 &lt; y ∧ y ≤ x → motive (x - y) y → motive x y)
      (base : ∀ x y, ¬(0 &lt; y ∧ y ≤ x) → motive x y)
      : motive x y :=
-/

example (x : Nat) {y : Nat} (h : y &gt; 0) : x % y &lt; y := by
  induction x, y using Nat.mod.inductionOn with
  | ind x y h₁ ih =&gt;
    rw [Nat.mod_eq_sub_mod h₁.2]
    exact ih h
  | base x y h₁ =&gt;
     have : ¬ 0 &lt; y ∨ ¬ y ≤ x := Iff.mp (Decidable.not_and_iff_or_not ..) h₁
     match this with
     | Or.inl h₁ =&gt; exact absurd h h₁
     | Or.inr h₁ =&gt;
       have hgt : y &gt; x := Nat.gt_of_not_le h₁
       rw [← Nat.mod_eq_of_lt hgt] at hgt
       assumption
</code></pre>
<p>You can use the <code>match</code> notation in tactics too:</p>
<pre><code class="language-lean">example : p ∨ q → q ∨ p := by
  intro h
  match h with
  | Or.inl _  =&gt; apply Or.inr; assumption
  | Or.inr h2 =&gt; apply Or.inl; exact h2
</code></pre>
<p>As a convenience, pattern-matching has been integrated into tactics such as <code>intro</code> and <code>funext</code>.</p>
<pre><code class="language-lean">example : s ∧ q ∧ r → p ∧ r → q ∧ p := by
  intro ⟨_, ⟨hq, _⟩⟩ ⟨hp, _⟩
  exact ⟨hq, hp⟩

example :
    (fun (x : Nat × Nat) (y : Nat × Nat) =&gt; x.1 + y.2)
    =
    (fun (x : Nat × Nat) (z : Nat × Nat) =&gt; z.2 + x.1) := by
  funext (a, b) (c, d)
  show a + d = d + a
  rw [Nat.add_comm]
</code></pre>
<p>We close this section with one last tactic that is designed to
facilitate working with inductive types, namely, the <code>injection</code>
tactic. By design, the elements of an inductive type are freely
generated, which is to say, the constructors are injective and have
disjoint ranges. The <code>injection</code> tactic is designed to make use of
this fact:</p>
<pre><code class="language-lean">open Nat

example (m n k : Nat) (h : succ (succ m) = succ (succ n))
        : n + k = m + k := by
  injection h with h'
  injection h' with h''
  rw [h'']
</code></pre>
<p>The first instance of the tactic adds <code>h' : succ m = succ n</code> to the
context, and the second adds <code>h'' : m = n</code>.</p>
<p>The <code>injection</code> tactic also detects contradictions that arise when different constructors
are set equal to one another, and uses them to close the goal.</p>
<pre><code class="language-lean">open Nat


example (m n : Nat) (h : succ m = 0) : n = n + 7 := by
  injection h

example (m n : Nat) (h : succ m = 0) : n = n + 7 := by
  contradiction

example (h : 7 = 4) : False := by
  contradiction
</code></pre>
<p>As the second example shows, the <code>contradiction</code> tactic also detects contradictions of this form.</p>
<h2><a class="header" href="#inductive-families" id="inductive-families">Inductive Families</a></h2>
<p>We are almost done describing the full range of inductive definitions
accepted by Lean. So far, you have seen that Lean allows you to
introduce inductive types with any number of recursive
constructors. In fact, a single inductive definition can introduce an
indexed <em>family</em> of inductive types, in a manner we now describe.</p>
<p>An inductive family is an indexed family of types defined by a
simultaneous induction of the following form:</p>
<pre><code>inductive foo : ... → Sort u where
  | constructor₁ : ... → foo ...
  | constructor₂ : ... → foo ...
  ...
  | constructorₙ : ... → foo ...
</code></pre>
<p>In contrast to ordinary inductive definition, which constructs an
element of some <code>Sort u</code>, the more general version constructs a
function <code>... → Sort u</code>, where &quot;<code>...</code>&quot; denotes a sequence of
argument types, also known as <em>indices</em>. Each constructor then
constructs an element of some member of the family. One example is the
definition of <code>Vector α n</code>, the type of vectors of elements of <code>α</code>
of length <code>n</code>:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>inductive Vector (α : Type u) : Nat → Type u where
  | nil  : Vector α 0
  | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
<span class="boring">end Hidden
</span></code></pre>
<p>Notice that the <code>cons</code> constructor takes an element of
<code>Vector α n</code> and returns an element of <code>Vector α (n+1)</code>, thereby using an
element of one member of the family to build an element of another.</p>
<p>A more exotic example is given by the definition of the equality type in Lean:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>inductive Eq {α : Sort u} (a : α) : α → Prop where
  | refl {} : Eq a a
<span class="boring">end Hidden
</span></code></pre>
<p>For each fixed <code>α : Sort u</code> and <code>a : α</code>, this definition
constructs a family of types <code>Eq a x</code>, indexed by <code>x : α</code>.
Notably, however, there is only one constructor, <code>refl</code>, which
is an element of <code>Eq a a</code>, and the curly braces after the
constructor tell Lean to make the argument to <code>refl</code>
explicit. Intuitively, the only way to construct a proof of <code>Eq a x</code>
is to use reflexivity, in the case where <code>x</code> is <code>a</code>.
Note that <code>Eq a a</code> is the only inhabited type in the family of types
<code>Eq a x</code>. The elimination principle generated by Lean is as follows:</p>
<pre><code class="language-lean">universe u v

#check (@Eq.rec : {α : Sort u} → {a : α} → {motive : (x : α) → a = x → Sort v}
                  → motive a rfl → {b : α} → (h : a = b) → motive b h)
</code></pre>
<p>It is a remarkable fact that all the basic axioms for equality follow
from the constructor, <code>refl</code>, and the eliminator, <code>Eq.rec</code>. The
definition of equality is atypical, however; see the discussion in the
next section.</p>
<p>The recursor <code>Eq.rec</code> is also used to define substitution:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
  Eq.rec (motive := fun x _ =&gt; p x) h₂ h₁
<span class="boring">end Hidden
</span></code></pre>
<p>You can also define <code>subst</code> using <code>match</code>.</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
  match h₁ with
  | rfl =&gt; h₂
<span class="boring">end Hidden
</span></code></pre>
<p>Actually, Lean compiles the <code>match</code> expressions using a definition based on
<code>Eq.rec</code>.</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>theorem subst {α : Type u} {a b : α} {p : α → Prop} (h₁ : Eq a b) (h₂ : p a) : p b :=
  match h₁ with
  | rfl =&gt; h₂

set_option pp.all true
#print subst
  -- ... subst.match_1 ...
#print subst.match_1
  -- ... Eq.casesOn ...
#print Eq.casesOn
  -- ... Eq.rec ...
<span class="boring">end Hidden
</span></code></pre>
<p>Using the recursor or <code>match</code> with <code>h₁ : a = b</code>, we may assume <code>a</code> and <code>b</code> are the same,
in which case, <code>p b</code> and <code>p a</code> are the same.</p>
<p>It is not hard to prove that <code>Eq</code> is symmetric and transitive.
In the following example, we prove <code>symm</code> and leave as exercise the theorems <code>trans</code> and <code>congr</code> (congruence).</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>theorem symm {α : Type u} {a b : α} (h : Eq a b) : Eq b a :=
  match h with
  | rfl =&gt; rfl

theorem trans {α : Type u} {a b c : α} (h₁ : Eq a b) (h₂ : Eq b c) : Eq a c :=
  sorry

theorem congr {α β : Type u} {a b : α} (f : α → β) (h : Eq a b) : Eq (f a) (f b) :=
  sorry
<span class="boring">end Hidden
</span></code></pre>
<p>In the type theory literature, there are further generalizations of
inductive definitions, for example, the principles of
<em>induction-recursion</em> and <em>induction-induction</em>. These are not
supported by Lean.</p>
<h2><a class="header" href="#axiomatic-details" id="axiomatic-details">Axiomatic Details</a></h2>
<p>We have described inductive types and their syntax through
examples. This section provides additional information for those
interested in the axiomatic foundations.</p>
<p>We have seen that the constructor to an inductive type takes
<em>parameters</em> --- intuitively, the arguments that remain fixed
throughout the inductive construction --- and <em>indices</em>, the arguments
parameterizing the family of types that is simultaneously under
construction. Each constructor should have a type, where the
argument types are built up from previously defined types, the
parameter and index types, and the inductive family currently being
defined. The requirement is that if the latter is present at all, it
occurs only <em>strictly positively</em>. This means simply that any argument
to the constructor in which it occurs is a dependent arrow type in which the
inductive type under definition occurs only as the resulting type,
where the indices are given in terms of constants and previous
arguments.</p>
<p>Since an inductive type lives in <code>Sort u</code> for some <code>u</code>, it is
reasonable to ask <em>which</em> universe levels <code>u</code> can be instantiated
to. Each constructor <code>c</code> in the definition of a family <code>C</code> of
inductive types is of the form</p>
<pre><code>  c : (a : α) → (b : β[a]) → C a p[a,b]
</code></pre>
<p>where <code>a</code> is a sequence of data type parameters, <code>b</code> is the
sequence of arguments to the constructors, and <code>p[a, b]</code> are the
indices, which determine which element of the inductive family the
construction inhabits. (Note that this description is somewhat
misleading, in that the arguments to the constructor can appear in any
order as long as the dependencies make sense.) The constraints on the
universe level of <code>C</code> fall into two cases, depending on whether or
not the inductive type is specified to land in <code>Prop</code> (that is,
<code>Sort 0</code>).</p>
<p>Let us first consider the case where the inductive type is <em>not</em>
specified to land in <code>Prop</code>. Then the universe level <code>u</code> is
constrained to satisfy the following:</p>
<blockquote>
<p>For each constructor <code>c</code> as above, and each <code>βk[a]</code> in the sequence <code>β[a]</code>, if <code>βk[a] : Sort v</code>, we have <code>u</code> ≥ <code>v</code>.</p>
</blockquote>
<p>In other words, the universe level <code>u</code> is required to be at least as
large as the universe level of each type that represents an argument
to a constructor.</p>
<p>When the inductive type is specified to land in <code>Prop</code>, there are no
constraints on the universe levels of the constructor arguments. But
these universe levels do have a bearing on the elimination
rule. Generally speaking, for an inductive type in <code>Prop</code>, the
motive of the elimination rule is required to be in <code>Prop</code>.</p>
<p>There is an exception to this last rule: we are allowed to eliminate
from an inductively defined <code>Prop</code> to an arbitrary <code>Sort</code> when
there is only one constructor and each constructor argument is either
in <code>Prop</code> or an index. The intuition is that in this case the
elimination does not make use of any information that is not already
given by the mere fact that the type of argument is inhabited. This
special case is known as <em>singleton elimination</em>.</p>
<p>We have already seen singleton elimination at play in applications of
<code>Eq.rec</code>, the eliminator for the inductively defined equality
type. We can use an element <code>h : Eq a b</code> to cast an element
<code>t' : p a</code> to <code>p b</code> even when <code>p a</code> and <code>p b</code> are arbitrary types,
because the cast does not produce new data; it only reinterprets the
data we already have. Singleton elimination is also used with
heterogeneous equality and well-founded recursion, which will be
discussed in a later chapter.</p>
<h2><a class="header" href="#a-name_mutual_and_nested_inductive_typesamutual-and-nested-inductive-types" id="a-name_mutual_and_nested_inductive_typesamutual-and-nested-inductive-types"><a name="_mutual_and_nested_inductive_types"></a>Mutual and Nested Inductive Types</a></h2>
<p>We now consider two generalizations of inductive types that are often
useful, which Lean supports by &quot;compiling&quot; them down to the more
primitive kinds of inductive types described above. In other words,
Lean parses the more general definitions, defines auxiliary inductive
types based on them, and then uses the auxiliary types to define the
ones we really want. Lean's equation compiler, described in the next
chapter, is needed to make use of these types
effectively. Nonetheless, it makes sense to describe the declarations
here, because they are straightforward variations on ordinary
inductive definitions.</p>
<p>First, Lean supports <em>mutually defined</em> inductive types. The idea is
that we can define two (or more) inductive types at the same time,
where each one refers to the other(s).</p>
<pre><code class="language-lean">mutual
  inductive Even : Nat → Prop where
    | even_zero : Even 0
    | even_succ : (n : Nat) → Odd n → Even (n + 1)

  inductive Odd : Nat → Prop where
    | odd_succ : (n : Nat) → Even n → Odd (n + 1)
end
</code></pre>
<p>In this example, two types are defined simultaneously: a natural
number <code>n</code> is <code>Even</code> if it is <code>0</code> or one more than an <code>Odd</code>
number, and <code>Odd</code> if it is one more than an <code>Even</code> number.
In the exercises below, you are asked to spell out the details.</p>
<p>A mutual inductive definition can also be used to define the notation
of a finite tree with nodes labelled by elements of <code>α</code>:</p>
<pre><code class="language-lean">mutual
    inductive Tree (α : Type u) where
      | node : α → TreeList α → Tree α

    inductive TreeList (α : Type u) where
      | nil  : TreeList α
      | cons : Tree α → TreeList α → TreeList α
end
</code></pre>
<p>With this definition, one can construct an element of <code>Tree α</code> by
giving an element of <code>α</code> together with a list of subtrees, possibly
empty. The list of subtrees is represented by the type <code>TreeList α</code>,
which is defined to be either the empty list, <code>nil</code>, or the
<code>cons</code> of a tree and an element of <code>TreeList α</code>.</p>
<p>This definition is inconvenient to work with, however. It would be
much nicer if the list of subtrees were given by the type
<code>List (Tree α)</code>, especially since Lean's library contains a number of functions
and theorems for working with lists. One can show that the type
<code>TreeList α</code> is <em>isomorphic</em> to <code>List (Tree α)</code>, but translating
results back and forth along this isomorphism is tedious.</p>
<p>In fact, Lean allows us to define the inductive type we really want:</p>
<pre><code class="language-lean">inductive Tree (α : Type u) where
  | mk : α → List (Tree α) → Tree α
</code></pre>
<p>This is known as a <em>nested</em> inductive type. It falls outside the
strict specification of an inductive type given in the last section
because <code>Tree</code> does not occur strictly positively among the
arguments to <code>mk</code>, but, rather, nested inside the <code>List</code> type
constructor. Lean then automatically builds the
isomorphism between <code>TreeList α</code> and <code>List (Tree α)</code> in its kernel,
and defines the constructors for <code>Tree</code> in terms of the isomorphism.</p>
<h2><a class="header" href="#exercises" id="exercises">Exercises</a></h2>
<ol>
<li>
<p>Try defining other operations on the natural numbers, such as
multiplication, the predecessor function (with <code>pred 0 = 0</code>),
truncated subtraction (with <code>n - m = 0</code> when <code>m</code> is greater
than or equal to <code>n</code>), and exponentiation. Then try proving some
of their basic properties, building on the theorems we have already
proved.</p>
<p>Since many of these are already defined in Lean's core library, you
should work within a namespace named <code>Hidden</code>, or something like
that, in order to avoid name clashes.</p>
</li>
<li>
<p>Define some operations on lists, like a <code>length</code> function or the
<code>reverse</code> function. Prove some properties, such as the following:</p>
<p>a. <code>length (s ++ t) = length s + length t</code></p>
<p>b. <code>length (reverse t) = length t</code></p>
<p>c. <code>reverse (reverse t) = t</code></p>
</li>
<li>
<p>Define an inductive data type consisting of terms built up from the following constructors:</p>
<ul>
<li><code>const n</code>, a constant denoting the natural number <code>n</code></li>
<li><code>var n</code>, a variable, numbered <code>n</code></li>
<li><code>plus s t</code>, denoting the sum of <code>s</code> and <code>t</code></li>
<li><code>times s t</code>, denoting the product of <code>s</code> and <code>t</code></li>
</ul>
<p>Recursively define a function that evaluates any such term with respect to an assignment of values to the variables.</p>
</li>
<li>
<p>Similarly, define the type of propositional formulas, as well as
functions on the type of such formulas: an evaluation function,
functions that measure the complexity of a formula, and a function
that substitutes another formula for a given variable.</p>
</li>
</ol>
<h1><a class="header" href="#induction-and-recursion" id="induction-and-recursion">Induction and Recursion</a></h1>
<p>In the previous chapter, we saw that inductive definitions provide a
powerful means of introducing new types in Lean. Moreover, the
constructors and the recursors provide the only means of defining
functions on these types. By the propositions-as-types correspondence,
this means that induction is the fundamental method of proof.</p>
<p>Lean provides natural ways of defining recursive functions, performing
pattern matching, and writing inductive proofs. It allows you to
define a function by specifying equations that it should satisfy, and
it allows you to prove a theorem by specifying how to handle various
cases that can arise. Behind the scenes, these descriptions are
&quot;compiled&quot; down to primitive recursors, using a procedure that we
refer to as the &quot;equation compiler.&quot; The equation compiler is not part
of the trusted code base; its output consists of terms that are
checked independently by the kernel.</p>
<h2><a class="header" href="#pattern-matching" id="pattern-matching">Pattern Matching</a></h2>
<p>The interpretation of schematic patterns is the first step of the
compilation process. We have seen that the <code>casesOn</code> recursor can
be used to define functions and prove theorems by cases, according to
the constructors involved in an inductively defined type. But
complicated definitions may use several nested <code>casesOn</code>
applications, and may be hard to read and understand. Pattern matching
provides an approach that is more convenient, and familiar to users of
functional programming languages.</p>
<p>Consider the inductively defined type of natural numbers. Every
natural number is either <code>zero</code> or <code>succ x</code>, and so you can define
a function from the natural numbers to an arbitrary type by specifying
a value in each of those cases:</p>
<pre><code class="language-lean">open Nat

def sub1 : Nat → Nat
  | zero   =&gt; zero
  | succ x =&gt; x

def isZero : Nat → Bool
  | zero   =&gt; true
  | succ x =&gt; false
</code></pre>
<p>The equations used to define these function hold definitionally:</p>
<pre><code class="language-lean"><span class="boring">open Nat
</span><span class="boring">def sub1 : Nat → Nat
</span><span class="boring">  | zero   =&gt; zero
</span><span class="boring">  | succ x =&gt; x
</span><span class="boring">def isZero : Nat → Bool
</span><span class="boring">  | zero   =&gt; true
</span><span class="boring">  | succ x =&gt; false
</span>example : sub1 0 = 0 := rfl
example (x : Nat) : sub1 (succ x) = x := rfl

example : isZero 0 = true := rfl
example (x : Nat) : isZero (succ x) = false := rfl

example : sub1 7 = 6 := rfl
example (x : Nat) : isZero (x + 3) = false := rfl
</code></pre>
<p>Instead of <code>zero</code> and <code>succ</code>, we can use more familiar notation:</p>
<pre><code class="language-lean">def sub1 : Nat → Nat
  | 0   =&gt; 0
  | x+1 =&gt; x

def isZero : Nat → Bool
  | 0   =&gt; true
  | x+1 =&gt; false
</code></pre>
<p>Because addition and the zero notation have been assigned the
<code>[matchPattern]</code> attribute, they can be used in pattern matching. Lean
simply normalizes these expressions until the constructors <code>zero</code>
and <code>succ</code> are exposed.</p>
<p>Pattern matching works with any inductive type, such as products and option types:</p>
<pre><code class="language-lean">def swap : α × β → β × α
  | (a, b) =&gt; (b, a)

def foo : Nat × Nat → Nat
  | (m, n) =&gt; m + n

def bar : Option Nat → Nat
  | some n =&gt; n + 1
  | none   =&gt; 0
</code></pre>
<p>Here we use it not only to define a function, but also to carry out a
proof by cases:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>def not : Bool → Bool
  | true  =&gt; false
  | false =&gt; true

theorem not_not : ∀ (b : Bool), not (not b) = b
  | true  =&gt; rfl  -- proof that not (not true) = true
  | false =&gt; rfl  -- proof that not (not false) = false
<span class="boring">end Hidden
</span></code></pre>
<p>Pattern matching can also be used to destruct inductively defined propositions:</p>
<pre><code class="language-lean">example (p q : Prop) : p ∧ q → q ∧ p
  | And.intro h₁ h₂ =&gt; And.intro h₂ h₁

example (p q : Prop) : p ∨ q → q ∨ p
  | Or.inl hp =&gt; Or.inr hp
  | Or.inr hq =&gt; Or.inl hq
</code></pre>
<p>This provides a compact way of unpacking hypotheses that make use of logical connectives.</p>
<p>In all these examples, pattern matching was used to carry out a single
case distinction. More interestingly, patterns can involve nested
constructors, as in the following examples.</p>
<pre><code class="language-lean">def sub2 : Nat → Nat
  | 0   =&gt; 0
  | 1   =&gt; 0
  | x+2 =&gt; x
</code></pre>
<p>The equation compiler first splits on cases as to whether the input is
<code>zero</code> or of the form <code>succ x</code>.  It then does a case split on
whether <code>x</code> is of the form <code>zero</code> or <code>succ x</code>.  It determines
the necessary case splits from the patterns that are presented to it,
and raises an error if the patterns fail to exhaust the cases. Once
again, we can use arithmetic notation, as in the version below. In
either case, the defining equations hold definitionally.</p>
<pre><code class="language-lean"><span class="boring">def sub2 : Nat → Nat
</span><span class="boring">  | 0   =&gt; 0
</span><span class="boring">  | 1   =&gt; 0
</span><span class="boring">  | x+2 =&gt; x
</span>example : sub2 0 = 0 := rfl
example : sub2 1 = 0 := rfl
example : sub2 (x+2) = x := rfl

example : sub2 5 = 3 := rfl
</code></pre>
<p>You can write <code>#print sub2</code> to see how the function was compiled to
recursors. (Lean will tell you that <code>sub2</code> has been defined in terms
of an internal auxiliary function, <code>sub2.match_1</code>, but you can print
that out too.) Lean uses these auxiliary functions to compile <code>match</code> expressions.
Actually, the definition above is expanded to</p>
<pre><code class="language-lean">def sub2 : Nat → Nat :=
  fun x =&gt;
    match x with
    | 0   =&gt; 0
    | 1   =&gt; 0
    | x+2 =&gt; x
</code></pre>
<p>Here are some more examples of nested pattern matching:</p>
<pre><code class="language-lean">example (p q : α → Prop)
        : (∃ x, p x ∨ q x) → (∃ x, p x) ∨ (∃ x, q x)
  | Exists.intro x (Or.inl px) =&gt; Or.inl (Exists.intro x px)
  | Exists.intro x (Or.inr qx) =&gt; Or.inr (Exists.intro x qx)

def foo : Nat × Nat → Nat
  | (0, n)     =&gt; 0
  | (m+1, 0)   =&gt; 1
  | (m+1, n+1) =&gt; 2
</code></pre>
<p>The equation compiler can process multiple arguments sequentially. For
example, it would be more natural to define the previous example as a
function of two arguments:</p>
<pre><code class="language-lean">def foo : Nat → Nat → Nat
  | 0,   n   =&gt; 0
  | m+1, 0   =&gt; 1
  | m+1, n+1 =&gt; 2
</code></pre>
<p>Here is another example:</p>
<pre><code class="language-lean">def bar : List Nat → List Nat → Nat
  | [],      []      =&gt; 0
  | a :: as, []      =&gt; a
  | [],      b :: bs =&gt; b
  | a :: as, b :: bs =&gt; a + b
</code></pre>
<p>Note that the patterns are separated by commas.</p>
<p>In each of the following examples, splitting occurs on only the first
argument, even though the others are included among the list of
patterns.</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>def and : Bool → Bool → Bool
  | true,  a =&gt; a
  | false, _ =&gt; false

def or : Bool → Bool → Bool
  | true,  _ =&gt; true
  | false, a =&gt; a

def cond : Bool → α → α → α
  | true,  x, y =&gt; x
  | false, x, y =&gt; y
<span class="boring">end Hidden
</span></code></pre>
<p>Notice also that, when the value of an argument is not needed in the
definition, you can use an underscore instead. This underscore is
known as a <em>wildcard pattern</em>, or an <em>anonymous variable</em>. In contrast
to usage outside the equation compiler, here the underscore does <em>not</em>
indicate an implicit argument. The use of underscores for wildcards is
common in functional programming languages, and so Lean adopts that
notation. <a href="induction_and_recursion.html#wildcards_and_overlapping_patterns">Section wildcards and overlapping patterns</a>
expands on the notion of a wildcard, and <a href="induction_and_recursion.html#inaccessible_terms">Section Inaccessible Patterns</a> explains how
you can use implicit arguments in patterns as well.</p>
<p>As described in <a href="./inductive_types.html">Chapter Inductive Types</a>,
inductive data types can depend on parameters. The following example defines
the <code>tail</code> function using pattern matching. The argument <code>α : Type</code>
is a parameter and occurs before the colon to indicate it does not participate in the pattern matching.
Lean also allows parameters to occur after <code>:</code>, but it cannot pattern match on them.</p>
<pre><code class="language-lean">def tail1 {α : Type u} : List α → List α
  | []      =&gt; []
  | a :: as =&gt; as

def tail2 : {α : Type u} → List α → List α
  | α, []      =&gt; []
  | α, a :: as =&gt; as
</code></pre>
<p>Despite the different placement of the parameter <code>α</code> in these two
examples, in both cases it treated in the same way, in that it does
not participate in a case split.</p>
<p>Lean can also handle more complex forms of pattern matching, in which
arguments to dependent types pose additional constraints on the
various cases. Such examples of <em>dependent pattern matching</em> are
considered in the <a href="induction_and_recursion.html#dependent_pattern_matching">Section Dependent Pattern Matching</a>.</p>
<h2><a class="header" href="#a-namewildcards_and_overlapping_patternsawildcards-and-overlapping-patterns" id="a-namewildcards_and_overlapping_patternsawildcards-and-overlapping-patterns"><a name="wildcards_and_overlapping_patterns"></a>Wildcards and Overlapping Patterns</a></h2>
<p>Consider one of the examples from the last section:</p>
<pre><code class="language-lean">def foo : Nat → Nat → Nat
  | 0,   n   =&gt; 0
  | m+1, 0   =&gt; 1
  | m+1, n+1 =&gt; 2
</code></pre>
<pre><code class="language-lean">def foo : Nat → Nat → Nat
  | 0, n =&gt; 0
  | m, 0 =&gt; 1
  | m, n =&gt; 2
</code></pre>
<p>In the second presentation, the patterns overlap; for example, the
pair of arguments <code>0 0</code> matches all three cases. But Lean handles
the ambiguity by using the first applicable equation, so in this example
the net result is the same. In particular, the following equations hold
definitionally:</p>
<pre><code class="language-lean"><span class="boring">def foo : Nat → Nat → Nat
</span><span class="boring">  | 0, n =&gt; 0
</span><span class="boring">  | m, 0 =&gt; 1
</span><span class="boring">  | m, n =&gt; 2
</span>example : foo 0     0     = 0 := rfl
example : foo 0     (n+1) = 0 := rfl
example : foo (m+1) 0     = 1 := rfl
example : foo (m+1) (n+1) = 2 := rfl
</code></pre>
<p>Since the values of <code>m</code> and <code>n</code> are not needed, we can just as well use wildcard patterns instead.</p>
<pre><code class="language-lean">def foo : Nat → Nat → Nat
  | 0, _ =&gt; 0
  | _, 0 =&gt; 1
  | _, _ =&gt; 2
</code></pre>
<p>You can check that this definition of <code>foo</code> satisfies the same
definitional identities as before.</p>
<p>Some functional programming languages support <em>incomplete
patterns</em>. In these languages, the interpreter produces an exception
or returns an arbitrary value for incomplete cases. We can simulate
the arbitrary value approach using the <code>Inhabited</code> type
class. Roughly, an element of <code>Inhabited α</code> is a witness to the fact
that there is an element of <code>α</code>; in the <a href="./type_classes.html">Chapter Type Classes</a>
we will see that Lean can be instructed that suitable
base types are inhabited, and can automatically infer that other
constructed types are inhabited. On this basis, the
standard library provides an arbitrary element, <code>arbitrary</code>, of
any inhabited type.</p>
<p>We can also use the type <code>Option α</code> to simulate incomplete patterns.
The idea is to return <code>some a</code> for the provided patterns, and use
<code>none</code> for the incomplete cases. The following example demonstrates
both approaches.</p>
<pre><code class="language-lean">def f1 : Nat → Nat → Nat
  | 0, _  =&gt; 1
  | _, 0  =&gt; 2
  | _, _  =&gt; arbitrary  -- the &quot;incomplete&quot; case

example : f1 0     0     = 1 := rfl
example : f1 0     (a+1) = 1 := rfl
example : f1 (a+1) 0     = 2 := rfl
example : f1 (a+1) (b+1) = arbitrary := rfl

def f2 : Nat → Nat → Option Nat
  | 0, _  =&gt; some 1
  | _, 0  =&gt; some 2
  | _, _  =&gt; none     -- the &quot;incomplete&quot; case

example : f2 0     0     = some 1 := rfl
example : f2 0     (a+1) = some 1 := rfl
example : f2 (a+1) 0     = some 2 := rfl
example : f2 (a+1) (b+1) = none   := rfl
</code></pre>
<p>The equation compiler is clever. If you leave out any of the cases in
the following definition, the error message will let you know what has
not been covered.</p>
<pre><code class="language-lean">def bar : Nat → List Nat → Bool → Nat
  | 0,   _,      false =&gt; 0
  | 0,   b :: _, _     =&gt; b
  | 0,   [],     true  =&gt; 7
  | a+1, [],     false =&gt; a
  | a+1, [],     true  =&gt; a + 1
  | a+1, b :: _, _     =&gt; a + b
</code></pre>
<p>It will also use an &quot;if ... then ... else&quot; instead of a <code>casesOn</code> in appropriate situations.</p>
<pre><code class="language-lean">def foo : Char → Nat
  | 'A' =&gt; 1
  | 'B' =&gt; 2
  | _   =&gt; 3

#print foo.match_1
</code></pre>
<h2><a class="header" href="#a-namestructural_recursion_and_inductionastructural-recursion-and-induction" id="a-namestructural_recursion_and_inductionastructural-recursion-and-induction"><a name="structural_recursion_and_induction"></a>Structural Recursion and Induction</a></h2>
<p>What makes the equation compiler powerful is that it also supports
recursive definitions. In the next three sections, we will describe,
respectively:</p>
<ul>
<li>structurally recursive definitions</li>
<li>well-founded recursive definitions</li>
<li>mutually recursive definitions</li>
</ul>
<p>Generally speaking, the equation compiler processes input of the following form:</p>
<pre><code>def foo (a : α) : (b : β) → γ
  | [patterns₁] =&gt; t₁
  ...
  | [patternsₙ] =&gt; tₙ
</code></pre>
<p>Here <code>(a : α)</code> is a sequence of parameters, <code>(b : β)</code> is the
sequence of arguments on which pattern matching takes place, and <code>γ</code>
is any type, which can depend on <code>a</code> and <code>b</code>. Each line should
contain the same number of patterns, one for each element of <code>β</code>. As we
have seen, a pattern is either a variable, a constructor applied to
other patterns, or an expression that normalizes to something of that
form (where the non-constructors are marked with the <code>[matchPattern]</code>
attribute). The appearances of constructors prompt case splits, with
the arguments to the constructors represented by the given
variables. In <a href="induction_and_recursion.html#dependent_pattern_matching">Section Dependent Pattern Matching</a>,
we will see that it is sometimes necessary to include explicit terms in patterns that
are needed to make an expression type check, though they do not play a
role in pattern matching. These are called &quot;inaccessible patterns&quot; for
that reason. But we will not need to use such inaccessible patterns
before <a href="induction_and_recursion.html#dependent_pattern_matching">Section Dependent Pattern Matching</a>.</p>
<p>As we saw in the last section, the terms <code>t₁, ..., tₙ</code> can make use
of any of the parameters <code>a</code>, as well as any of the variables that
are introduced in the corresponding patterns. What makes recursion and
induction possible is that they can also involve recursive calls to
<code>foo</code>. In this section, we will deal with <em>structural recursion</em>, in
which the arguments to <code>foo</code> occurring on the right-hand side of the
<code>:=</code> are subterms of the patterns on the left-hand side. The idea is
that they are structurally smaller, and hence appear in the inductive
type at an earlier stage. Here are some examples of structural
recursion from the last chapter, now defined using the equation
compiler:</p>
<pre><code class="language-lean">open Nat
def add : Nat → Nat → Nat
  | m, zero   =&gt; m
  | m, succ n =&gt; succ (add m n)

theorem add_zero (m : Nat)   : add m zero = m := rfl
theorem add_succ (m n : Nat) : add m (succ n) = succ (add m n) := rfl

theorem zero_add : ∀ n, add zero n = n
  | zero   =&gt; rfl
  | succ n =&gt; congrArg succ (zero_add n)

def mul : Nat → Nat → Nat
  | n, zero   =&gt; zero
  | n, succ m =&gt; add (mul n m) n
</code></pre>
<p>The proof of <code>zero_add</code> makes it clear that proof by induction is
really a form of recursion in Lean.</p>
<p>The example above shows that the defining equations for <code>add</code> hold
definitionally, and the same is true of <code>mul</code>. The equation compiler
tries to ensure that this holds whenever possible, as is the case with
straightforward structural induction. In other situations, however,
reductions hold only <em>propositionally</em>, which is to say, they are
equational theorems that must be applied explicitly. The equation
compiler generates such theorems internally. They are not meant to be
used directly by the user; rather, the <code>simp</code> tactic
is configured to use them when necessary. Thus both of the following
proofs of <code>zero_add</code> work:</p>
<pre><code class="language-lean">open Nat
<span class="boring">def add : Nat → Nat → Nat
</span><span class="boring">  | m, zero   =&gt; m
</span><span class="boring">  | m, succ n =&gt; succ (add m n)
</span>theorem zero_add : ∀ n, add zero n = n
  | zero   =&gt; by simp [add]
  | succ n =&gt; by simp [add, zero_add]
</code></pre>
<!--
In fact, because in this case the defining equations hold
definitionally, we can use `dsimp`, the simplifier that uses
definitional reductions only, to carry out the first step.

.. code-block:: lean

    namespace hidden

    inductive nat : Type
    | zero : nat
    | succ : nat → nat

    namespace nat

    def add : nat → nat → nat
    | m zero     := m
    | m (succ n) := succ (add m n)

    local infix ` + ` := add

    -- BEGIN
    theorem zero_add : ∀ n, zero + n = n
    | zero     := by dsimp [add]; reflexivity
    | (succ n) := by dsimp [add]; rw [zero_add n]
    -- END

    end nat
    end hidden
-->
<p>As with definition by pattern matching, parameters to a structural
recursion or induction may appear before the colon. Such parameters
are simply added to the local context before the definition is
processed. For example, the definition of addition may also be written
as follows:</p>
<pre><code class="language-lean">open Nat
def add (m : Nat) : Nat → Nat
  | zero   =&gt; m
  | succ n =&gt; succ (add m n)
</code></pre>
<p>You can also write the example above using <code>match</code>.</p>
<pre><code class="language-lean">open Nat
def add (m n : Nat) : Nat :=
  match n with
  | zero   =&gt; m
  | succ n =&gt; succ (add m n)
</code></pre>
<p>A more interesting example of structural recursion is given by the Fibonacci function <code>fib</code>.</p>
<pre><code class="language-lean">def fib : Nat → Nat
  | 0   =&gt; 1
  | 1   =&gt; 1
  | n+2 =&gt; fib (n+1) + fib n

example : fib 0 = 1 := rfl
example : fib 1 = 1 := rfl
example : fib (n + 2) = fib (n + 1) + fib n := rfl

example : fib 7 = 21 := rfl
</code></pre>
<p>Here, the value of the <code>fib</code> function at <code>n + 2</code> (which is
definitionally equal to <code>succ (succ n)</code>) is defined in terms of the
values at <code>n + 1</code> (which is definitionally equivalent to <code>succ n</code>)
and the value at <code>n</code>. This is a notoriously inefficient way of
computing the fibonacci function, however, with an execution time that
is exponential in <code>n</code>. Here is a better way:</p>
<pre><code class="language-lean">def fibFast (n : Nat) : Nat :=
  (loop n).1
where
  loop : Nat → Nat × Nat
    | 0   =&gt; (0, 1)
    | n+1 =&gt; let p := loop n; (p.2, p.1 + p.2)

#eval fibFast 100
</code></pre>
<p>Here is the same definition using a <code>let rec</code> instead of a <code>where</code>.</p>
<pre><code class="language-lean">def fibFast (n : Nat) : Nat :=
  let rec loop : Nat → Nat × Nat
    | 0   =&gt; (0, 1)
    | n+1 =&gt; let p := loop n; (p.2, p.1 + p.2)
  (loop n).1
</code></pre>
<p>In both cases, Lean generates the auxiliary function <code>fibFast.loop</code>.</p>
<p>To handle structural recursion, the equation compiler uses
<em>course-of-values</em> recursion, using constants <code>below</code> and <code>brecOn</code>
that are automatically generated with each inductively defined
type. You can get a sense of how it works by looking at the types of
<code>Nat.below</code> and <code>Nat.brecOn</code>:</p>
<pre><code class="language-lean">variable (C : Nat → Type u)

#check (@Nat.below C : Nat → Type u)

#reduce @Nat.below C (3 : Nat)

#check (@Nat.brecOn C : (n : Nat) → ((n : Nat) → @Nat.below C n → C n) → C n)
</code></pre>
<p>The type <code>@Nat.below C (3 : nat)</code> is a data structure that stores elements of <code>C 0</code>, <code>C 1</code>, and <code>C 2</code>.
The course-of-values recursion is implemented by <code>Nat.brecOn</code>. It enables us to define the value of a dependent
function of type <code>(n : Nat) → C n</code> at a particular input <code>n</code> in terms of all the previous values of the function,
presented as an element of <code>@Nat.below C n</code>.</p>
<p>The use of course-of-values recursion is one of the techniques the equation compiler uses to justify to
the Lean kernel that a function terminates. It does not affect the code generator which compiles recursive
functions as other functional programming language compilers. Recall that <code>#eval fib &lt;n&gt;</code> is exponential on <code>&lt;n&gt;</code>.
On the other hand, <code>#reduce fib &lt;n&gt;</code> is efficient because it uses the definition sent to the kernel that
is based on the <code>brecOn</code> construction.</p>
<pre><code class="language-lean">def fib : Nat → Nat
  | 0   =&gt; 1
  | 1   =&gt; 1
  | n+2 =&gt; fib (n+1) + fib n

-- #eval fib 50 -- slow
#reduce fib 50  -- fast

#print fib
</code></pre>
<p>Another good example of a recursive definition is the list <code>append</code> function.</p>
<pre><code class="language-lean">def append : List α → List α → List α
  | [],    bs =&gt; bs
  | a::as, bs =&gt; a :: append as bs

example : append [1, 2, 3] [4, 5] = [1, 2, 3, 4, 5] := rfl
</code></pre>
<p>Here is another: it adds elements of the first list to elements of the second list, until one of the two lists runs out.</p>
<pre><code class="language-lean">def listAdd [Add α] : List α → List α → List α
  | [],      _       =&gt; []
  | _,       []      =&gt; []
  | a :: as, b :: bs =&gt; (a + b) :: listAdd as bs

#eval listAdd [1, 2, 3] [4, 5, 6, 6, 9, 10]
-- [5, 7, 9]
</code></pre>
<p>You are encouraged to experiment with similar examples in the exercises below.</p>
<h2><a class="header" href="#a-name_well_founded_recursion_and_inductiona-well-founded-recursion-and-induction" id="a-name_well_founded_recursion_and_inductiona-well-founded-recursion-and-induction"><a name="_well_founded_recursion_and_induction:"></a> Well-Founded Recursion and Induction</a></h2>
<p>Dependent type theory is powerful enough to encode and justify
well-founded recursion. Let us start with the logical background that
is needed to understand how it works.</p>
<p>Lean's standard library defines two predicates, <code>Acc r a</code> and
<code>WellFounded r</code>, where <code>r</code> is a binary relation on a type <code>α</code>,
and <code>a</code> is an element of type <code>α</code>.</p>
<pre><code class="language-lean">variable (α : Sort u)
variable (r : α → α → Prop)

#check (Acc r : α → Prop)
#check (WellFounded r : Prop)
</code></pre>
<p>The first, <code>Acc</code>, is an inductively defined predicate. According to
its definition, <code>Acc r x</code> is equivalent to
<code>∀ y, r y x → Acc r y</code>. If you think of <code>r y x</code> as denoting a kind of order relation
<code>y ≺ x</code>, then <code>Acc r x</code> says that <code>x</code> is accessible from below,
in the sense that all its predecessors are accessible. In particular,
if <code>x</code> has no predecessors, it is accessible. Given any type <code>α</code>,
we should be able to assign a value to each accessible element of
<code>α</code>, recursively, by assigning values to all its predecessors first.</p>
<p>The statement that <code>r</code> is well founded, denoted <code>WellFounded r</code>,
is exactly the statement that every element of the type is
accessible. By the above considerations, if <code>r</code> is a well-founded
relation on a type <code>α</code>, we should have a principle of well-founded
recursion on <code>α</code>, with respect to the relation <code>r</code>. And, indeed,
we do: the standard library defines <code>WellFounded.fix</code>, which serves
exactly that purpose.</p>
<pre><code class="language-lean">set_option codegen false
def f {α : Sort u}
      (r : α → α → Prop)
      (h : WellFounded r)
      (C : α → Sort v)
      (F : (x : α) → ((y : α) → r y x → C y) → C x)
      : (x : α) → C x := WellFounded.fix h F
</code></pre>
<p>There is a long cast of characters here, but the first block we have
already seen: the type, <code>α</code>, the relation, <code>r</code>, and the
assumption, <code>h</code>, that <code>r</code> is well founded. The variable <code>C</code>
represents the motive of the recursive definition: for each element
<code>x : α</code>, we would like to construct an element of <code>C x</code>. The
function <code>F</code> provides the inductive recipe for doing that: it tells
us how to construct an element <code>C x</code>, given elements of <code>C y</code> for
each predecessor <code>y</code> of <code>x</code>.</p>
<p>Note that <code>WellFounded.fix</code> works equally well as an induction
principle. It says that if <code>≺</code> is well founded and you want to prove
<code>∀ x, C x</code>, it suffices to show that for an arbitrary <code>x</code>, if we
have <code>∀ y ≺ x, C y</code>, then we have <code>C x</code>.</p>
<p>In the example above we set the option <code>codegen</code> to false because the code
generator currently does not support <code>WellFounded.fix</code>. The function
<code>WellFounded.fix</code> is another tool Lean uses to justify that a function
terminates.</p>
<p>Lean knows that the usual order <code>&lt;</code> on the natural numbers is well
founded. It also knows a number of ways of constructing new well
founded orders from others, for example, using lexicographic order.</p>
<p>Here is essentially the definition of division on the natural numbers that is found in the standard library.</p>
<pre><code class="language-lean">open Nat

theorem div_rec_lemma {x y : Nat} : 0 &lt; y ∧ y ≤ x → x - y &lt; x :=
  fun h =&gt; sub_lt (Nat.lt_of_lt_of_le h.left h.right) h.left

def div.F (x : Nat) (f : (x₁ : Nat) → x₁ &lt; x → Nat → Nat) (y : Nat) : Nat :=
  if h : 0 &lt; y ∧ y ≤ x then
    f (x - y) (div_rec_lemma h) y + 1
  else
    zero

set_option codegen false
def div := WellFounded.fix (measure id).wf div.F

#reduce div 8 2 -- 4
</code></pre>
<p>The definition is somewhat inscrutable. Here the recursion is on
<code>x</code>, and <code>div.F x f : Nat → Nat</code> returns the &quot;divide by <code>y</code>&quot;
function for that fixed <code>x</code>. You have to remember that the second
argument to <code>div.F</code>, the recipe for the recursion, is a function
that is supposed to return the divide by <code>y</code> function for all values
<code>x₁</code> smaller than <code>x</code>.</p>
<p>The equation compiler is designed to make definitions like this more
convenient. It accepts the following:</p>
<p><strong>TODO: waiting for well-founded support in Lean 4</strong></p>
<p>.. code-block:: lean</p>
<pre><code>namespace hidden
open nat

-- BEGIN
def div : ℕ → ℕ → ℕ
| x y :=
  if h : 0 &lt; y ∧ y ≤ x then
    have x - y &lt; x,
      from sub_lt (lt_of_lt_of_le h.left h.right) h.left,
    div (x - y) y + 1
  else
    0
-- END

end hidden
</code></pre>
<p>When the equation compiler encounters a recursive definition, it first
tries structural recursion, and only when that fails, does it fall
back on well-founded recursion. In this case, detecting the
possibility of well-founded recursion on the natural numbers, it uses
the usual lexicographic ordering on the pair <code>(x, y)</code>. The equation
compiler in and of itself is not clever enough to derive that <code>x - y</code> is less than <code>x</code> under the given hypotheses, but we can help it
out by putting this fact in the local context. The equation compiler
looks in the local context for such information, and, when it finds
it, puts it to good use.</p>
<p>The defining equation for <code>div</code> does <em>not</em> hold definitionally, but
the equation is available to <code>rewrite</code> and <code>simp</code>. The simplifier
will loop if you apply it blindly, but <code>rewrite</code> will do the trick.</p>
<p>.. code-block:: lean</p>
<pre><code>namespace hidden
open nat

def div : ℕ → ℕ → ℕ
| x y :=
  if h : 0 &lt; y ∧ y ≤ x then
    have x - y &lt; x,
      from sub_lt (lt_of_lt_of_le h.left h.right) h.left,
    div (x - y) y + 1
  else
    0

-- BEGIN
example (x y : ℕ) :
  div x y = if 0 &lt; y ∧ y ≤ x then div (x - y) y + 1 else 0 :=
by rw [div]

example (x y : ℕ) (h : 0 &lt; y ∧ y ≤ x) :
  div x y = div (x - y) y + 1 :=
by rw [div, if_pos h]
-- END

end hidden
</code></pre>
<p>The following example is similar: it converts any natural number to a
binary expression, represented as a list of 0's and 1's. We have to
provide the equation compiler with evidence that the recursive call is
decreasing, which we do here with a <code>sorry</code>. The <code>sorry</code> does not
prevent the bytecode evaluator from evaluating the function
successfully.</p>
<p>.. code-block:: lean</p>
<pre><code>def nat_to_bin : ℕ → list ℕ
| 0       := [0]
| 1       := [1]
| (n + 2) :=
  have (n + 2) / 2 &lt; n + 2, from sorry,
  nat_to_bin ((n + 2) / 2) ++ [n % 2]

#eval nat_to_bin 1234567
</code></pre>
<p>As a final example, we observe that Ackermann's function can be
defined directly, because it is justified by the well foundedness of
the lexicographic order on the natural numbers.</p>
<p>.. code-block:: lean</p>
<pre><code>def ack : nat → nat → nat
| 0     y     := y+1
| (x+1) 0     := ack x 1
| (x+1) (y+1) := ack x (ack (x+1) y)

#eval ack 3 5
</code></pre>
<p>Lean's mechanisms for guessing a well-founded relation and then
proving that recursive calls decrease are still in a rudimentary
state. They will be improved over time. When they work, they provide a
much more convenient way of defining functions than using
<code>WellFounded.fix</code> manually. When they don't, the latter is always
available as a backup.</p>
<p>.. TO DO: eventually, describe using_well_founded.</p>
<p>.. _nested_and_mutual_recursion:</p>
<h2><a class="header" href="#a-name_nested_and_mutual_recursiona-mutual-recursion" id="a-name_nested_and_mutual_recursiona-mutual-recursion"><a name="_nested_and_mutual_recursion"></a> Mutual Recursion</a></h2>
<p><strong>TODO: waiting for well-founded support in Lean 4</strong></p>
<p>Lean also supports mutual recursive definitions. The syntax is similar to that for mutual inductive types, as described in :numref:<code>mutual_and_nested_inductive_types</code>. Here is an example:</p>
<p>.. code-block:: lean</p>
<pre><code>mutual def even, odd
with even : nat → bool
| 0     := tt
| (a+1) := odd a
with odd : nat → bool
| 0     := ff
| (a+1) := even a

example (a : nat) : even (a + 1) = odd a :=
by simp [even]

example (a : nat) : odd (a + 1) = even a :=
by simp [odd]

lemma even_eq_not_odd : ∀ a, even a = bnot (odd a) :=
begin
  intro a, induction a,
  simp [even, odd],
  simp [*, even, odd]
end
</code></pre>
<p>What makes this a mutual definition is that <code>even</code> is defined recursively in terms of <code>odd</code>, while <code>odd</code> is defined recursively in terms of <code>even</code>. Under the hood, this is compiled as a single recursive definition. The internally defined function takes, as argument, an element of a sum type, either an input to <code>even</code>, or an input to <code>odd</code>. It then returns an output appropriate to the input. To define that function, Lean uses a suitable well-founded measure. The internals are meant to be hidden from users; the canonical way to make use of such definitions is to use <code>rewrite</code> or <code>simp</code>, as we did above.</p>
<p>Mutual recursive definitions also provide natural ways of working with mutual and nested inductive types, as described in :numref:<code>mutual_and_nested_inductive_types</code>. Recall the definition of <code>even</code> and <code>odd</code> as mutual inductive predicates, as presented as an example there:</p>
<p>.. code-block:: lean</p>
<pre><code>mutual inductive even, odd
with even : ℕ → Prop
| even_zero : even 0
| even_succ : ∀ n, odd n → even (n + 1)
with odd : ℕ → Prop
| odd_succ : ∀ n, even n → odd (n + 1)
</code></pre>
<p>The constructors, <code>even_zero</code>, <code>even_succ</code>, and <code>odd_succ</code> provide positive means for showing that a number is even or odd. We need to use the fact that the inductive type is generated by these constructors to know that the zero is not odd, and that the latter two implications reverse. As usual, the constructors are kept in a namespace that is named after the type being defined, and the command <code>open even odd</code> allows us to access them move conveniently.</p>
<p>.. code-block:: lean</p>
<pre><code>mutual inductive even, odd
with even : ℕ → Prop
| even_zero : even 0
| even_succ : ∀ n, odd n → even (n + 1)
with odd : ℕ → Prop
| odd_succ : ∀ n, even n → odd (n + 1)

-- BEGIN
open even odd

theorem not_odd_zero : ¬ odd 0.

mutual theorem even_of_odd_succ, odd_of_even_succ
with even_of_odd_succ : ∀ n, odd (n + 1) → even n
| _ (odd_succ n h) := h
with odd_of_even_succ : ∀ n, even (n + 1) → odd n
| _ (even_succ n h) := h
-- END
</code></pre>
<p>For another example, suppose we use a nested inductive type to define a set of terms inductively, so that a term is either a constant (with a name given by a string), or the result of applying a constant to a list of constants.</p>
<p>.. code-block:: lean</p>
<pre><code>inductive term
| const : string → term
| app   : string → list term → term
</code></pre>
<p>We can then use a mutual recursive definition to count the number of constants occurring in a term, as well as the number occurring in a list of terms.</p>
<p>.. code-block:: lean</p>
<pre><code>inductive term
| const : string → term
| app   : string → list term → term

-- BEGIN
open term

mutual def num_consts, num_consts_lst
with num_consts : term → nat
| (term.const n)  := 1
| (term.app n ts) := num_consts_lst ts
with num_consts_lst : list term → nat
| []      := 0
| (t::ts) := num_consts t + num_consts_lst ts

def sample_term := app &quot;f&quot; [app &quot;g&quot; [const &quot;x&quot;], const &quot;y&quot;]

#eval num_consts sample_term
-- END
</code></pre>
<h2><a class="header" href="#a-name_dependent_pattern_matchinga-dependent-pattern-matching" id="a-name_dependent_pattern_matchinga-dependent-pattern-matching"><a name="_dependent_pattern_matching"></a> Dependent Pattern Matching</a></h2>
<p>All the examples of pattern matching we considered in
:numref:<code>pattern_matching</code> can easily be written using <code>cases_on</code>
and <code>rec_on</code>. However, this is often not the case with indexed
inductive families such as <code>vector α n</code>, since case splits impose
constraints on the values of the indices. Without the equation
compiler, we would need a lot of boilerplate code to define very
simple functions such as <code>map</code>, <code>zip</code>, and <code>unzip</code> using
recursors. To understand the difficulty, consider what it would take
to define a function <code>tail</code> which takes a vector
<code>v : vector α (succ n)</code> and deletes the first element. A first thought might be to
use the <code>casesOn</code> function:</p>
<pre><code class="language-lean">inductive Vector (α : Type u) : Nat → Type u
  | nil  : Vector α 0
  | cons : α → {n : Nat} → Vector α n → Vector α (n+1)

namespace Vector

#check @Vector.casesOn
/-
  {α : Type u}
  → {motive : (a : Nat) → Vector α a → Sort v} →
  → {a : Nat} → (t : Vector α a)
  → motive 0 nil
  → ((a : α) → {n : Nat} → (a_1 : Vector α n) → motive (n + 1) (cons a a_1))
  → motive a t
-/

end Vector
</code></pre>
<p>But what value should we return in the <code>nil</code> case? Something funny
is going on: if <code>v</code> has type <code>Vector α (succ n)</code>, it <em>can't</em> be
nil, but it is not clear how to tell that to <code>casesOn</code>.</p>
<p>One solution is to define an auxiliary function:</p>
<pre><code class="language-lean"><span class="boring">inductive Vector (α : Type u) : Nat → Type u
</span><span class="boring">  | nil  : Vector α 0
</span><span class="boring">  | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
</span><span class="boring">namespace Vector
</span>def tailAux (v : Vector α m) : m = n + 1 → Vector α n :=
  Vector.casesOn (motive := fun x _ =&gt; x = n + 1 → Vector α n) v
    (fun h : 0 = n + 1 =&gt; Nat.noConfusion h)
    (fun (a : α) (m : Nat) (as : Vector α m) =&gt;
     fun (h : m + 1 = n + 1) =&gt;
       Nat.noConfusion h (fun h1 : m = n =&gt; h1 ▸ as))

def tail (v : Vector α (n+1)) : Vector α n :=
  tailAux v rfl
<span class="boring">end Vector
</span></code></pre>
<p>In the <code>nil</code> case, <code>m</code> is instantiated to <code>0</code>, and
<code>noConfusion</code> makes use of the fact that <code>0 = succ n</code> cannot
occur.  Otherwise, <code>v</code> is of the form <code>a :: w</code>, and we can simply
return <code>w</code>, after casting it from a vector of length <code>m</code> to a
vector of length <code>n</code>.</p>
<p>The difficulty in defining <code>tail</code> is to maintain the relationships between the indices.
The hypothesis <code>e : m = n + 1</code> in <code>tailAux</code> is used to communicate the relationship
between <code>n</code> and the index associated with the minor premise.
Moreover, the <code>zero = n + 1</code> case is unreachable, and the canonical way to discard such
a case is to use <code>noConfusion</code>.</p>
<p>The <code>tail</code> function is, however, easy to define using recursive
equations, and the equation compiler generates all the boilerplate
code automatically for us. Here are a number of similar examples:</p>
<pre><code class="language-lean"><span class="boring">inductive Vector (α : Type u) : Nat → Type u
</span><span class="boring">  | nil  : Vector α 0
</span><span class="boring">  | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
</span><span class="boring">namespace Vector
</span>def head : {n : Nat} → Vector α (n+1) → α
  | n, cons a as =&gt; a

def tail : {n : Nat} → Vector α (n+1) → Vector α n
  | n, cons a as =&gt; as

theorem eta : ∀ {n : Nat} (v : Vector α (n+1)), cons (head v) (tail v) = v
  | n, cons a as =&gt; rfl

def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
  | 0,   nil,       nil       =&gt; nil
  | n+1, cons a as, cons b bs =&gt; cons (f a b) (map f as bs)

def zip : {n : Nat} → Vector α n → Vector β n → Vector (α × β) n
  | 0,   nil,       nil       =&gt; nil
  | n+1, cons a as, cons b bs =&gt; cons (a, b) (zip as bs)
<span class="boring">end Vector
</span></code></pre>
<p>Note that we can omit recursive equations for &quot;unreachable&quot; cases such
as <code>head nil</code>. The automatically generated definitions for indexed
families are far from straightforward. For example:</p>
<pre><code class="language-lean"><span class="boring">inductive Vector (α : Type u) : Nat → Type u
</span><span class="boring">  | nil  : Vector α 0
</span><span class="boring">  | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
</span><span class="boring">namespace Vector
</span>def map (f : α → β → γ) : {n : Nat} → Vector α n → Vector β n → Vector γ n
  | 0,   nil,       nil       =&gt; nil
  | n+1, cons a as, cons b bs =&gt; cons (f a b) (map f as bs)

#print map
#print map.match_1
<span class="boring">end Vector
</span></code></pre>
<p>The <code>map</code> function is even more tedious to define by hand than the
<code>tail</code> function. We encourage you to try it, using <code>recOn</code>,
<code>casesOn</code> and <code>noConfusion</code>.</p>
<h2><a class="header" href="#a-name_inaccessible_patternsainaccessible-patterns" id="a-name_inaccessible_patternsainaccessible-patterns"><a name="_inaccessible_patterns"></a>Inaccessible Patterns</a></h2>
<p>Sometimes an argument in a dependent matching pattern is not essential
to the definition, but nonetheless has to be included to specialize
the type of the expression appropriately. Lean allows users to mark
such subterms as <em>inaccessible</em> for pattern matching. These
annotations are essential, for example, when a term occurring in the
left-hand side is neither a variable nor a constructor application,
because these are not suitable targets for pattern matching. We can
view such inaccessible patterns as &quot;don't care&quot; components of the
patterns. You can declare a subterm inaccessible by writing
<code>.(t)</code>. If the inaccessible pattern can be inferred, you can also write
<code>_</code>.</p>
<p>The following example, we declare an inductive type that defines the
property of &quot;being in the image of <code>f</code>&quot;. You can view an element of
the type <code>ImageOf f b</code> as evidence that <code>b</code> is in the image of
<code>f</code>, whereby the constructor <code>imf</code> is used to build such
evidence. We can then define any function <code>f</code> with an &quot;inverse&quot;
which takes anything in the image of <code>f</code> to an element that is
mapped to it. The typing rules forces us to write <code>f a</code> for the
first argument, but this term is neither a variable nor a constructor
application, and plays no role in the pattern-matching definition. To
define the function <code>inverse</code> below, we <em>have to</em> mark <code>f a</code>
inaccessible.</p>
<pre><code class="language-lean">inductive ImageOf {α β : Type u} (f : α → β) : β → Type u where
  | imf : (a : α) → ImageOf f (f a)

open ImageOf

def inverse {f : α → β} : (b : β) → ImageOf f b → α
  | .(f a), imf a =&gt; a

def inverse' {f : α → β} : (b : β) → ImageOf f b → α
  | _, imf a =&gt; a
</code></pre>
<p>In the example above, the inaccessible annotation makes it clear that
<code>f</code> is <em>not</em> a pattern matching variable.</p>
<p>Inaccessible patterns can be used to clarify and control definitions that
make use of dependent pattern matching. Consider the following
definition of the function <code>Vector.add,</code> which adds two vectors of
elements of a type, assuming that type has an associated addition
function:</p>
<pre><code class="language-lean">inductive Vector (α : Type u) : Nat → Type u
  | nil  : Vector α 0
  | cons : α → {n : Nat} → Vector α n → Vector α (n+1)

namespace Vector

def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
  | 0,   nil,       nil       =&gt; nil
  | n+1, cons a as, cons b bs =&gt; cons (a + b) (add as bs)

end Vector
</code></pre>
<p>The argument <code>{n : Nat}</code> appear after the colon, because it cannot
be held fixed throughout the definition.  When implementing this
definition, the equation compiler starts with a case distinction as to
whether the first argument is <code>0</code> or of the form <code>n+1</code>.  This is
followed by nested case splits on the next two arguments, and in each
case the equation compiler rules out the cases are not compatible with
the first pattern.</p>
<p>But, in fact, a case split is not required on the first argument; the
<code>casesOn</code> eliminator for <code>Vector</code> automatically abstracts this
argument and replaces it by <code>0</code> and <code>n + 1</code> when we do a case
split on the second argument. Using inaccessible patterns, we can prompt
the equation compiler to avoid the case split on <code>n</code></p>
<pre><code class="language-lean"><span class="boring">inductive Vector (α : Type u) : Nat → Type u
</span><span class="boring">  | nil  : Vector α 0
</span><span class="boring">  | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
</span><span class="boring">namespace Vector
</span>
def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
  | .(_),   nil,       nil       =&gt; nil
  | .(_), cons a as, cons b bs =&gt; cons (a + b) (add as bs)

<span class="boring">end Vector
</span></code></pre>
<p>Marking the position as an inaccessible pattern tells the
equation compiler first, that the form of the argument should be
inferred from the constraints posed by the other arguments, and,
second, that the first argument should <em>not</em> participate in pattern
matching.</p>
<p>The inaccessible pattern <code>.(_)</code> can be written as <code>_</code> for convenience.</p>
<pre><code class="language-lean"><span class="boring">inductive Vector (α : Type u) : Nat → Type u
</span><span class="boring">  | nil  : Vector α 0
</span><span class="boring">  | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
</span><span class="boring">namespace Vector
</span>
def add [Add α] : {n : Nat} → Vector α n → Vector α n → Vector α n
  | _,   nil,       nil       =&gt; nil
  | _, cons a as, cons b bs =&gt; cons (a + b) (add as bs)

<span class="boring">end Vector
</span></code></pre>
<p>As we mentioned above, the argument <code>{n : Nat}</code> is part of the
pattern matching, because it cannot be held fixed throughout the
definition. In previous Lean versions, users often found it cumbersome
to have to include these extra discriminants. Thus, Lean 4
implements a new feature, <em>discriminant refinement</em>, which includes
these extra discriminants automatically for us.</p>
<pre><code class="language-lean"><span class="boring">inductive Vector (α : Type u) : Nat → Type u
</span><span class="boring">  | nil  : Vector α 0
</span><span class="boring">  | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
</span><span class="boring">namespace Vector
</span>
def add [Add α] {n : Nat} : Vector α n → Vector α n → Vector α n
  | nil,       nil       =&gt; nil
  | cons a as, cons b bs =&gt; cons (a + b) (add as bs)

<span class="boring">end Vector
</span></code></pre>
<p>When combined with the <em>auto bound implicits</em> feature, you can simplify
the declare further and write:</p>
<pre><code class="language-lean"><span class="boring">inductive Vector (α : Type u) : Nat → Type u
</span><span class="boring">  | nil  : Vector α 0
</span><span class="boring">  | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
</span><span class="boring">namespace Vector
</span>
def add [Add α] : Vector α n → Vector α n → Vector α n
  | nil,       nil       =&gt; nil
  | cons a as, cons b bs =&gt; cons (a + b) (add as bs)

<span class="boring">end Vector
</span></code></pre>
<p>Using these new features, you can write the other vector functions defined
in the previous sections more compactly as follows:</p>
<pre><code class="language-lean"><span class="boring">inductive Vector (α : Type u) : Nat → Type u
</span><span class="boring">  | nil  : Vector α 0
</span><span class="boring">  | cons : α → {n : Nat} → Vector α n → Vector α (n+1)
</span><span class="boring">namespace Vector
</span>def head : Vector α (n+1) → α
  | cons a as =&gt; a

def tail : Vector α (n+1) → Vector α n
  | cons a as =&gt; as

theorem eta : (v : Vector α (n+1)) → cons (head v) (tail v) = v
  | cons a as =&gt; rfl

def map (f : α → β → γ) : Vector α n → Vector β n → Vector γ n
  | nil,       nil       =&gt; nil
  | cons a as, cons b bs =&gt; cons (f a b) (map f as bs)

def zip : Vector α n → Vector β n → Vector (α × β) n
  | nil,       nil       =&gt; nil
  | cons a as, cons b bs =&gt; cons (a, b) (zip as bs)
<span class="boring">end Vector
</span></code></pre>
<h2><a class="header" href="#a-name_match_expressionsamatch-expressions" id="a-name_match_expressionsamatch-expressions"><a name="_match_expressions"></a>Match Expressions</a></h2>
<p>Lean also provides a compiler for <em>match-with</em> expressions found in
many functional languages.</p>
<pre><code class="language-lean">def isNotZero (m : Nat) : Bool :=
  match m with
  | 0   =&gt; false
  | n+1 =&gt; true
</code></pre>
<p>This does not look very different from an ordinary pattern matching
definition, but the point is that a <code>match</code> can be used anywhere in
an expression, and with arbitrary arguments.</p>
<pre><code class="language-lean">def isNotZero (m : Nat) : Bool :=
  match m with
  | 0   =&gt; false
  | n+1 =&gt; true

def filter (p : α → Bool) : List α → List α
  | []      =&gt; []
  | a :: as =&gt;
    match p a with
    | true =&gt; a :: filter p as
    | false =&gt; filter p as

example : filter isNotZero [1, 0, 0, 3, 0] = [1, 3] := rfl
</code></pre>
<p>Here is another example:</p>
<pre><code class="language-lean">def foo (n : Nat) (b c : Bool) :=
  5 + match n - 5, b &amp;&amp; c with
      | 0,   true  =&gt; 0
      | m+1, true  =&gt; m + 7
      | 0,   false =&gt; 5
      | m+1, false =&gt; m + 3

#eval foo 7 true false

example : foo 7 true false = 9 := rfl
</code></pre>
<p>Lean uses the <code>match</code> construct internally to implement pattern-matching in all parts of the system.
Thus, all four of these definitions have the same net effect.</p>
<pre><code class="language-lean">def bar₁ : Nat × Nat → Nat
  | (m, n) =&gt; m + n

def bar₂ (p : Nat × Nat) : Nat :=
  match p with
  | (m, n) =&gt; m + n

def bar₃ : Nat × Nat → Nat :=
  fun (m, n) =&gt; m + n

def bar₄ (p : Nat × Nat) : Nat :=
  let (m, n) := p; m + n
</code></pre>
<p>These variations are equally useful for destructing propositions:</p>
<pre><code class="language-lean">variable (p q : Nat → Prop)

example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y
 | ⟨x, px⟩, ⟨y, qy⟩ =&gt; ⟨x, y, px, qy⟩

example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
        : ∃ x y, p x ∧ q y :=
  match h₀, h₁ with
  | ⟨x, px⟩, ⟨y, qy⟩ =&gt; ⟨x, y, px, qy⟩


example : (∃ x, p x) → (∃ y, q y) → ∃ x y, p x ∧ q y :=
  fun ⟨x, px⟩ ⟨y, qy⟩ =&gt; ⟨x, y, px, qy⟩

example (h₀ : ∃ x, p x) (h₁ : ∃ y, q y)
        : ∃ x y, p x ∧ q y :=
  let ⟨x, px⟩ := h₀
  let ⟨y, qy⟩ := h₁
  ⟨x, y, px, qy⟩
</code></pre>
<h2><a class="header" href="#local-recursive-declarations" id="local-recursive-declarations">Local recursive declarations</a></h2>
<p>You can define local recursive declarations using the <code>let rec</code> keyword.</p>
<pre><code class="language-lean">def replicate (n : Nat) (a : α) : List α :=
  let rec loop : Nat → List α → List α
    | 0,   as =&gt; as
    | n+1, as =&gt; loop n (a::as)
  loop n []

#check @replicate.loop
-- {α : Type} → α → Nat → List α → List α
</code></pre>
<p>Lean creates an auxiliary declaration for each <code>let rec</code>. In the example above,
it created the declaration <code>replicate.loop</code> for the <code>let rec loop</code> occurring at <code>replicate</code>.
Note that, Lean &quot;closes&quot; the declaration by adding any local variable occurring in the
<code>let rec</code> declaration as additional parameters. For example, the local variable <code>a</code> occurs
at <code>let rec loop</code>.</p>
<p>You can also use <code>let rec</code> in tactic mode and for creating proofs by induction.</p>
<pre><code class="language-lean"><span class="boring">def replicate (n : Nat) (a : α) : List α :=
</span><span class="boring"> let rec loop : Nat → List α → List α
</span><span class="boring">   | 0,   as =&gt; as
</span><span class="boring">   | n+1, as =&gt; loop n (a::as)
</span><span class="boring"> loop n []
</span>theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
  let rec aux (n : Nat) (as : List α)
              : (replicate.loop a n as).length = n + as.length := by
    match n with
    | 0   =&gt; simp [replicate.loop]
    | n+1 =&gt; simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
  exact aux n []
</code></pre>
<p>You can also introduce auxiliary recursive declarations using <code>where</code> clause after your definition.
Lean converts them into a <code>let rec</code>.</p>
<pre><code class="language-lean">def replicate (n : Nat) (a : α) : List α :=
  loop n []
where
  loop : Nat → List α → List α
    | 0,   as =&gt; as
    | n+1, as =&gt; loop n (a::as)

theorem length_replicate (n : Nat) (a : α) : (replicate n a).length = n := by
  exact aux n []
where
  aux (n : Nat) (as : List α)
      : (replicate.loop a n as).length = n + as.length := by
    match n with
    | 0   =&gt; simp [replicate.loop]
    | n+1 =&gt; simp [replicate.loop, aux n, Nat.add_succ, Nat.succ_add]
</code></pre>
<h2><a class="header" href="#exercises-1" id="exercises-1">Exercises</a></h2>
<ol>
<li>
<p>Open a namespace <code>Hidden</code> to avoid naming conflicts, and use the
equation compiler to define addition, multiplication, and
exponentiation on the natural numbers. Then use the equation
compiler to derive some of their basic properties.</p>
</li>
<li>
<p>Similarly, use the equation compiler to define some basic
operations on lists (like the <code>reverse</code> function) and prove
theorems about lists by induction (such as the fact that
<code>reverse (reverse xs) = xs</code> for any list <code>xs</code>).</p>
</li>
<li>
<p>Define your own function to carry out course-of-value recursion on
the natural numbers. Similarly, see if you can figure out how to
define <code>WellFounded.fix</code> on your own.</p>
</li>
<li>
<p>Following the examples in <a href="induction_and_recursion.html#dependent_pattern_matching">Section Dependent Pattern Matching</a>,
define a function that will append two vectors.
This is tricky; you will have to define an auxiliary function.</p>
</li>
<li>
<p>Consider the following type of arithmetic expressions. The idea is
that <code>var n</code> is a variable, <code>vₙ</code>, and <code>const n</code> is the
constant whose value is <code>n</code>.</p>
</li>
</ol>
<pre><code class="language-lean">inductive Expr where
  | const : Nat → Expr
  | var : Nat → Expr
  | plus : Expr → Expr → Expr
  | times : Expr → Expr → Expr
  deriving Repr

open Expr

def sampleExpr : Expr :=
  plus (times (var 0) (const 7)) (times (const 2) (var 1))
</code></pre>
<p>Here <code>sampleExpr</code> represents <code>(v₀ * 7) + (2 * v₁)</code>.</p>
<p>Write a function that evaluates such an expression, evaluating each <code>var n</code> to <code>v n</code>.</p>
<pre><code class="language-lean"><span class="boring">inductive Expr where
</span><span class="boring">  | const : Nat → Expr
</span><span class="boring">  | var : Nat → Expr
</span><span class="boring">  | plus : Expr → Expr → Expr
</span><span class="boring">  | times : Expr → Expr → Expr
</span><span class="boring">  deriving Repr
</span><span class="boring">open Expr
</span><span class="boring">def sampleExpr : Expr :=
</span><span class="boring">  plus (times (var 0) (const 7)) (times (const 2) (var 1))
</span>def eval (v : Nat → Nat) : Expr → Nat
  | const n     =&gt; sorry
  | var n       =&gt; v n
  | plus e₁ e₂  =&gt; sorry
  | times e₁ e₂ =&gt; sorry

def sampleVal : Nat → Nat
  | 0 =&gt; 5
  | 1 =&gt; 6
  | _ =&gt; 0

-- Try it out. You should get 47 here.
-- #eval eval sampleVal sampleExpr
</code></pre>
<p>Implement &quot;constant fusion,&quot; a procedure that simplifies subterms like
<code>5 + 7</code> to <code>12</code>. Using the auxiliary function <code>simpConst</code>,
define a function &quot;fuse&quot;: to simplify a plus or a times, first
simplify the arguments recursively, and then apply <code>simpConst</code> to
try to simplify the result.</p>
<pre><code class="language-lean"><span class="boring">inductive Expr where
</span><span class="boring">  | const : Nat → Expr
</span><span class="boring">  | var : Nat → Expr
</span><span class="boring">  | plus : Expr → Expr → Expr
</span><span class="boring">  | times : Expr → Expr → Expr
</span><span class="boring">  deriving Repr
</span><span class="boring">open Expr
</span><span class="boring">def eval (v : Nat → Nat) : Expr → Nat
</span><span class="boring">  | const n     =&gt; sorry
</span><span class="boring">  | var n       =&gt; v n
</span><span class="boring">  | plus e₁ e₂  =&gt; sorry
</span><span class="boring">  | times e₁ e₂ =&gt; sorry
</span>def simpConst : Expr → Expr
  | plus (const n₁) (const n₂)  =&gt; const (n₁ + n₂)
  | times (const n₁) (const n₂) =&gt; const (n₁ * n₂)
  | e                           =&gt; e

def fuse : Expr → Expr := sorry

theorem simpConst_eq (v : Nat → Nat)
        : ∀ e : Expr, eval v (simpConst e) = eval v e :=
  sorry

theorem fuse_eq (v : Nat → Nat)
        : ∀ e : Expr, eval v (fuse e) = eval v e :=
  sorry
</code></pre>
<p>The last two theorems show that the definitions preserve the value.</p>
<h1><a class="header" href="#结构体和记录" id="结构体和记录">结构体和记录</a></h1>
<p>我们已经看到Lean的基本系统包括递归类型。此外，显然仅基于类型宇宙、依赖箭头类型和递归类型，就有可能构建一个坚实的数学大厦；其他的一切都是由此而来。Lean标准库包含许多递归类型的实例(例如，<code>Nat</code>，<code>Prod</code>，<code>List</code>)，甚至逻辑连接词也是使用递归类型定义的。</p>
<p>回忆一下，只包含一个构造子的非递归递归类型被称为<em>结构体</em>（structure）或<em>记录</em>（record）。乘积类型是一种结构体，依赖乘积(Sigma)类型也是如此。一般来说，每当我们定义一个结构体<code>S</code>时，我们通常定义<em>投影</em>（projection）函数来“析构”（destruct）<code>S</code>的每个实例并检索存储在其字段中的值。<code>prod.pr1</code>和<code>prod.pr2</code>，分别返回乘积对中的第一个和第二个元素的函数，就是这种投影的例子。</p>
<p>在编写程序或形式化数学时，定义包含许多字段的结构体是很常见的。Lean中可用<code>structure</code>命令实现此过程。当我们使用这个命令定义一个结构体时，Lean会自动生成所有的投影函数。<code>structure</code>命令还允许我们根据以前定义的结构体定义新的结构体。此外，Lean为定义给定结构体的实例提供了方便的符号。</p>
<h2><a class="header" href="#声明结构体" id="声明结构体">声明结构体</a></h2>
<p>结构体命令本质上是定义归纳数据类型的“前端”。每个<code>structure</code>声明都会引入一个同名的命名空间。一般形式如下:</p>
<pre><code>    structure &lt;name&gt; &lt;parameters&gt; &lt;parent-structures&gt; where
      &lt;constructor&gt; :: &lt;fields&gt;
</code></pre>
<p>大多数部分不是必要的。例子：</p>
<pre><code class="language-lean">structure Point (α : Type u) where
  mk :: (x : α) (y : α)
</code></pre>
<p>类型<code>Point</code>的值是使用<code>Point.mk a b</code>创建的，并且点<code>p</code>的字段可以使用<code>Point.x p</code>和<code>Point.y p</code>。结构体命令还生成有用的递归子和定理。下面是为上述声明生成的一些结构体方法。</p>
<pre><code class="language-lean"><span class="boring">structure Point (α : Type u) where
</span><span class="boring"> mk :: (x : α) (y : α)
</span>#check Point       -- a Type
#check @Point.rec  -- the eliminator
#check @Point.mk   -- the constructor
#check @Point.x    -- a projection
#check @Point.y    -- a projection
</code></pre>
<p>如果没有提供构造子名称，则默认的构造函数名为' ' mk ' '。如果在每个字段之间添加换行符，也可以避免字段名周围的括号。</p>
<pre><code class="language-lean">structure Point (α : Type u) where
  x : α
  y : α
</code></pre>
<p>下面是一些使用生成的结构的简单定理和表达式。像往常一样，您可以通过使用命令<code>open Point</code>来避免前缀<code>Point</code>。</p>
<pre><code class="language-lean">#eval Point.x (Point.mk 10 20)
#eval Point.y (Point.mk 10 20)

open Point

example (a b : α) : x (mk a b) = a :=
  rfl

example (a b : α) : y (mk a b) = b :=
  rfl
</code></pre>
<p>给定<code>p : Point Nat</code>，符号<code>p.x</code>是<code>Point.x p</code>的缩写。这提供了一种方便的方式来访问结构体的字段。</p>
<pre><code class="language-lean">def p := Point.mk 10 20

#check p.x  -- Nat
#eval p.x   -- 10
#eval p.y   -- 20
</code></pre>
<p>点表示法不仅方便于访问记录的投影，而且也方便于应用同名命名空间中定义的函数。回想一下<a href="./propositions_and_proofs.html#_conjunction">合取</a>一节，如果<code>p</code>具有<code>Point</code>类型，那么表达式<code>p.foo</code>被解释为<code>Point.foo p</code>，假设<code>foo</code>的第一个非隐式参数具有类型<code>Point</code>，表达式<code>p.add q</code>因此是<code>Point.add p q</code>的缩写。可见下面的例子。</p>
<pre><code class="language-lean">structure Point (α : Type u) where
  x : α
  y : α
  deriving Repr

def Point.add (p q : Point Nat) :=
  mk (p.x + q.x) (p.y + q.y)

def p : Point Nat := Point.mk 1 2
def q : Point Nat := Point.mk 3 4

#eval p.add q  -- {x := 4, y := 6}
</code></pre>
<p>在下一章中，您将学习如何定义一个像<code>add</code>这样的函数，这样它就可以通用地为<code>Point α</code>的元素工作，而不仅仅是<code>Point Nat</code>，只要假设<code>α</code>有一个关联的加法操作。</p>
<p>更一般地，给定一个表达式<code>p.foo x y z</code>其中<code>p : Point</code>，Lean会把<code>p</code>以<code>Point</code>为类型插入到<code>Point.foo</code>的第一个参数。例如，下面是标量乘法的定义，<code>p.smul 3</code>被解释为<code>Point.smul 3 p</code>。</p>
<pre><code class="language-lean">def Point.smul (n : Nat) (p : Point Nat) :=
  Point.mk (n * p.x) (n * p.y)

def p : Point Nat := Point.mk 1 2

#eval p.smul 3  -- {x := 3, y := 6}
</code></pre>
<p>对<code>List.map</code>函数使用类似的技巧很常用。它接受一个列表作为它的第二个非隐式参数:</p>
<pre><code class="language-lean">#check @List.map

def xs : List Nat := [1, 2, 3]
def f : Nat → Nat := fun x =&gt; x * x

#eval xs.map f  -- [1, 4, 9]
</code></pre>
<p>此处<code>xs.map f</code>被解释为<code>List.map f xs</code>。</p>
<p>Here <code>xs.map f</code> is interpreted as <code>List.map f xs</code>.</p>
<h2><a class="header" href="#对象" id="对象">对象</a></h2>
<p>我们一直在使用构造子创建结构体类型的元素。对于包含许多字段的结构，这通常是不方便的，因为我们必须记住字段定义的顺序。因此，Lean为定义结构体类型的元素提供了以下替代符号。</p>
<pre><code>    { (&lt;field-name&gt; := &lt;expr&gt;)* : structure-type }
    or
    { (&lt;field-name&gt; := &lt;expr&gt;)* }
</code></pre>
<p>只要可以从期望的类型推断出结构体的名称，后缀<code>: structure-type</code>就可以省略。例如，我们使用这种表示法来定义“点”。字段的指定顺序无关紧要，因此下面的所有表达式定义相同的点。</p>
<pre><code class="language-lean">structure Point (α : Type u) where
  x : α
  y : α

#check { x := 10, y := 20 : Point Nat }  -- Point ℕ
#check { y := 20, x := 10 : Point _ }
#check ({ x := 10, y := 20 } : Point Nat)

example : Point Nat :=
  { y := 20, x := 10 }
</code></pre>
<p>如果一个字段的值没有指定，Lean会尝试推断它。如果不能推断出未指定的字段，Lean会标记一个错误，表明相应的占位符无法合成。</p>
<pre><code class="language-lean">structure MyStruct where
    {α : Type u}
    {β : Type v}
    a : α
    b : β

#check { a := 10, b := true : MyStruct }
</code></pre>
<p><em>记录更新</em>是另一个常见的操作，相当于通过修改旧记录中的一个或多个字段的值来创建一个新的记录对象。通过在字段赋值之前添加注释<code>s with</code>，Lean允许您指定记录规范中未赋值的字段，该字段应从之前定义的结构对象<code>s</code>中获取。如果提供了多个记录对象，那么将按顺序访问它们，直到Lean找到一个包含未指定字段的记录对象。如果在访问了所有对象之后仍未指定任何字段名，Lean将引发错误。</p>
<pre><code class="language-lean">structure Point (α : Type u) where
  x : α
  y : α
  deriving Repr

def p : Point Nat :=
  { x := 1, y := 2 }

#eval { p with y := 3 }  -- { x := 1, y := 3 }
#eval { p with x := 4 }  -- { x := 4, y := 2 }

structure Point3 (α : Type u) where
  x : α
  y : α
  z : α

def q : Point3 Nat :=
  { x := 5, y := 5, z := 5 }

def r : Point3 Nat :=
  { p, q with x := 6 }

example : r.x = 6 := rfl
example : r.y = 2 := rfl
example : r.z = 5 := rfl
</code></pre>
<h2><a class="header" href="#继承" id="继承">继承</a></h2>
<p>我们可以通过添加新的字段来<em>扩展</em>现有的结构体。这个特性允许我们模拟一种形式的<em>继承</em>。</p>
<pre><code class="language-lean">structure Point (α : Type u) where
  x : α
  y : α

inductive Color where
  | red | green | blue

structure ColorPoint (α : Type u) extends Point α where
  c : Color
</code></pre>
<p>在下一个例子中，我们使用多重继承定义一个结构体，然后使用父结构的对象定义一个对象。</p>
<pre><code class="language-lean">structure Point (α : Type u) where
  x : α
  y : α
  z : α

structure RGBValue where
  red : Nat
  green : Nat
  blue : Nat

structure RedGreenPoint (α : Type u) extends Point α, RGBValue where
  no_blue : blue = 0

def p : Point Nat :=
  { x := 10, y := 10, z := 20 }

def rgp : RedGreenPoint Nat :=
  { p with red := 200, green := 40, blue := 0, no_blue := rfl }

example : rgp.x   = 10 := rfl
example : rgp.red = 200 := rfl
</code></pre>
<h1><a class="header" href="#type-classes" id="type-classes">Type classes</a></h1>
<p>Type classes were introduced as a principled way of enabling
ad-hoc polymorphism in functional programming languages. We first observe that it
would be easy to implement an ad-hoc polymorphic function (such as addition) if the
function simply took the type-specific implementation of addition as an argument
and then called that implementation on the remaining arguments. For example,
suppose we declare a structure in Lean to hold implementations of addition</p>
<pre><code class="language-lean"><span class="boring">namespace Ex
</span>structure Add (a : Type) where
  add : a -&gt; a -&gt; a

#check @Add.add
-- Add.add : {a : Type} → Add a → a → a → a
<span class="boring">end Ex
</span></code></pre>
<p>In the above Lean code, the field <code>add</code> has type
<code>Add.add : {α : Type} → Add α → α → α → α</code>
where the curly braces around the type <code>a</code> mean that it is an implicit argument.
We could implement <code>double</code> by</p>
<pre><code class="language-lean"><span class="boring">namespace Ex
</span><span class="boring">structure Add (a : Type) where
</span><span class="boring"> add : a -&gt; a -&gt; a
</span>def double (s : Add a) (x : a) : a :=
  s.add x x

#eval double { add := Nat.add } 10
-- 20

#eval double { add := Nat.mul } 10
-- 100

#eval double { add := Int.add } 10
-- 20

<span class="boring">end Ex
</span></code></pre>
<p>Note that you can double a natural number <code>n</code> by <code>double { add := Nat.add } n</code>.
Of course, it would be highly cumbersome for users to manually pass the
implementations around in this way.
Indeed, it would defeat most of the potential benefits of ad-hoc
polymorphism.</p>
<p>The main idea behind type classes is to make arguments such as <code>Add a</code> implicit,
and to use a database of user-defined instances to synthesize the desired instances
automatically through a process known as typeclass resolution. In Lean, by changing
<code>structure</code> to <code>class</code> in the example above, the type of <code>Add.add</code> becomes</p>
<pre><code class="language-lean"><span class="boring">namespace Ex
</span>class Add (a : Type) where
  add : a -&gt; a -&gt; a

#check @Add.add
-- Add.add : {a : Type} → [self : Add a] → a → a → a
<span class="boring">end Ex
</span></code></pre>
<p>where the square brackets indicate that the argument of type <code>Add a</code> is <em>instance implicit</em>,
i.e. that it should be synthesized using typeclass resolution. This version of
<code>add</code> is the Lean analogue of the Haskell term <code>add :: Add a =&gt; a -&gt; a -&gt; a</code>.
Similarly, we can register an instance by</p>
<pre><code class="language-lean"><span class="boring">namespace Ex
</span><span class="boring">class Add (a : Type) where
</span><span class="boring"> add : a -&gt; a -&gt; a
</span>instance : Add Nat where
  add := Nat.add

<span class="boring">end Ex
</span></code></pre>
<p>Then for <code>n : Nat</code> and <code>m : Nat</code>, the term <code>Add.add n m</code> triggers typeclass resolution with the goal
of <code>Add Nat</code>, and typeclass resolution will synthesize the instance above. In
general, instances may depend on other instances in complicated ways. For example,
you can declare an (anonymous) instance stating that if <code>a</code> has addition, then <code>Array a</code>
has addition:</p>
<pre><code class="language-lean">instance [Add a] : Add (Array a) where
  add x y := Array.zipWith x y (. + .)

#eval Add.add #[1, 2] #[3, 4]
-- #[4, 6]

#eval #[1, 2] + #[3, 4]
-- #[4, 6]
</code></pre>
<p>Note that <code>x + y</code> is notation for <code>Add.add x y</code> in Lean.</p>
<p>The example above demonstrates how type classes are used to overload notation.
Now, we explore another application. We often need an arbitrary element of a given type.
Recall that types may not have any elements in Lean.
It often happens that we would like a definition to return an arbitrary element in a &quot;corner case.&quot;
For example, we may like the expression <code>head xs</code> to be of type <code>a</code> when <code>xs</code> is of type <code>List a</code>.
Similarly, many theorems hold under the additional assumption that a type is not empty.
For example, if <code>a</code> is a type, <code>exists x : a, x = x</code> is true only if <code>a</code> is not empty.
The standard library defines a type class <code>Inhabited</code> to enable type class inference to infer a
&quot;default&quot; or &quot;arbitrary&quot; element of an inhabited type.
Let us start with the first step of the program above, declaring an appropriate class:</p>
<pre><code class="language-lean"><span class="boring">namespace Ex
</span>class Inhabited (a : Type u) where
  default : a

#check @Inhabited.default
-- Inhabited.default : {a : Type u} → [self : Inhabited a] → a
<span class="boring">end Ex
</span></code></pre>
<p>Note <code>Inhabited.default</code> doesn't have any explicit argument.</p>
<p>An element of the class <code>Inhabited a</code> is simply an expression of the form <code>Inhabited.mk x</code>, for some element <code>x : a</code>.
The projection <code>Inhabited.default</code> will allow us to &quot;extract&quot; such an element of <code>a</code> from an element of <code>Inhabited a</code>.
Now we populate the class with some instances:</p>
<pre><code class="language-lean"><span class="boring">namespace Ex
</span><span class="boring">class Inhabited (a : Type _) where
</span><span class="boring"> default : a
</span>instance : Inhabited Bool where
  default := true

instance : Inhabited Nat where
  default := 0

instance : Inhabited Unit where
  default := ()

instance : Inhabited Prop where
  default := True

#eval (Inhabited.default : Nat)
-- 0

#eval (Inhabited.default : Bool)
-- true
<span class="boring">end Ex
</span></code></pre>
<p>You can use the command <code>export</code> to create the alias <code>default</code> for <code>Inhabited.default</code></p>
<pre><code class="language-lean"><span class="boring">namespace Ex
</span><span class="boring">class Inhabited (a : Type _) where
</span><span class="boring"> default : a
</span><span class="boring">instance : Inhabited Bool where
</span><span class="boring"> default := true
</span><span class="boring">instance : Inhabited Nat where
</span><span class="boring"> default := 0
</span><span class="boring">instance : Inhabited Unit where
</span><span class="boring"> default := ()
</span><span class="boring">instance : Inhabited Prop where
</span><span class="boring"> default := True
</span>export Inhabited (default)

#eval (default : Nat)
-- 0

#eval (default : Bool)
-- true
<span class="boring">end Ex
</span></code></pre>
<p>Sometimes we want to think of the default element of a type as being an <em>arbitrary</em> element, whose specific value should not play a role in our proofs.
For that purpose, we can write <code>arbitrary</code> instead of <code>default</code>. We define <code>arbitrary</code> as an <em>opaque</em> constant.
Opaque constants are never unfolded by the type checker.</p>
<pre><code class="language-lean"><span class="boring">namespace Ex
</span><span class="boring">export Inhabited (default)
</span>theorem defNatEq0 : (default : Nat) = 0 :=
  rfl

constant arbitrary [Inhabited a] : a :=
  Inhabited.default

-- theorem arbitraryNatEq0 : (arbitrary : Nat) = 0 :=
--   rfl
/-
error: type mismatch
  rfl
has type
  arbitrary = arbitrary
but is expected to have type
  arbitrary = 0
-/
<span class="boring">end Ex
</span></code></pre>
<p>The theorem <code>defNatEq0</code> type checks because the type checker can unfold <code>(default : Nat)</code> and reduce it to <code>0</code>. This is not the case in the theorem <code>arbitraryNatEq0</code> because <code>arbitrary</code> is an opaque constant.</p>
<h2><a class="header" href="#chaining-instances" id="chaining-instances">Chaining Instances</a></h2>
<p>If that were the extent of type class inference, it would not be all that impressive;
it would be simply a mechanism of storing a list of instances for the elaborator to find in a lookup table.
What makes type class inference powerful is that one can <em>chain</em> instances. That is,
an instance declaration can in turn depend on an implicit instance of a type class.
This causes class inference to chain through instances recursively, backtracking when necessary, in a Prolog-like search.</p>
<p>For example, the following definition shows that if two types <code>a</code> and <code>b</code> are inhabited, then so is their product:</p>
<pre><code class="language-lean">instance [Inhabited a] [Inhabited b] : Inhabited (a × b) where
  default := (arbitrary, arbitrary)
</code></pre>
<p>With this added to the earlier instance declarations, type class instance can infer, for example, a default element of <code>Nat × Bool</code>:</p>
<pre><code class="language-lean"><span class="boring">namespace Ex
</span><span class="boring">class Inhabited (a : Type u) where
</span><span class="boring"> default : a
</span><span class="boring">instance : Inhabited Bool where
</span><span class="boring"> default := true
</span><span class="boring">instance : Inhabited Nat where
</span><span class="boring"> default := 0
</span><span class="boring">constant arbitrary [Inhabited a] : a :=
</span><span class="boring"> Inhabited.default
</span>instance [Inhabited a] [Inhabited b] : Inhabited (a × b) where
  default := (arbitrary, arbitrary)

#eval (arbitrary : Nat × Bool)
-- (0, true)
<span class="boring">end Ex
</span></code></pre>
<p>Similarly, we can inhabit type function with suitable constant functions:</p>
<pre><code class="language-lean">instance [Inhabited b] : Inhabited (a -&gt; b) where
  default := fun _ =&gt; arbitrary
</code></pre>
<p>As an exercise, try defining default instances for other types, such as <code>List</code> and <code>Sum</code> types.</p>
<p>The Lean standard library contains the definition <code>inferInstance</code>. It has type <code>{α : Sort u} → [i : α] → α</code>,
and is useful for triggering the type class resolution procedure when the expected type is an instance.</p>
<pre><code class="language-lean">#check (inferInstance : Inhabited Nat) -- Inhabited Nat

def foo : Inhabited (Nat × Nat) :=
  inferInstance

theorem ex : foo.default = (arbitrary, arbitrary) :=
  rfl
</code></pre>
<p>You can use the command <code>#print</code> to inspect how simple <code>inferInstance</code> is.</p>
<pre><code class="language-lean">#print inferInstance
</code></pre>
<h2><a class="header" href="#tostring" id="tostring">ToString</a></h2>
<p>The polymorphic method <code>toString</code> has type <code>{α : Type u} → [ToString α] → α → String</code>. You implement the instance
for your own types and use chaining to convert complex values into strings. Lean comes with <code>ToString</code> instances
for most builtin types.</p>
<pre><code class="language-lean">structure Person where
  name : String
  age  : Nat

instance : ToString Person where
  toString p := p.name ++ &quot;@&quot; ++ toString p.age

#eval toString { name := &quot;Leo&quot;, age := 542 : Person }
#eval toString ({ name := &quot;Daniel&quot;, age := 18 : Person }, &quot;hello&quot;)
</code></pre>
<h2><a class="header" href="#numerals" id="numerals">Numerals</a></h2>
<p>Numerals are polymorphic in Lean. You can use a numeral (e.g., <code>2</code>) to denote an element of any type that implements
the type class <code>OfNat</code>.</p>
<pre><code class="language-lean">structure Rational where
  num : Int
  den : Nat
  inv : den ≠ 0

instance : OfNat Rational n where
  ofNat := { num := n, den := 1, inv := by decide }

instance : ToString Rational where
  toString r := s!&quot;{r.num}/{r.den}&quot;

#eval (2 : Rational) -- 2/1

#check (2 : Rational) -- Rational
#check (2 : Nat)      -- Nat
</code></pre>
<p>Lean elaborates the terms <code>(2 : Nat)</code> and <code>(2 : Rational)</code> as
<code>OfNat.ofNat Nat 2 (instOfNatNat 2)</code> and
<code>OfNat.ofNat Rational 2 (instOfNatRational 2)</code> respectively.
We say the numerals <code>2</code> occurring in the elaborated terms are <em>raw</em> natural numbers.
You can input the raw natural number <code>2</code> using the macro <code>nat_lit 2</code>.</p>
<pre><code class="language-lean">#check nat_lit 2  -- Nat
</code></pre>
<p>Raw natural numbers are <em>not</em> polymorphic.</p>
<p>The <code>OfNat</code> instance is parametric on the numeral. So, you can define instances for particular numerals.
The second argument is often a variable as in the example above, or a <em>raw</em> natural number.</p>
<pre><code class="language-lean">class Monoid (α : Type u) where
  unit : α
  op   : α → α → α

instance [s : Monoid α] : OfNat α (nat_lit 1) where
  ofNat := s.unit

def getUnit [Monoid α] : α :=
  1
</code></pre>
<h2><a class="header" href="#output-parameters" id="output-parameters">Output parameters</a></h2>
<p>By default, Lean only tries to synthesize an instance <code>Inhabited T</code> when the term <code>T</code> is known and does not
contain missing parts. The following command produces the error
&quot;failed to create type class instance for <code>Inhabited (Nat × ?m.1499)</code>&quot; because the type has a missing part (i.e., the <code>_</code>).</p>
<pre><code class="language-lean">#check_failure (inferInstance : Inhabited (Nat × _))
</code></pre>
<p>You can view the parameter of the type class <code>Inhabited</code> as an <em>input</em> value for the type class synthesizer.
When a type class has multiple parameters, you can mark some of them as output parameters.
Lean will start type class synthesizer even when these parameters have missing parts.
In the following example, we use output parameters to define a <em>heterogeneous</em> polymorphic
multiplication.</p>
<pre><code class="language-lean"><span class="boring">namespace Ex
</span>class HMul (α : Type u) (β : Type v) (γ : outParam (Type w)) where
  hMul : α → β → γ

export HMul (hMul)

instance : HMul Nat Nat Nat where
  hMul := Nat.mul

instance : HMul Nat (Array Nat) (Array Nat) where
  hMul a bs := bs.map (fun b =&gt; hMul a b)

#eval hMul 4 3           -- 12
#eval hMul 4 #[2, 3, 4]  -- #[8, 12, 16]
<span class="boring">end Ex
</span></code></pre>
<p>The parameters <code>α</code> and <code>β</code> are considered input parameters and <code>γ</code> an output one.
Given an application <code>hMul a b</code>, after types of <code>a</code> and <code>b</code> are known, the type class
synthesizer is invoked, and the resulting type is obtained from the output parameter <code>γ</code>.
In the example above, we defined two instances. The first one is the homogeneous
multiplication for natural numbers. The second is the scalar multiplication for arrays.
Note that you chain instances and generalize the second instance.</p>
<pre><code class="language-lean"><span class="boring">namespace Ex
</span>class HMul (α : Type u) (β : Type v) (γ : outParam (Type w)) where
  hMul : α → β → γ

export HMul (hMul)

instance : HMul Nat Nat Nat where
  hMul := Nat.mul

instance : HMul Int Int Int where
  hMul := Int.mul

instance [HMul α β γ] : HMul α (Array β) (Array γ) where
  hMul a bs := bs.map (fun b =&gt; hMul a b)

#eval hMul 4 3                    -- 12
#eval hMul 4 #[2, 3, 4]           -- #[8, 12, 16]
#eval hMul (-2) #[3, -1, 4]       -- #[-6, 2, -8]
#eval hMul 2 #[#[2, 3], #[0, 4]]  -- #[#[4, 6], #[0, 8]]
<span class="boring">end Ex
</span></code></pre>
<p>You can use our new scalar array multiplication instance on arrays of type <code>Array β</code>
with a scalar of type <code>α</code> whenever you have an instance <code>HMul α β γ</code>.
In the last <code>#eval</code>, note that the instance was used twice on an array of arrays.</p>
<h2><a class="header" href="#default-instances" id="default-instances">Default instances</a></h2>
<p>In the class <code>HMul</code>, the parameters <code>α</code> and <code>β</code> are treated as input values.
Thus, type class synthesis only starts after these two types are known. This may often
be too restrictive.</p>
<pre><code class="language-lean"><span class="boring">namespace Ex
</span>class HMul (α : Type u) (β : Type v) (γ : outParam (Type w)) where
  hMul : α → β → γ

export HMul (hMul)

instance : HMul Int Int Int where
  hMul := Int.mul

def xs : List Int := [1, 2, 3]

-- Error &quot;failed to create type class instance for HMul Int ?m.1767 (?m.1797 x)&quot;
#check_failure fun y =&gt; xs.map (fun x =&gt; hMul x y)
<span class="boring">end Ex
</span></code></pre>
<p>The instance <code>HMul</code> is not synthesized by Lean because the type of <code>y</code> has not been provided.
However, it is natural to assume that the type of <code>y</code> and <code>x</code> should be the same in
this kind of situation. We can achieve exactly that using <em>default instances</em>.</p>
<pre><code class="language-lean"><span class="boring">namespace Ex
</span>class HMul (α : Type u) (β : Type v) (γ : outParam (Type w)) where
  hMul : α → β → γ

export HMul (hMul)

@[defaultInstance]
instance : HMul Int Int Int where
  hMul := Int.mul

def xs : List Int := [1, 2, 3]

#check fun y =&gt; xs.map (fun x =&gt; hMul x y)  -- Int -&gt; List Int
<span class="boring">end Ex
</span></code></pre>
<p>By tagging the instance above with the attribute <code>defaultInstance</code>, we are instructing Lean
to use this instance on pending type class synthesis problems.
The actual Lean implementation defines homogeneous and heterogeneous classes for arithmetical operators.
Moreover, <code>a+b</code>, <code>a*b</code>, <code>a-b</code>, <code>a/b</code>, and <code>a%b</code> are notations for the heterogeneous versions.
The instance <code>OfNat Nat n</code> is the default instance for the <code>OfNat</code> class. This is why the numeral
<code>2</code> has type <code>Nat</code> when the expected type is not known. You can define default instances with higher
priority to override the builtin ones.</p>
<pre><code class="language-lean">structure Rational where
  num : Int
  den : Nat
  inv : den ≠ 0

@[defaultInstance 1]
instance : OfNat Rational n where
  ofNat := { num := n, den := 1, inv := by decide }

instance : ToString Rational where
  toString r := s!&quot;{r.num}/{r.den}&quot;

#check 2 -- Rational
</code></pre>
<p>Priorities are also useful to control the interaction between different default instances.
For example, suppose <code>xs</code> has type <code>α</code>, when elaboration <code>xs.map (fun x =&gt; 2 * x)</code>, we want the homogeneous instance for multiplication
to have higher priority than the default instance for <code>OfNat</code>. This is particularly important when we have implemented only the instance
<code>HMul α α α</code>, and did not implement <code>HMul Nat α α</code>.
Now, we reveal how the notation <code>a*b</code> is defined in Lean.</p>
<pre><code class="language-lean"><span class="boring">namespace Ex
</span>class OfNat (α : Type u) (n : Nat) where
  ofNat : α

@[defaultInstance]
instance (n : Nat) : OfNat Nat n where
  ofNat := n

class HMul (α : Type u) (β : Type v) (γ : outParam (Type w)) where
  hMul : α → β → γ

class Mul (α : Type u) where
  mul : α → α → α

@[defaultInstance 10]
instance [Mul α] : HMul α α α where
  hMul a b := Mul.mul a b

infixl:70 &quot; * &quot;  =&gt; HMul.hMul
<span class="boring">end Ex
</span></code></pre>
<p>The <code>Mul</code> class is convenient for types that only implement the homogeneous multiplication.</p>
<h2><a class="header" href="#local-instances" id="local-instances">Local Instances</a></h2>
<p>Type classes are implemented using attributes in Lean. Thus, you can
use the <code>local</code> modifier to indicate that they only have effect until
the current <code>section</code> or <code>namespace</code> is closed, or until the end
of the current file.</p>
<pre><code class="language-lean">structure Point where
  x : Nat
  y : Nat

section

local instance : Add Point where
  add a b := { x := a.x + b.x, y := a.y + b.y }

def double (p : Point) :=
  p + p

end -- instance `Add Point` is not active anymore

-- def triple (p : Point) :=
--  p + p + p  -- Error: failed to sythesize instance
</code></pre>
<p>You can also temporarily disable an instance using the <code>attribute</code> command
until the current <code>section</code> or <code>namespace</code> is closed, or until the end
of the current file.</p>
<pre><code class="language-lean">structure Point where
  x : Nat
  y : Nat

instance addPoint : Add Point where
  add a b := { x := a.x + b.x, y := a.y + b.y }

def double (p : Point) :=
  p + p

attribute [-instance] addPoint

-- def triple (p : Point) :=
--  p + p + p  -- Error: failed to sythesize instance
</code></pre>
<p>We recommend you only use this command to diagnose problems.</p>
<h2><a class="header" href="#scoped-instances" id="scoped-instances">Scoped Instances</a></h2>
<p>You can also declare scoped instances in namespaces. This kind of instance is
only active when you are inside of the namespace or open the namespace.</p>
<pre><code class="language-lean">structure Point where
  x : Nat
  y : Nat

namespace Point

scoped instance : Add Point where
  add a b := { x := a.x + b.x, y := a.y + b.y }

def double (p : Point) :=
  p + p

end Point
-- instance `Add Point` is not active anymore

-- #check fun (p : Point) =&gt; p + p + p  -- Error

namespace Point
-- instance `Add Point` is active again
#check fun (p : Point) =&gt; p + p + p

end Point

open Point -- activates instance `Add Point`
#check fun (p : Point) =&gt; p + p + p
</code></pre>
<p>You can use the command <code>open scoped &lt;namespace&gt;</code> to activate scoped attributes but will
not &quot;open&quot; the names from the namespace.</p>
<pre><code class="language-lean">structure Point where
  x : Nat
  y : Nat

namespace Point

scoped instance : Add Point where
  add a b := { x := a.x + b.x, y := a.y + b.y }

def double (p : Point) :=
  p + p

end Point

open scoped Point -- activates instance `Add Point`
#check fun (p : Point) =&gt; p + p + p

-- #check fun (p : Point) =&gt; double p -- Error: unknown identifier 'double'
</code></pre>
<h2><a class="header" href="#decidable-propositions" id="decidable-propositions">Decidable Propositions</a></h2>
<p>Let us consider another example of a type class defined in the
standard library, namely the type class of <code>Decidable</code>
propositions. Roughly speaking, an element of <code>Prop</code> is said to be
decidable if we can decide whether it is true or false. The
distinction is only useful in constructive mathematics; classically,
every proposition is decidable. But if we use the classical principle,
say, to define a function by cases, that function will not be
computable. Algorithmically speaking, the <code>Decidable</code> type class can
be used to infer a procedure that effectively determines whether or
not the proposition is true. As a result, the type class supports such
computational definitions when they are possible while at the same
time allowing a smooth transition to the use of classical definitions
and classical reasoning.</p>
<p>In the standard library, <code>Decidable</code> is defined formally as follows:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>class inductive Decidable (p : Prop) where
  | isFalse (h : ¬p) : Decidable p
  | isTrue  (h : p)  : Decidable p
<span class="boring">end Hidden
</span></code></pre>
<p>Logically speaking, having an element <code>t : Decidable p</code> is stronger
than having an element <code>t : p ∨ ¬p</code>; it enables us to define values
of an arbitrary type depending on the truth value of <code>p</code>. For
example, for the expression <code>if p then a else b</code> to make sense, we
need to know that <code>p</code> is decidable. That expression is syntactic
sugar for <code>ite p a b</code>, where <code>ite</code> is defined as follows:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>def ite {α : Sort u} (c : Prop) [h : Decidable c] (t e : α) : α :=
  Decidable.casesOn (motive := fun _ =&gt; α) h (fun _ =&gt; e) (fun _ =&gt; t)
<span class="boring">end Hidden
</span></code></pre>
<p>The standard library also contains a variant of <code>ite</code> called
<code>dite</code>, the dependent if-then-else expression. It is defined as
follows:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>def dite {α : Sort u} (c : Prop) [h : Decidable c] (t : c → α) (e : Not c → α) : α :=
  Decidable.casesOn (motive := fun _ =&gt; α) h e t
<span class="boring">end Hidden
</span></code></pre>
<p>That is, in <code>dite c t e</code>, we can assume <code>hc : c</code> in the &quot;then&quot;
branch, and <code>hnc : ¬ c</code> in the &quot;else&quot; branch. To make <code>dite</code> more
convenient to use, Lean allows us to write <code>if h : c then t else e</code>
instead of <code>dite c (λ h : c, t) (λ h : ¬ c, e)</code>.</p>
<p>Without classical logic, we cannot prove that every proposition is
decidable. But we can prove that <em>certain</em> propositions are
decidable. For example, we can prove the decidability of basic
operations like equality and comparisons on the natural numbers and
the integers. Moreover, decidability is preserved under propositional
connectives:</p>
<pre><code class="language-lean">#check @instDecidableAnd
  -- {p q : Prop} → [Decidable p] → [Decidable q] → Decidable (And p q)

#check @instDecidableOr
#check @instDecidableNot
#check @instDecidableArrow
</code></pre>
<p>Thus we can carry out definitions by cases on decidable predicates on
the natural numbers:</p>
<pre><code class="language-lean">def step (a b x : Nat) : Nat :=
  if x &lt; a ∨ x &gt; b then 0 else 1

set_option pp.explicit true
#print step
</code></pre>
<p>Turning on implicit arguments shows that the elaborator has inferred
the decidability of the proposition <code>x &lt; a ∨ x &gt; b</code>, simply by
applying appropriate instances.</p>
<p>With the classical axioms, we can prove that every proposition is
decidable. You can import the classical axioms and make the generic
instance of decidability available by opening the <code>Classical</code> namespace.</p>
<pre><code class="language-lean">open Classical
</code></pre>
<p>Thereafter <code>decidable p</code> has an instance for every <code>p</code>.
Thus all theorems in the library
that rely on decidability assumptions are freely available when you
want to reason classically. In <a href="./axioms_and_computation.html">Chapter Axioms and Computation</a>,
we will see that using the law of the
excluded middle to define functions can prevent them from being used
computationally. Thus, the standard library assigns a low priority to
the <code>propDecidable</code> instance.</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>open Classical
noncomputable scoped
instance (priority := low) propDecidable (a : Prop) : Decidable a :=
  choice &lt;| match em a with
    | Or.inl h =&gt; ⟨isTrue h⟩
    | Or.inr h =&gt; ⟨isFalse h⟩
<span class="boring">end Hidden
</span></code></pre>
<p>The guarantees that Lean will favor other instances and fall back on
<code>propDecidable</code> only after other attempts to infer decidability have
failed.</p>
<p>The <code>Decidable</code> type class also provides a bit of small-scale
automation for proving theorems. The standard library introduces the
tactic <code>decide</code> that uses the <code>Decidable</code> instance to solve simple goals.</p>
<pre><code class="language-lean">example : 10 &lt; 5 ∨ 1 &gt; 0 := by
  decide

example : ¬ (True ∧ False) := by
  decide

example : 10 * 20 = 200 := by
  decide

theorem ex : True ∧ 2 = 1+1 := by
  decide

#print ex
-- theorem ex : True ∧ 2 = 1 + 1 :=
-- of_decide_eq_true (Eq.refl true)

#check @of_decide_eq_true
-- ∀ {p : Prop} [Decidable p], decide p = true → p

#check @decide
-- (p : Prop) → [Decidable p] → Bool
</code></pre>
<p>They work as follows. The expression <code>decide p</code> tries to infer a
decision procedure for <code>p</code>, and, if it is successful, evaluates to
either <code>true</code> or <code>false</code>. In particular, if <code>p</code> is a true closed
expression, <code>decide p</code> will reduce definitionally to the Boolean <code>true</code>.
On the assumption that <code>decide p = true</code> holds, <code>of_decide_eq_true</code>
produces a proof of <code>p</code>. The tactic <code>decide</code> puts it all together: to
prove a target <code>p</code>. By the previous observations,
<code>decide</code> will succeed any time the inferred decision procedure
for <code>c</code> has enough information to evaluate, definitionally, to the <code>isTrue</code> case.</p>
<h2><a class="header" href="#managing-type-class-inference" id="managing-type-class-inference">Managing Type Class Inference</a></h2>
<p>If you are ever in a situation where you need to supply an expression
that Lean can infer by type class inference, you can ask Lean to carry
out the inference using <code>inferInstance</code>:</p>
<pre><code class="language-lean">def foo : Add Nat := inferInstance
def bar : Inhabited (Nat → Nat) := inferInstance

#check @inferInstance
-- {α : Sort u} → [α] → α
</code></pre>
<p>In fact, you can use Lean's <code>(t : T)</code> notation to specify the class whose instance you are looking for,
in a concise manner:</p>
<pre><code class="language-lean">#check (inferInstance : Add Nat)
</code></pre>
<p>You can also use the auxiliary definition <code>inferInstanceAs</code>:</p>
<pre><code class="language-lean">#check inferInstanceAs (Add Nat)

#check @inferInstanceAs
-- (α : Sort u) → [α] → α
</code></pre>
<p>Sometimes Lean can't find an instance because the class is buried
under a definition. For example, Lean cannot
find an instance of <code>Inhabited (Set α)</code>. We can declare one
explicitly:</p>
<pre><code class="language-lean">
def Set (α : Type u) := α → Prop

-- fails
-- example : Inhabited (Set α) :=
--  inferInstance

instance : Inhabited (Set α) :=
  inferInstanceAs (Inhabited (α → Prop))
</code></pre>
<p>At times, you may find that the type class inference fails to find an
expected instance, or, worse, falls into an infinite loop and times
out. To help debug in these situations, Lean enables you to request a
trace of the search:</p>
<pre><code>set_option trace.Meta.synthInstance true
</code></pre>
<p>If you are using VS Code, you can read the results by hovering over
the relevant theorem or definition, or opening the messages window
with <code>Ctrl-Shift-Enter</code>. In Emacs, you can use <code>C-c C-x</code> to run an
independent Lean process on your file, and the output buffer will show
a trace every time the type class resolution procedure is subsequently
triggered.</p>
<p>You can also limit the search using the following options:</p>
<pre><code>set_option synthInstance.maxHeartbeats 10000
set_option synthInstance.maxSize 400
</code></pre>
<p>Option <code>synthInstance.maxHeartbeats</code> specifies the maximum amount of
heartbeats per typeclass resolution problem. A heartbeat is number of
(small) memory allocations (in thousands), 0 means there is no limit.
Option <code>synthInstance.maxSize</code> is the maximum number of instances used
to construct a solution in the type class instance synthesis procedure</p>
<p>Remember also that in both the VS Code and Emacs editor modes, tab
completion works in <code>set_option</code>, to help you find suitable options.</p>
<p>As noted above, the type class instances in a given context represent
a Prolog-like program, which gives rise to a backtracking search. Both
the efficiency of the program and the solutions that are found can
depend on the order in which the system tries the instance. Instances
which are declared last are tried first. Moreover, if instances are
declared in other modules, the order in which they are tried depends
on the order in which namespaces are opened. Instances declared in
namespaces which are opened later are tried earlier.</p>
<p>You can change the order that type classes instances are tried by
assigning them a <em>priority</em>. When an instance is declared, it is
assigned a default priority value. You can assign other priorities
when defining an instance. The following example illustrates how this
is done:</p>
<pre><code class="language-lean">class Foo where
  a : Nat
  b : Nat

instance (priority := default+1) i1 : Foo where
  a := 1
  b := 1

instance i2 : Foo where
  a := 2
  b := 2

example : Foo.a = 1 :=
  rfl

instance (priority := default+2) i3 : Foo where
  a := 3
  b := 3

example : Foo.a = 3 :=
  rfl
</code></pre>
<!--
TODO: we may change the coercion mechanism
.. _coercions_using_type_classes:

Coercions using Type Classes
----------------------------

The most basic type of coercion maps elements of one type to another. For example, a coercion from ``nat`` to ``int`` allows us to view any element ``n : nat`` as an element of ``int``. But some coercions depend on parameters; for example, for any type ``α``, we can view any element ``l : list α`` as an element of ``set α``, namely, the set of elements occurring in the list. The corresponding coercion is defined on the "family" of types ``list α``, parameterized by ``α``.

Lean allows us to declare three kinds of coercions:

-  from a family of types to another family of types
-  from a family of types to the class of sorts
-  from a family of types to the class of function types

The first kind of coercion allows us to view any element of a member of the source family as an element of a corresponding member of the target family. The second kind of coercion allows us to view any element of a member of the source family as a type. The third kind of coercion allows us to view any element of the source family as a function. Let us consider each of these in turn.

In Lean, coercions are implemented on top of the type class resolution framework. We define a coercion from ``α`` to ``β`` by declaring an instance of ``has_coe α β``. For example, we can define a coercion from ``bool`` to ``Prop`` as follows:

.. code-block:: lean

    instance bool_to_Prop : has_coe bool Prop :=
    ⟨λ b, b = tt⟩

This enables us to use boolean terms in if-then-else expressions:

.. code-block:: lean

    instance bool_to_Prop : has_coe bool Prop :=
    ⟨λ b, b = tt⟩
    -- BEGIN
    #reduce if tt then 3 else 5
    #reduce if ff then 3 else 5
    -- END

We can define a coercion from ``list α`` to ``set α`` as follows:

.. code-block:: lean

    def list.to_set {α : Type*} : list α → set α
    | []     := ∅
    | (h::t) := {h} ∪ list.to_set t

    instance list_to_set_coe (α : Type*) :
      has_coe (list α) (set α) :=
    ⟨list.to_set⟩

    def s : set nat  := {1, 2}
    def l : list nat := [3, 4]

    #check s ∪ l -- set nat

Coercions are only considered if the given and expected types do not contain metavariables at elaboration time. In the following example, when we elaborate the union operator, the type of ``[3, 2]`` is ``list ?m``, and a coercion will not be considered since it contains metavariables.

.. code-block:: lean

    def list.to_set {α : Type*} : list α → set α
    | []     := ∅
    | (h::t) := {h} ∪ list.to_set t

    instance list_to_set_coe (α : Type*) :
      has_coe (list α) (set α) :=
    ⟨list.to_set⟩

    def s : set nat  := {1, 2}

    -- BEGIN
    /- The following #check command produces an error. -/
    -- #check s ∪ [3, 2]
    -- END

We can work around this issue by using a type ascription.

.. code-block:: lean

    def list.to_set {α : Type*} : list α → set α
    | []     := ∅
    | (h::t) := {h} ∪ list.to_set t

    instance list_to_set_coe (α : Type*) :
      has_coe (list α) (set α) :=
    ⟨list.to_set⟩

    def s : set nat  := {1, 2}

    -- BEGIN
    #check s ∪ [(3:nat), 2]
    -- or
    #check s ∪ ([3, 2] : list nat)
    -- END

In the examples above, you may have noticed the symbol ``↑`` produced by the ``#check`` commands. It is the lift operator, ``↑t`` is notation for ``coe t``. We can use this operator to force a coercion to be introduced in a particular place. It is also helpful to make our intent clear, and work around limitations of the coercion resolution system.

.. code-block:: lean

    def list.to_set {α : Type*} : list α → set α
    | []     := ∅
    | (h::t) := {h} ∪ list.to_set t

    instance list_to_set_coe (α : Type*) :
      has_coe (list α) (set α) :=
    ⟨list.to_set⟩

    def s : set nat  := {1, 2}

    -- BEGIN
    #check s ∪ ↑[3, 2]

    variables n m : nat
    variable i : int
    #check i + ↑n + ↑m
    #check i + ↑(n + m)
    #check ↑n + i
    -- END

In the first two examples, the coercions are not strictly necessary since Lean will insert implicit nat → int coercions. However, ``#check n + i`` would raise an error, because the expected type of ``i`` is nat in order to match the type of n, and no int → nat coercion exists). In the third example, we therefore insert an explicit ``↑`` to coerce ``n`` to ``int``.

The standard library defines a coercion from subtype ``{x : α // p x}`` to ``α`` as follows:

.. code-block:: lean

    namespace hidden
    -- BEGIN
    instance coe_subtype {α : Type*} {p : α → Prop} :
      has_coe {x // p x} α :=
    ⟨λ s, subtype.val s⟩
    -- END
    end hidden

Lean will also chain coercions as necessary. Actually, the type class ``has_coe_t`` is the transitive closure of ``has_coe``. You may have noticed that the type of ``coe`` depends on ``has_lift_t``, the transitive closure of the type class ``has_lift``, instead of ``has_coe_t``. Every instance of ``has_coe_t`` is also an instance of ``has_lift_t``, but the elaborator only introduces automatically instances of ``has_coe_t``. That is, to be able to coerce using an instance of ``has_lift_t``, we must use the operator ``↑``. In the standard library, we have the following instance:

.. code-block:: lean

    namespace hidden
    universes u v

    instance lift_list {a : Type u} {b : Type v} [has_lift_t a b] :
      has_lift (list a) (list b) :=
    ⟨λ l, list.map (@coe a b _) l⟩

    variables s : list nat
    variables r : list int
    #check ↑s ++ r

    end hidden

It is not an instance of ``has_coe`` because lists are frequently used for writing programs, and we do not want a linear-time operation to be silently introduced by Lean, and potentially mask mistakes performed by the user. By forcing the user to write ``↑``, she is making her intent clear to Lean.

Let us now consider the second kind of coercion. By the *class of sorts*, we mean the collection of universes ``Type u``. A coercion of the second kind is of the form

.. code-block:: text

    c : Π x1 : A1, ..., xn : An, F x1 ... xn → Type u

where ``F`` is a family of types as above. This allows us to write ``s : t`` whenever ``t`` is of type ``F a1 ... an``. In other words, the coercion allows us to view the elements of ``F a1 ... an`` as types. This is very useful when defining algebraic structures in which one component, the carrier of the structure, is a ``Type``. For example, we can define a semigroup as follows:

.. code-block:: lean

    universe u

    structure Semigroup : Type (u+1) :=
    (carrier : Type u)
    (mul : carrier → carrier → carrier)
    (mul_assoc : ∀ a b c : carrier,
                   mul (mul a b) c = mul a (mul b c))

    instance Semigroup_has_mul (S : Semigroup) :
      has_mul (S.carrier) :=
    ⟨S.mul⟩

In other words, a semigroup consists of a type, ``carrier``, and a multiplication, ``mul``, with the property that the multiplication is associative. The ``instance`` command allows us to write ``a * b`` instead of ``Semigroup.mul S a b`` whenever we have ``a b : S.carrier``; notice that Lean can infer the argument ``S`` from the types of ``a`` and ``b``. The function ``Semigroup.carrier`` maps the class ``Semigroup`` to the sort ``Type u``:

.. code-block:: lean

    universe u

    structure Semigroup : Type (u+1) :=
    (carrier : Type u)
    (mul : carrier → carrier → carrier)
    (mul_assoc : ∀ a b c : carrier,
                   mul (mul a b) c = mul a (mul b c))

    instance Semigroup_has_mul (S : Semigroup) : has_mul (S.carrier) :=
    ⟨S.mul⟩
    -- BEGIN
    #check Semigroup.carrier
    -- END

If we declare this function to be a coercion, then whenever we have a semigroup ``S : Semigroup``, we can write ``a : S`` instead of ``a : S.carrier``:

.. code-block:: lean

    universe u

    structure Semigroup : Type (u+1) :=
    (carrier : Type u)
    (mul : carrier → carrier → carrier)
    (mul_assoc : ∀ a b c : carrier, mul (mul a b) c = mul a (mul b c))

    instance Semigroup_has_mul (S : Semigroup) : has_mul (S.carrier) :=
    ⟨S.mul⟩

    -- BEGIN
    instance Semigroup_to_sort : has_coe_to_sort Semigroup :=
    {S := Type u, coe := λ S, S.carrier}

    example (S : Semigroup) (a b c : S) :
      (a * b) * c = a * (b * c) :=
    Semigroup.mul_assoc _ a b c
    -- END

It is the coercion that makes it possible to write ``(a b c : S)``. Note that, we define an instance of ``has_coe_to_sort Semigroup`` instead of ``has_coe Semigroup Type``. The reason is that when Lean needs a coercion to sort, it only knows it needs a type, but, in general, the universe is not known. The field ``S`` in the class ``has_coe_to_sort`` is used to specify the universe we are coercing too.

By the *class of function types*, we mean the collection of Pi types ``Π z : B, C``. The third kind of coercion has the form

.. code-block:: text

    c : Π x1 : A1, ..., xn : An, y : F x1 ... xn, Π z : B, C

where ``F`` is again a family of types and ``B`` and ``C`` can depend on ``x1, ..., xn, y``. This makes it possible to write ``t s`` whenever ``t`` is an element of ``F a1 ... an``. In other words, the coercion enables us to view elements of ``F a1 ... an`` as functions. Continuing the example above, we can define the notion of a morphism between semigroups ``S1`` and ``S2``. That is, a function from the carrier of ``S1`` to the carrier of ``S2`` (note the implicit coercion) that respects the multiplication. The projection ``morphism.mor`` takes a morphism to the underlying function:

.. code-block:: lean

    universe u

    structure Semigroup : Type (u+1) :=
    (carrier : Type u)
    (mul : carrier → carrier → carrier)
    (mul_assoc : ∀ a b c : carrier, mul (mul a b) c = mul a (mul b c))

    instance Semigroup_has_mul (S : Semigroup) : has_mul (S.carrier) :=
    ⟨S.mul⟩

    -- BEGIN
    instance Semigroup_to_sort : has_coe_to_sort Semigroup :=
    {S := _, coe := λ S, S.carrier}

    structure morphism (S1 S2 : Semigroup) :=
    (mor : S1 → S2)
    (resp_mul : ∀ a b : S1, mor (a * b) = (mor a) * (mor b))

    #check @morphism.mor
    -- END

As a result, it is a prime candidate for the third type of coercion.

.. code-block:: lean

    universe u

    structure Semigroup : Type (u+1) :=
    (carrier : Type u)
    (mul : carrier → carrier → carrier)
    (mul_assoc : ∀ a b c : carrier, mul (mul a b) c = mul a (mul b c))

    instance Semigroup_has_mul (S : Semigroup) : has_mul (S.carrier) :=
    ⟨S.mul⟩


    instance Semigroup_to_sort : has_coe_to_sort Semigroup :=
    {S := _, coe := λ S, S.carrier}

    structure morphism (S1 S2 : Semigroup) :=
    (mor : S1 → S2)
    (resp_mul : ∀ a b : S1, mor (a * b) = (mor a) * (mor b))

    -- BEGIN
    instance morphism_to_fun (S1 S2 : Semigroup) :
      has_coe_to_fun (morphism S1 S2) :=
    { F   := λ _, S1 → S2,
      coe := λ m, m.mor }

    lemma resp_mul {S1 S2 : Semigroup}
        (f : morphism S1 S2) (a b : S1) :
      f (a * b) = f a * f b :=
    f.resp_mul a b

    example (S1 S2 : Semigroup) (f : morphism S1 S2) (a : S1) :
      f (a * a * a) = f a * f a * f a :=
    calc
      f (a * a * a) = f (a * a) * f a : by rw [resp_mul f]
                ... = f a * f a * f a : by rw [resp_mul f]
    -- END

With the coercion in place, we can write ``f (a * a * a)`` instead of ``morphism.mor f (a * a * a)``. When the ``morphism``, ``f``, is used where a function is expected, Lean inserts the coercion. Similar to ``has_coe_to_sort``, we have yet another class ``has_coe_to_fun`` for this class of coercions. The field ``F`` is used to specify the function type we are coercing to. This type may depend on the type we are coercing from.

Finally, ``⇑f`` and ``↥S`` are notations for ``coe_fn f`` and ``coe_sort S``. They are the coercion operators for the function and sort classes.

We can instruct Lean's pretty-printer to hide the operators ``↑`` and ``⇑`` with ``set_option``.

.. code-block:: lean

    universe u

    structure Semigroup : Type (u+1) :=
    (carrier : Type u)
    (mul : carrier → carrier → carrier)
    (mul_assoc : ∀ a b c : carrier, mul (mul a b) c = mul a (mul b c))

    instance Semigroup_has_mul (S : Semigroup) : has_mul (S.carrier) :=
    ⟨S.mul⟩

    instance Semigroup_to_sort : has_coe_to_sort Semigroup :=
    {S := _, coe := λ S, S.carrier}

    structure morphism (S1 S2 : Semigroup) :=
    (mor : S1 → S2)
    (resp_mul : ∀ a b : S1, mor (a * b) = (mor a) * (mor b))

    instance morphism_to_fun (S1 S2 : Semigroup) : has_coe_to_fun (morphism S1 S2) :=
    { F   := λ _, S1 → S2,
      coe := λ m, m.mor }

    lemma resp_mul {S1 S2 : Semigroup} (f : morphism S1 S2) (a b : S1) : f (a * b) = f a * f b :=
    f.resp_mul a b

    -- BEGIN
    theorem test (S1 S2 : Semigroup)
        (f : morphism S1 S2) (a : S1) :
      f (a * a * a) = f a * f a * f a :=
    calc
      f (a * a * a) = f (a * a) * f a : by rw [resp_mul f]
                ... = f a * f a * f a : by rw [resp_mul f]

    #check @test
    set_option pp.coercions false
    #check @test
    -- END
-->
<h1><a class="header" href="#转换策略模式" id="转换策略模式">转换策略模式</a></h1>
<p>在策略块中，可以使用关键字<code>conv</code>进入转换模式。这种模式允许在假设和目标内部，甚至在函数抽象和依赖箭头内部移动，以应用重写或简化步骤。</p>
<h2><a class="header" href="#基本导航和重写" id="基本导航和重写">基本导航和重写</a></h2>
<p>作为第一个例子，让我们证明<code>(a b c : Nat) : a * (b * c) = a * (c * b)</code>（本段中的例子有些刻意设计，因为其他策略可以立即完成它们）。首次简单的尝试是尝试<code>rw [Nat.mul_comm]</code>，但这将目标转化为<code>b * c * a = a * (c * b)</code>，在换算了项中出现的第一个乘法后。有几种方法可以解决这个问题，其中一个方法是使用一个更精确的工具：转换模式。下面的代码块显示了每行之后的当前目标。</p>
<pre><code class="language-lean">example (a b c : Nat) : a * (b * c) = a * (c * b) := by
  conv =&gt;
    -- |- a * (b * c) = a * (c * b)
    lhs
    -- |- a * (b * c)
    congr
    -- 2 goals : |- a and |- b * c
    skip
    -- |- b * c
    rw [Nat.mul_comm]
</code></pre>
<p>上面这段设计三个导航指令：</p>
<ul>
<li><code>lhs</code>（left hand side）导航到关系（此处是等式）左边。同理<code>rhs</code>导航到右边。</li>
<li><code>congr</code>创建与当前头函数的(非依赖的和显式的)参数数量一样多的目标（此处的头函数是乘法）。</li>
<li><code>skip</code>走到下一个目标。</li>
</ul>
<p>一旦到达相关目标，我们就可以像在普通策略模式中一样使用<code>rw</code>。</p>
<p>使用转换模式的第二个主要原因是在约束器下重写。假设我们想证明<code>(fun x : Nat =&gt; 0 + x) = (fun x =&gt; x)</code>。首次简单的尝试<code>rw [zero_add]</code>是失败的。报错：</p>
<pre><code>error: tactic 'rewrite' failed, did not find instance of the pattern
       in the target expression
  0 + ?n
⊢ (fun x =&gt; 0 + x) = fun x =&gt; x
</code></pre>
<p>（错误：'rewrite'策略失败了，没有找到目标表达式中的模式0 + ?n）</p>
<p>正确的结果为：</p>
<pre><code class="language-lean">example : (fun x : Nat =&gt; 0 + x) = (fun x =&gt; x) := by
  conv =&gt;
    lhs
    intro x
    rw [Nat.zero_add]
</code></pre>
<p>其中<code>intro x</code>是导航命令，它进入了<code>fun</code>约束器。这个例子有点刻意，你也可以这样做：</p>
<pre><code class="language-lean">example : (fun x : Nat =&gt; 0 + x) = (fun x =&gt; x) := by
  funext x; rw [Nat.zero_add]
</code></pre>
<p>或者这样：</p>
<pre><code class="language-lean">example : (fun x : Nat =&gt; 0 + x) = (fun x =&gt; x) := by
  simp
</code></pre>
<p>所有这些也可以用<code>conv at h</code>从局部上下文重写一个假设<code>h</code>。</p>
<h2><a class="header" href="#模式匹配" id="模式匹配">模式匹配</a></h2>
<p>使用上面的命令进行导航可能很无聊。使用下面的模式匹配来简化它：</p>
<pre><code class="language-lean">example (a b c : Nat) : a * (b * c) = a * (c * b) := by
  conv in b * c =&gt; rw [Nat.mul_comm]
</code></pre>
<p>这是下面代码的语法糖：</p>
<pre><code class="language-lean">example (a b c : Nat) : a * (b * c) = a * (c * b) := by
  conv =&gt;
    pattern b * c
    rw [Nat.mul_comm]
</code></pre>
<p>当然也可以用通配符：</p>
<pre><code class="language-lean">example (a b c : Nat) : a * (b * c) = a * (c * b) := by
  conv in _ * c =&gt; rw [Nat.mul_comm]
</code></pre>
<h2><a class="header" href="#结构化转换策略" id="结构化转换策略">结构化转换策略</a></h2>
<p>大括号和<code>.</code>也可以在<code>conv</code>模式下用于结构化策略。</p>
<pre><code class="language-lean">example (a b c : Nat) : (0 + a) * (b * c) = a * (c * b) := by
  conv =&gt;
    lhs
    congr
    . rw [Nat.zero_add]
    . rw [Nat.mul_comm]
</code></pre>
<h2><a class="header" href="#转换模式中的其他策略" id="转换模式中的其他策略">转换模式中的其他策略</a></h2>
<ul>
<li><code>arg i</code>进入一个应用的第<code>i</code>个非独立显式参数。</li>
</ul>
<pre><code class="language-lean">example (a b c : Nat) : a * (b * c) = a * (c * b) := by
  conv =&gt;
    -- |- a * (b * c) = a * (c * b)
    lhs
    -- |- a * (b * c)
    arg 2
    -- |- b * c
    rw [Nat.mul_comm]
</code></pre>
<ul>
<li>
<p><code>args</code>是<code>congr</code>的替代品。</p>
</li>
<li>
<p><code>simp</code>将简化器应用于当前目标。它支持常规策略模式中的相同选项。</p>
</li>
</ul>
<pre><code class="language-lean">def f (x : Nat) :=
  if x &gt; 0 then x + 1 else x + 2

example (g : Nat → Nat) (h₁ : g x = x + 1) (h₂ : x &gt; 0) : g x = f x := by
  conv =&gt;
    rhs
    simp [f, h₂]
  exact h₁
</code></pre>
<ul>
<li><code>enter [1, x, 2, y]</code>是<code>arg</code>和<code>intro</code>使用给定参数的宏。</li>
</ul>
<pre><code>syntax enterArg := ident &lt;|&gt; num
syntax &quot;enter &quot; &quot;[&quot; (colGt enterArg),+ &quot;]&quot;: conv
macro_rules
  | `(conv| enter [$i:numLit]) =&gt; `(conv| arg $i)
  | `(conv| enter [$id:ident]) =&gt; `(conv| ext $id)
  | `(conv| enter [$arg:enterArg, $args,*]) =&gt; `(conv| (enter [$arg]; enter [$args,*]))
</code></pre>
<ul>
<li>
<p><code>done</code>会失败如果有未解决的目标。</p>
</li>
<li>
<p><code>traceState</code>显示当前策略状态。</p>
</li>
<li>
<p><code>whnf</code> put term in weak head normal form.</p>
</li>
<li>
<p><code>tactic =&gt; &lt;tactic sequence&gt;</code>回到常规策略模式。这对于退出<code>conv</code>模式不支持的目标，以及应用自定义的一致性和扩展性引理很有用。</p>
</li>
</ul>
<pre><code class="language-lean">example (g : Nat → Nat → Nat)
        (h₁ : ∀ x, x ≠ 0 → g x x = 1)
        (h₂ : x ≠ 0)
        : g x x + x = 1 + x := by
  conv =&gt;
    lhs
    -- |- g x x + x
    arg 1
    -- |- g x x
    rw [h₁]
    -- 2 goals: |- 1, |- x ≠ 0
    . skip
    . tactic =&gt; exact h₂
</code></pre>
<ul>
<li><code>apply &lt;term&gt;</code>是<code>tactic =&gt; apply &lt;term&gt;</code>的语法糖。</li>
</ul>
<pre><code class="language-lean">example (g : Nat → Nat → Nat)
        (h₁ : ∀ x, x ≠ 0 → g x x = 1)
        (h₂ : x ≠ 0)
        : g x x + x = 1 + x := by
  conv =&gt;
    lhs
    arg 1
    rw [h₁]
    . skip
    . apply h₂
</code></pre>
<h1><a class="header" href="#axioms-and-computation" id="axioms-and-computation">Axioms and Computation</a></h1>
<p>We have seen that the version of the Calculus of Constructions that
has been implemented in Lean includes dependent function types,
inductive types, and a hierarchy of universes that starts with an
impredicative, proof-irrelevant <code>Prop</code> at the bottom. In this
chapter, we consider ways of extending the CIC with additional axioms
and rules. Extending a foundational system in such a way is often
convenient; it can make it possible to prove more theorems, as well as
make it easier to prove theorems that could have been proved
otherwise. But there can be negative consequences of adding additional
axioms, consequences which may go beyond concerns about their
correctness. In particular, the use of axioms bears on the
computational content of definitions and theorems, in ways we will
explore here.</p>
<p>Lean is designed to support both computational and classical
reasoning. Users that are so inclined can stick to a &quot;computationally
pure&quot; fragment, which guarantees that closed expressions in the system
evaluate to canonical normal forms. In particular, any closed
computationally pure expression of type <code>Nat</code>, for example, will
reduce to a numeral.</p>
<p>Lean's standard library defines an additional axiom, propositional
extensionality, and a quotient construction which in turn implies the
principle of function extensionality. These extensions are used, for
example, to develop theories of sets and finite sets. We will see
below that using these theorems can block evaluation in Lean's kernel,
so that closed terms of type <code>Nat</code> no longer evaluate to numerals. But
Lean erases types and propositional information when compiling
definitions to bytecode for its virtual machine evaluator, and since
these axioms only add new propositions, they are compatible with that
computational interpretation. Even computationally inclined users may
wish to use the classical law of the excluded middle to reason about
computation. This also blocks evaluation in the kernel, but it is
compatible with compilation to bytecode.</p>
<p>The standard library also defines a choice principle that is entirely
antithetical to a computational interpretation, since it magically
produces &quot;data&quot; from a proposition asserting its existence. Its use is
essential to some classical constructions, and users can import it
when needed. But expressions that use this construction to produce
data do not have computational content, and in Lean we are required to
mark such definitions as <code>noncomputable</code> to flag that fact.</p>
<p>Using a clever trick (known as Diaconescu's theorem), one can use
propositional extensionality, function extensionality, and choice to
derive the law of the excluded middle. As noted above, however, use of
the law of the excluded middle is still compatible with bytecode
compilation and code extraction, as are other classical principles, as
long as they are not used to manufacture data.</p>
<p>To summarize, then, on top of the underlying framework of universes,
dependent function types, and inductive types, the standard library
adds three additional components:</p>
<ul>
<li>the axiom of propositional extensionality</li>
<li>a quotient construction, which implies function extensionality</li>
<li>a choice principle, which produces data from an existential proposition.</li>
</ul>
<p>The first two of these block normalization within Lean, but are
compatible with bytecode evaluation, whereas the third is not amenable
to computational interpretation. We will spell out the details more
precisely below.</p>
<h2><a class="header" href="#historical-and-philosophical-context" id="historical-and-philosophical-context">Historical and Philosophical Context</a></h2>
<p>For most of its history, mathematics was essentially computational:
geometry dealt with constructions of geometric objects, algebra was
concerned with algorithmic solutions to systems of equations, and
analysis provided means to compute the future behavior of systems
evolving over time. From the proof of a theorem to the effect that
&quot;for every <code>x</code>, there is a <code>y</code> such that ...&quot;, it was generally
straightforward to extract an algorithm to compute such a <code>y</code> given
<code>x</code>.</p>
<p>In the nineteenth century, however, increases in the complexity of
mathematical arguments pushed mathematicians to develop new styles of
reasoning that suppress algorithmic information and invoke
descriptions of mathematical objects that abstract away the details of
how those objects are represented. The goal was to obtain a powerful
&quot;conceptual&quot; understanding without getting bogged down in
computational details, but this had the effect of admitting
mathematical theorems that are simply <em>false</em> on a direct
computational reading.</p>
<p>There is still fairly uniform agreement today that computation is
important to mathematics. But there are different views as to how best
to address computational concerns. From a <em>constructive</em> point of
view, it is a mistake to separate mathematics from its computational
roots; every meaningful mathematical theorem should have a direct
computational interpretation. From a <em>classical</em> point of view, it is
more fruitful to maintain a separation of concerns: we can use one
language and body of methods to write computer programs, while
maintaining the freedom to use a nonconstructive theories and methods
to reason about them. Lean is designed to support both of these
approaches. Core parts of the library are developed constructively,
but the system also provides support for carrying out classical
mathematical reasoning.</p>
<p>Computationally, the purest part of dependent type theory avoids the
use of <code>Prop</code> entirely. Inductive types and dependent function types
can be viewed as data types, and terms of these types can be
&quot;evaluated&quot; by applying reduction rules until no more rules can be
applied. In principle, any closed term (that is, term with no free
variables) of type <code>Nat</code> should evaluate to a numeral, <code>succ (... (succ zero)...)</code>.</p>
<p>Introducing a proof-irrelevant <code>Prop</code> and marking theorems
irreducible represents a first step towards separation of
concerns. The intention is that elements of a type <code>p : Prop</code> should
play no role in computation, and so the particular construction of a
term <code>t : p</code> is &quot;irrelevant&quot; in that sense. One can still define
computational objects that incorporate elements of type <code>Prop</code>; the
point is that these elements can help us reason about the effects of
the computation, but can be ignored when we extract &quot;code&quot; from the
term. Elements of type <code>Prop</code> are not entirely innocuous,
however. They include equations <code>s = t : α</code> for any type <code>α</code>, and
such equations can be used as casts, to type check terms. Below, we
will see examples of how such casts can block computation in the
system. However, computation is still possible under an evaluation
scheme that erases propositional content, ignores intermediate typing
constraints, and reduces terms until they reach a normal form. This is
precisely what Lean's virtual machine does.</p>
<p>Having adopted a proof-irrelevant <code>Prop</code>, one might consider it
legitimate to use, for example, the law of the excluded middle,
<code>p ∨ ¬p</code>, where <code>p</code> is any proposition. Of course, this, too, can block
computation according to the rules of CIC, but it does not block
bytecode evaluation, as described above. It is only the choice
principles discussed in :numref:<code>choice</code> that completely erase the
distinction between the proof-irrelevant and data-relevant parts of
the theory.</p>
<h2><a class="header" href="#propositional-extensionality" id="propositional-extensionality">Propositional Extensionality</a></h2>
<p>Propositional extensionality is the following axiom:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>axiom propext {a b : Prop} : (a ↔ b) → a = b
<span class="boring">end Hidden
</span></code></pre>
<p>It asserts that when two propositions imply one another, they are
actually equal. This is consistent with set-theoretic interpretations
in which any element <code>a : Prop</code> is either empty or the singleton set
<code>{*}</code>, for some distinguished element <code>*</code>. The axiom has the
effect that equivalent propositions can be substituted for one another
in any context:</p>
<pre><code class="language-lean">theorem thm₁ (a b c d e : Prop) (h : a ↔ b) : (c ∧ a ∧ d → e) ↔ (c ∧ b ∧ d → e) :=
  propext h ▸ Iff.refl _

theorem thm₂ (a b : Prop) (p : Prop → Prop) (h : a ↔ b) (h₁ : p a) : p b :=
  propext h ▸ h₁
</code></pre>
<!--
The first example could be proved more laboriously without ``propext``
using the fact that the propositional connectives respect
propositional equivalence. The second example represents a more
essential use of ``propext``. In fact, it is equivalent to ``propext``
itself, a fact which we encourage you to prove.

Given any definition or theorem in Lean, you can use the ``#print
axioms`` command to display the axioms it depends on.

.. code-block:: lean

    variables a b c d e : Prop
    variable p : Prop → Prop

    theorem thm₁ (h : a ↔ b) : (c ∧ a ∧ d → e) ↔ (c ∧ b ∧ d → e) :=
    propext h ▸ iff.refl _

    theorem thm₂ (h : a ↔ b) (h₁ : p a) : p b :=
    propext h ▸ h₁

    -- BEGIN
    #print axioms thm₁  -- propext
    #print axioms thm₂  -- propext
    -- END
-->
<h2><a class="header" href="#function-extensionality" id="function-extensionality">Function Extensionality</a></h2>
<p>Similar to propositional extensionality, function extensionality
asserts that any two functions of type <code>(x : α) → β x</code> that agree on
all their inputs are equal.</p>
<pre><code class="language-lean">universe u v
#check (@funext :
           {α : Type u}
         → {β : α → Type u}
         → {f g : (x : α) → β x}
         → (∀ (x : α), f x = g x)
         → f = g)

#print funext
</code></pre>
<p>From a classical, set-theoretic perspective, this is exactly what it
means for two functions to be equal. This is known as an &quot;extensional&quot;
view of functions. From a constructive perspective, however, it is
sometimes more natural to think of functions as algorithms, or
computer programs, that are presented in some explicit way. It is
certainly the case that two computer programs can compute the same
answer for every input despite the fact that they are syntactically
quite different. In much the same way, you might want to maintain a
view of functions that does not force you to identify two functions
that have the same input / output behavior. This is known as an
&quot;intensional&quot; view of functions.</p>
<p>In fact, function extensionality follows from the existence of
quotients, which we describe in the next section. In the Lean standard
library, therefore, <code>funext</code> is thus
<a href="https://github.com/leanprover/lean4/blob/master/src/Init/Core.lean">proved from the quotient construction</a>.</p>
<p>Suppose that for <code>α : Type</code> we define the <code>Set α := α → Prop</code> to
denote the type of subsets of <code>α</code>, essentially identifying subsets
with predicates. By combining <code>funext</code> and <code>propext</code>, we obtain an
extensional theory of such sets:</p>
<pre><code class="language-lean">def Set (α : Type u) := α → Prop

namespace Set

def mem (x : α) (a : Set α) := a x

infix:50 &quot;∈&quot; =&gt; mem

theorem setext {a b : Set α} (h : ∀ x, x ∈ a ↔ x ∈ b) : a = b :=
  funext (fun x =&gt; propext (h x))

end Set
</code></pre>
<p>We can then proceed to define the empty set and set intersection, for
example, and prove set identities:</p>
<pre><code class="language-lean"><span class="boring">def Set (α : Type u) := α → Prop
</span><span class="boring">namespace Set
</span><span class="boring">def mem (x : α) (a : Set α) := a x
</span><span class="boring">infix:50 &quot;∈&quot; =&gt; mem
</span><span class="boring">theorem setext {a b : Set α} (h : ∀ x, x ∈ a ↔ x ∈ b) : a = b :=
</span><span class="boring"> funext (fun x =&gt; propext (h x))
</span>def empty : Set α := fun x =&gt; False

notation (priority := high) &quot;∅&quot; =&gt; empty

def inter (a b : Set α) : Set α :=
  fun x =&gt; x ∈ a ∧ x ∈ b

infix:70 &quot; ∩ &quot; =&gt; inter

theorem inter_self (a : Set α) : a ∩ a = a :=
  setext fun x =&gt; Iff.intro
    (fun ⟨h, _⟩ =&gt; h)
    (fun h =&gt; ⟨h, h⟩)

theorem inter_empty (a : Set α) : a ∩ ∅ = ∅ :=
  setext fun x =&gt; Iff.intro
    (fun ⟨_, h⟩ =&gt; h)
    (fun h =&gt; False.elim h)

theorem empty_inter (a : Set α) : ∅ ∩ a = ∅ :=
  setext fun x =&gt; Iff.intro
    (fun ⟨h, _⟩ =&gt; h)
    (fun h =&gt; False.elim h)

theorem inter.comm (a b : Set α) : a ∩ b = b ∩ a :=
  setext fun x =&gt; Iff.intro
    (fun ⟨h₁, h₂⟩ =&gt; ⟨h₂, h₁⟩)
    (fun ⟨h₁, h₂⟩ =&gt; ⟨h₂, h₁⟩)
<span class="boring">end Set
</span></code></pre>
<p>The following is an example of how function extensionality blocks
computation inside the Lean kernel.</p>
<pre><code class="language-lean">def f (x : Nat) := x
def g (x : Nat) := 0 + x

theorem f_eq_g : f = g :=
  funext fun x =&gt; (Nat.zero_add x).symm

def val : Nat :=
  Eq.recOn (motive := fun _ _ =&gt; Nat) f_eq_g 0

-- does not reduce to 0
#reduce val

-- evaluates to 0
#eval val
</code></pre>
<p>First, we show that the two functions <code>f</code> and <code>g</code> are equal using
function extensionality, and then we cast <code>0</code> of type <code>Nat</code> by
replacing <code>f</code> by <code>g</code> in the type. Of course, the cast is
vacuous, because <code>Nat</code> does not depend on <code>f</code>. But that is enough
to do the damage: under the computational rules of the system, we now
have a closed term of <code>Nat</code> that does not reduce to a numeral. In this
case, we may be tempted to reduce the expression to <code>0</code>. But in
nontrivial examples, eliminating cast changes the type of the term,
which might make an ambient expression type incorrect. The virtual
machine, however, has no trouble evaluating the expression to
<code>0</code>. Here is a similarly contrived example that shows how
<code>propext</code> can get in the way.</p>
<pre><code class="language-lean">theorem tteq : (True ∧ True) = True :=
  propext (Iff.intro (fun ⟨h, _⟩ =&gt; h) (fun h =&gt; ⟨h, h⟩))

def val : Nat :=
  Eq.recOn (motive := fun _ _ =&gt; Nat) tteq 0

-- does not reduce to 0
#reduce val

-- evaluates to 0
#eval val
</code></pre>
<p>Current research programs, including work on <em>observational type
theory</em> and <em>cubical type theory</em>, aim to extend type theory in ways
that permit reductions for casts involving function extensionality,
quotients, and more. But the solutions are not so clear cut, and the
rules of Lean's underlying calculus do not sanction such reductions.</p>
<p>In a sense, however, a cast does not change the meaning of an
expression. Rather, it is a mechanism to reason about the expression's
type. Given an appropriate semantics, it then makes sense to reduce
terms in ways that preserve their meaning, ignoring the intermediate
bookkeeping needed to make the reductions type correct. In that case,
adding new axioms in <code>Prop</code> does not matter; by proof irrelevance,
an expression in <code>Prop</code> carries no information, and can be safely
ignored by the reduction procedures.</p>
<h2><a class="header" href="#quotients" id="quotients">Quotients</a></h2>
<p>Let <code>α</code> be any type, and let <code>r</code> be an equivalence relation on
<code>α</code>. It is mathematically common to form the &quot;quotient&quot; <code>α / r</code>,
that is, the type of elements of <code>α</code> &quot;modulo&quot; <code>r</code>. Set
theoretically, one can view <code>α / r</code> as the set of equivalence
classes of <code>α</code> modulo <code>r</code>. If <code>f : α → β</code> is any function that
respects the equivalence relation in the sense that for every
<code>x y : α</code>, <code>r x y</code> implies <code>f x = f y</code>, then <code>f</code> &quot;lifts&quot; to a function
<code>f' : α / r → β</code> defined on each equivalence class <code>⟦x⟧</code> by
<code>f' ⟦x⟧ = f x</code>. Lean's standard library extends the Calculus of
Constructions with additional constants that perform exactly these
constructions, and installs this last equation as a definitional
reduction rule.</p>
<p>In its most basic form, the quotient construction does not even
require <code>r</code> to be an equivalence relation. The following constants
are built into Lean:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>universe u v

axiom Quot : {α : Sort u} → (α → α → Prop) → Sort u

axiom Quot.mk : {α : Sort u} → (r : α → α → Prop) → α → Quot r

axiom Quot.ind :
    ∀ {α : Sort u} {r : α → α → Prop} {β : Quot r → Prop},
      (∀ a, β (Quot.mk r a)) → (q : Quot r) → β q

axiom Quot.lift :
    {α : Sort u} → {r : α → α → Prop} → {β : Sort u} → (f : α → β)
    → (∀ a b, r a b → f a = f b) → Quot r → β
<span class="boring">end Hidden
</span></code></pre>
<p>The first one forms a type <code>Quot r</code> given a type <code>α</code> by any binary
relation <code>r</code> on <code>α</code>. The second maps <code>α</code> to <code>Quot α</code>, so that
if <code>r : α → α → Prop</code> and <code>a : α</code>, then <code>Quot.mk r a</code> is an
element of <code>Quot r</code>. The third principle, <code>Quot.ind</code>, says that
every element of <code>Quot.mk r a</code> is of this form.  As for
<code>Quot.lift</code>, given a function <code>f : α → β</code>, if <code>h</code> is a proof
that <code>f</code> respects the relation <code>r</code>, then <code>Quot.lift f h</code> is the
corresponding function on <code>Quot r</code>. The idea is that for each
element <code>a</code> in <code>α</code>, the function <code>Quot.lift f h</code> maps
<code>Quot.mk r a</code> (the <code>r</code>-class containing <code>a</code>) to <code>f a</code>, wherein <code>h</code>
shows that this function is well defined. In fact, the computation
principle is declared as a reduction rule, as the proof below makes
clear.</p>
<pre><code class="language-lean">def mod7Rel (x y : Nat) : Prop :=
  x % 7 = y % 7

-- the quotient type
#check (Quot mod7Rel : Type)

-- the class of a
#check (Quot.mk mod7Rel 4 : Quot mod7Rel)

def f (x : Nat) : Bool :=
   x % 7 = 0

theorem f_respects (a b : Nat) (h : mod7Rel a b) : f a = f b := by
  simp [mod7Rel, f] at *
  rw [h]

#check (Quot.lift f f_respects : Quot mod7Rel → Bool)

-- the computation principle
example (a : Nat) : Quot.lift f f_respects (Quot.mk mod7Rel a) = f a :=
  rfl
</code></pre>
<p>The four constants, <code>Quot</code>, <code>Quot.mk</code>, <code>Quot.ind</code>, and
<code>Quot.lift</code> in and of themselves are not very strong. You can check
that the <code>Quot.ind</code> is satisfied if we take <code>Quot r</code> to be simply
<code>α</code>, and take <code>Quot.lift</code> to be the identity function (ignoring
<code>h</code>). For that reason, these four constants are not viewed as
additional axioms:</p>
<!--
    variables α β : Type
    variable  r : α → α → Prop
    variable  a : α
    variable  f : α → β
    variable   h : ∀ a₁ a₂, r a₁ a₂ → f a₁ = f a₂
    theorem thm : quot.lift f h (quot.mk r a) = f a := rfl
    -- BEGIN
    #print axioms thm   -- no axioms
    -- END
-->
<p>They are, like inductively defined types and the associated
constructors and recursors, viewed as part of the logical framework.</p>
<p>What makes the <code>Quot</code> construction into a bona fide quotient is the
following additional axiom:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span><span class="boring">universe u v
</span>axiom Quot.sound :
      ∀ {α : Type u} {r : α → α → Prop} {a b : α},
        r a b → Quot.mk r a = Quot.mk r b
<span class="boring">end Hidden
</span></code></pre>
<p>This is the axiom that asserts that any two elements of <code>α</code> that are
related by <code>r</code> become identified in the quotient. If a theorem or
definition makes use of <code>Quot.sound</code>, it will show up in the
<code>#print axioms</code> command.</p>
<p>Of course, the quotient construction is most commonly used in
situations when <code>r</code> is an equivalence relation. Given <code>r</code> as
above, if we define <code>r'</code> according to the rule <code>r' a b</code> iff
<code>Quot.mk r a = Quot.mk r b</code>, then it's clear that <code>r'</code> is an
equivalence relation. Indeed, <code>r'</code> is the <em>kernel</em> of the function
<code>a ↦ quot.mk r a</code>.  The axiom <code>Quot.sound</code> says that <code>r a b</code>
implies <code>r' a b</code>. Using <code>Quot.lift</code> and <code>Quot.ind</code>, we can show
that <code>r'</code> is the smallest equivalence relation containing <code>r</code>, in
the sense that if <code>r''</code> is any equivalence relation containing
<code>r</code>, then <code>r' a b</code> implies <code>r'' a b</code>. In particular, if <code>r</code>
was an equivalence relation to start with, then for all <code>a</code> and
<code>b</code> we have <code>r a b</code> iff <code>r' a b</code>.</p>
<p>To support this common use case, the standard library defines the
notion of a <em>setoid</em>, which is simply a type with an associated
equivalence relation:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>class Setoid (α : Sort u) where
  r : α → α → Prop
  iseqv {} : Equivalence r

instance {α : Sort u} [Setoid α] : HasEquiv α :=
  ⟨Setoid.r⟩

namespace Setoid

variable {α : Sort u} [Setoid α]

theorem refl (a : α) : a ≈ a :=
  (Setoid.iseqv α).refl a

theorem symm {a b : α} (hab : a ≈ b) : b ≈ a :=
  (Setoid.iseqv α).symm hab

theorem trans {a b c : α} (hab : a ≈ b) (hbc : b ≈ c) : a ≈ c :=
  (Setoid.iseqv α).trans hab hbc

end Setoid
<span class="boring">end Hidden
</span></code></pre>
<p>Given a type <code>α</code>, a relation <code>r</code> on <code>α</code>, and a proof <code>p</code>
that <code>r</code> is an equivalence relation, we can define <code>Setoid.mk p</code>
as an instance of the setoid class.</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>def Quotient {α : Sort u} (s : Setoid α) :=
  @Quot α Setoid.r
<span class="boring">end Hidden
</span></code></pre>
<p>The constants <code>Quotient.mk</code>, <code>Quotient.ind</code>, <code>Quotient.lift</code>,
and <code>Quotient.sound</code> are nothing more than the specializations of
the corresponding elements of <code>Quot</code>. The fact that type class
inference can find the setoid associated to a type <code>α</code> brings a
number of benefits. First, we can use the notation <code>a ≈ b</code> (entered
with <code>\approx</code>) for <code>Setoid.r a b</code>, where the instance of
<code>Setoid</code> is implicit in the notation <code>Setoid.r</code>. We can use the
generic theorems <code>Setoid.refl</code>, <code>Setoid.symm</code>, <code>Setoid.trans</code> to
reason about the relation. Specifically with quotients we can use the
generic notation <code>⟦a⟧</code> for <code>Quot.mk Setoid.r</code> where the instance
of <code>Setoid</code> is implicit in the notation <code>Setoid.r</code>, as well as the
theorem <code>Quotient.exact</code>:</p>
<pre><code class="language-lean"><span class="boring">universe u
</span>#check (@Quotient.exact :
         ∀ {α : Sort u} [s : Setoid α] {a b : α},
           Quotient.mk a = Quotient.mk b → a ≈ b)
</code></pre>
<p>Together with <code>Quotient.sound</code>, this implies that the elements of
the quotient correspond exactly to the equivalence classes of elements
in <code>α</code>.</p>
<p>Recall that in the standard library, <code>α × β</code> represents the
Cartesian product of the types <code>α</code> and <code>β</code>. To illustrate the use
of quotients, let us define the type of <em>unordered</em> pairs of elements
of a type <code>α</code> as a quotient of the type <code>α × α</code>. First, we define
the relevant equivalence relation:</p>
<pre><code class="language-lean">private def eqv (p₁ p₂ : α × α) : Prop :=
  (p₁.1 = p₂.1 ∧ p₁.2 = p₂.2) ∨ (p₁.1 = p₂.2 ∧ p₁.2 = p₂.1)

infix:50 &quot; ~ &quot; =&gt; eqv
</code></pre>
<p>The next step is to prove that <code>eqv</code> is in fact an equivalence
relation, which is to say, it is reflexive, symmetric and
transitive. We can prove these three facts in a convenient and
readable way by using dependent pattern matching to perform
case-analysis and break the hypotheses into pieces that are then
reassembled to produce the conclusion.</p>
<pre><code class="language-lean"><span class="boring">private def eqv (p₁ p₂ : α × α) : Prop :=
</span><span class="boring"> (p₁.1 = p₂.1 ∧ p₁.2 = p₂.2) ∨ (p₁.1 = p₂.2 ∧ p₁.2 = p₂.1)
</span><span class="boring">infix:50 &quot; ~ &quot; =&gt; eqv
</span>private theorem eqv.refl (p : α × α) : p ~ p :=
  Or.inl ⟨rfl, rfl⟩

private theorem eqv.symm  : ∀ {p₁ p₂ : α × α}, p₁ ~ p₂ → p₂ ~ p₁
  | (a₁, a₂), (b₁, b₂), (Or.inl ⟨a₁b₁, a₂b₂⟩) =&gt;
    Or.inl (by simp_all)
  | (a₁, a₂), (b₁, b₂), (Or.inr ⟨a₁b₂, a₂b₁⟩) =&gt;
    Or.inr (by simp_all)

private theorem eqv.trans : ∀ {p₁ p₂ p₃ : α × α}, p₁ ~ p₂ → p₂ ~ p₃ → p₁ ~ p₃
  | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inl ⟨a₁b₁, a₂b₂⟩, Or.inl ⟨b₁c₁, b₂c₂⟩ =&gt;
    Or.inl (by simp_all)
  | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inl ⟨a₁b₁, a₂b₂⟩, Or.inr ⟨b₁c₂, b₂c₁⟩ =&gt;
    Or.inr (by simp_all)
  | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inr ⟨a₁b₂, a₂b₁⟩, Or.inl ⟨b₁c₁, b₂c₂⟩ =&gt;
    Or.inr (by simp_all)
  | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inr ⟨a₁b₂, a₂b₁⟩, Or.inr ⟨b₁c₂, b₂c₁⟩ =&gt;
    Or.inl (by simp_all)

private theorem is_equivalence : Equivalence (@eqv α) :=
   { refl := eqv.refl, symm := eqv.symm, trans := eqv.trans }
</code></pre>
<p>Now that we have proved that <code>eqv</code> is an equivalence relation, we
can construct a <code>Setoid (α × α)</code>, and use it to define the type
<code>UProd α</code> of unordered pairs.</p>
<pre><code class="language-lean"><span class="boring">private def eqv (p₁ p₂ : α × α) : Prop :=
</span><span class="boring"> (p₁.1 = p₂.1 ∧ p₁.2 = p₂.2) ∨ (p₁.1 = p₂.2 ∧ p₁.2 = p₂.1)
</span><span class="boring">infix:50 &quot; ~ &quot; =&gt; eqv
</span><span class="boring">private theorem eqv.refl (p : α × α) : p ~ p :=
</span><span class="boring"> Or.inl ⟨rfl, rfl⟩
</span><span class="boring">private theorem eqv.symm  : ∀ {p₁ p₂ : α × α}, p₁ ~ p₂ → p₂ ~ p₁
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (Or.inl ⟨a₁b₁, a₂b₂⟩) =&gt;
</span><span class="boring">    Or.inl (by simp_all)
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (Or.inr ⟨a₁b₂, a₂b₁⟩) =&gt;
</span><span class="boring">    Or.inr (by simp_all)
</span><span class="boring">private theorem eqv.trans : ∀ {p₁ p₂ p₃ : α × α}, p₁ ~ p₂ → p₂ ~ p₃ → p₁ ~ p₃
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inl ⟨a₁b₁, a₂b₂⟩, Or.inl ⟨b₁c₁, b₂c₂⟩ =&gt;
</span><span class="boring">    Or.inl (by simp_all)
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inl ⟨a₁b₁, a₂b₂⟩, Or.inr ⟨b₁c₂, b₂c₁⟩ =&gt;
</span><span class="boring">    Or.inr (by simp_all)
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inr ⟨a₁b₂, a₂b₁⟩, Or.inl ⟨b₁c₁, b₂c₂⟩ =&gt;
</span><span class="boring">    Or.inr (by simp_all)
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inr ⟨a₁b₂, a₂b₁⟩, Or.inr ⟨b₁c₂, b₂c₁⟩ =&gt;
</span><span class="boring">    Or.inl (by simp_all)
</span><span class="boring">private theorem is_equivalence : Equivalence (@eqv α) :=
</span><span class="boring">  { refl := eqv.refl, symm := eqv.symm, trans := eqv.trans }
</span>instance uprodSetoid (α : Type u) : Setoid (α × α) where
   r     := eqv
   iseqv := is_equivalence

def UProd (α : Type u) : Type u :=
  Quotient (uprodSetoid α)

namespace UProd

def mk {α : Type} (a₁ a₂ : α) : UProd α :=
  Quotient.mk (a₁, a₂)

notation &quot;{ &quot; a₁ &quot;, &quot; a₂ &quot; }&quot; =&gt; mk a₁ a₂

end UProd
</code></pre>
<p>Notice that we locally define the notation <code>{a₁, a₂}</code> for ordered
pairs as <code>Quotient.mk (a₁, a₂)</code>. This is useful for illustrative
purposes, but it is not a good idea in general, since the notation
will shadow other uses of curly brackets, such as for records and
sets.</p>
<p>We can easily prove that <code>{a₁, a₂} = {a₂, a₁}</code> using <code>quot.sound</code>,
since we have <code>(a₁, a₂) ~ (a₂, a₁)</code>.</p>
<pre><code class="language-lean"><span class="boring">private def eqv (p₁ p₂ : α × α) : Prop :=
</span><span class="boring"> (p₁.1 = p₂.1 ∧ p₁.2 = p₂.2) ∨ (p₁.1 = p₂.2 ∧ p₁.2 = p₂.1)
</span><span class="boring">infix:50 &quot; ~ &quot; =&gt; eqv
</span><span class="boring">private theorem eqv.refl (p : α × α) : p ~ p :=
</span><span class="boring"> Or.inl ⟨rfl, rfl⟩
</span><span class="boring">private theorem eqv.symm  : ∀ {p₁ p₂ : α × α}, p₁ ~ p₂ → p₂ ~ p₁
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (Or.inl ⟨a₁b₁, a₂b₂⟩) =&gt;
</span><span class="boring">    Or.inl (by simp_all)
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (Or.inr ⟨a₁b₂, a₂b₁⟩) =&gt;
</span><span class="boring">    Or.inr (by simp_all)
</span><span class="boring">private theorem eqv.trans : ∀ {p₁ p₂ p₃ : α × α}, p₁ ~ p₂ → p₂ ~ p₃ → p₁ ~ p₃
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inl ⟨a₁b₁, a₂b₂⟩, Or.inl ⟨b₁c₁, b₂c₂⟩ =&gt;
</span><span class="boring">    Or.inl (by simp_all)
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inl ⟨a₁b₁, a₂b₂⟩, Or.inr ⟨b₁c₂, b₂c₁⟩ =&gt;
</span><span class="boring">    Or.inr (by simp_all)
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inr ⟨a₁b₂, a₂b₁⟩, Or.inl ⟨b₁c₁, b₂c₂⟩ =&gt;
</span><span class="boring">    Or.inr (by simp_all)
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inr ⟨a₁b₂, a₂b₁⟩, Or.inr ⟨b₁c₂, b₂c₁⟩ =&gt;
</span><span class="boring">    Or.inl (by simp_all)
</span><span class="boring">private theorem is_equivalence : Equivalence (@eqv α) :=
</span><span class="boring">  { refl := eqv.refl, symm := eqv.symm, trans := eqv.trans }
</span><span class="boring">instance uprodSetoid (α : Type u) : Setoid (α × α) where
</span><span class="boring">   r     := eqv
</span><span class="boring">   iseqv := is_equivalence
</span><span class="boring">def UProd (α : Type u) : Type u :=
</span><span class="boring">  Quotient (uprodSetoid α)
</span><span class="boring">namespace UProd
</span><span class="boring">def mk {α : Type} (a₁ a₂ : α) : UProd α :=
</span><span class="boring">  Quotient.mk (a₁, a₂)
</span><span class="boring">notation &quot;{ &quot; a₁ &quot;, &quot; a₂ &quot; }&quot; =&gt; mk a₁ a₂
</span>theorem mk_eq_mk (a₁ a₂ : α) : {a₁, a₂} = {a₂, a₁} :=
  Quot.sound (Or.inr ⟨rfl, rfl⟩)
<span class="boring">end UProd
</span></code></pre>
<p>To complete the example, given <code>a : α</code> and <code>u : uprod α</code>, we
define the proposition <code>a ∈ u</code> which should hold if <code>a</code> is one of
the elements of the unordered pair <code>u</code>. First, we define a similar
proposition <code>mem_fn a u</code> on (ordered) pairs; then we show that
<code>mem_fn</code> respects the equivalence relation <code>eqv</code> with the lemma
<code>mem_respects</code>. This is an idiom that is used extensively in the
Lean standard library.</p>
<pre><code class="language-lean"><span class="boring">private def eqv (p₁ p₂ : α × α) : Prop :=
</span><span class="boring"> (p₁.1 = p₂.1 ∧ p₁.2 = p₂.2) ∨ (p₁.1 = p₂.2 ∧ p₁.2 = p₂.1)
</span><span class="boring">infix:50 &quot; ~ &quot; =&gt; eqv
</span><span class="boring">private theorem eqv.refl (p : α × α) : p ~ p :=
</span><span class="boring"> Or.inl ⟨rfl, rfl⟩
</span><span class="boring">private theorem eqv.symm  : ∀ {p₁ p₂ : α × α}, p₁ ~ p₂ → p₂ ~ p₁
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (Or.inl ⟨a₁b₁, a₂b₂⟩) =&gt;
</span><span class="boring">    Or.inl (by simp_all)
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (Or.inr ⟨a₁b₂, a₂b₁⟩) =&gt;
</span><span class="boring">    Or.inr (by simp_all)
</span><span class="boring">private theorem eqv.trans : ∀ {p₁ p₂ p₃ : α × α}, p₁ ~ p₂ → p₂ ~ p₃ → p₁ ~ p₃
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inl ⟨a₁b₁, a₂b₂⟩, Or.inl ⟨b₁c₁, b₂c₂⟩ =&gt;
</span><span class="boring">    Or.inl (by simp_all)
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inl ⟨a₁b₁, a₂b₂⟩, Or.inr ⟨b₁c₂, b₂c₁⟩ =&gt;
</span><span class="boring">    Or.inr (by simp_all)
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inr ⟨a₁b₂, a₂b₁⟩, Or.inl ⟨b₁c₁, b₂c₂⟩ =&gt;
</span><span class="boring">    Or.inr (by simp_all)
</span><span class="boring">  | (a₁, a₂), (b₁, b₂), (c₁, c₂), Or.inr ⟨a₁b₂, a₂b₁⟩, Or.inr ⟨b₁c₂, b₂c₁⟩ =&gt;
</span><span class="boring">    Or.inl (by simp_all)
</span><span class="boring">private theorem is_equivalence : Equivalence (@eqv α) :=
</span><span class="boring">  { refl := eqv.refl, symm := eqv.symm, trans := eqv.trans }
</span><span class="boring">instance uprodSetoid (α : Type u) : Setoid (α × α) where
</span><span class="boring">   r     := eqv
</span><span class="boring">   iseqv := is_equivalence
</span><span class="boring">def UProd (α : Type u) : Type u :=
</span><span class="boring">  Quotient (uprodSetoid α)
</span><span class="boring">namespace UProd
</span><span class="boring">def mk {α : Type} (a₁ a₂ : α) : UProd α :=
</span><span class="boring">  Quotient.mk (a₁, a₂)
</span><span class="boring">notation &quot;{ &quot; a₁ &quot;, &quot; a₂ &quot; }&quot; =&gt; mk a₁ a₂
</span><span class="boring">theorem mk_eq_mk (a₁ a₂ : α) : {a₁, a₂} = {a₂, a₁} :=
</span><span class="boring">  Quot.sound (Or.inr ⟨rfl, rfl⟩)
</span>
private def mem_fn (a : α) : α × α → Prop
  | (a₁, a₂) =&gt; a = a₁ ∨ a = a₂

-- auxiliary lemma for proving mem_respects
private theorem mem_swap {a : α} :
      ∀ {p : α × α}, mem_fn a p = mem_fn a (⟨p.2, p.1⟩)
  | (a₁, a₂) =&gt; by
    apply propext
    apply Iff.intro
    . intro
      | Or.inl h =&gt; exact Or.inr h
      | Or.inr h =&gt; exact Or.inl h
    . intro
      | Or.inl h =&gt; exact Or.inr h
      | Or.inr h =&gt; exact Or.inl h


private theorem mem_respects
      : {p₁ p₂ : α × α} → (a : α) → p₁ ~ p₂ → mem_fn a p₁ = mem_fn a p₂
  | (a₁, a₂), (b₁, b₂), a, Or.inl ⟨a₁b₁, a₂b₂⟩ =&gt; by simp_all
  | (a₁, a₂), (b₁, b₂), a, Or.inr ⟨a₁b₂, a₂b₁⟩ =&gt; by simp_all; apply mem_swap

def mem (a : α) (u : UProd α) : Prop :=
  Quot.liftOn u (fun p =&gt; mem_fn a p) (fun p₁ p₂ e =&gt; mem_respects a e)

infix:50 &quot; ∈ &quot; =&gt; mem

theorem mem_mk_left (a b : α) : a ∈ {a, b} :=
  Or.inl rfl

theorem mem_mk_right (a b : α) : b ∈ {a, b} :=
  Or.inr rfl

theorem mem_or_mem_of_mem_mk {a b c : α} : c ∈ {a, b} → c = a ∨ c = b :=
  fun h =&gt; h
<span class="boring">end UProd
</span></code></pre>
<p>For convenience, the standard library also defines <code>Quotient.lift₂</code>
for lifting binary functions, and <code>Quotient.ind₂</code> for induction on
two variables.</p>
<p>We close this section with some hints as to why the quotient
construction implies function extenionality. It is not hard to show
that extensional equality on the <code>(x : α) → β x</code> is an equivalence
relation, and so we can consider the type <code>extfun α β</code> of functions
&quot;up to equivalence.&quot; Of course, application respects that equivalence
in the sense that if <code>f₁</code> is equivalent to <code>f₂</code>, then <code>f₁ a</code> is
equal to <code>f₂ a</code>. Thus application gives rise to a function
<code>extfun_app : extfun α β → (x : α) → β x</code>. But for every <code>f</code>,
<code>extfun_app ⟦f⟧</code> is definitionally equal to <code>fun x =&gt; f x</code>, which is
in turn definitionally equal to <code>f</code>. So, when <code>f₁</code> and <code>f₂</code> are
extensionally equal, we have the following chain of equalities:</p>
<pre><code>    f₁ = extfun_app ⟦f₁⟧ = extfun_app ⟦f₂⟧ = f₂
</code></pre>
<p>As a result, <code>f₁</code> is equal to <code>f₂</code>.</p>
<h2><a class="header" href="#choice" id="choice">Choice</a></h2>
<p>To state the final axiom defined in the standard library, we need the
<code>Nonempty</code> type, which is defined as follows:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>class inductive Nonempty (α : Sort u) : Prop where
  | intro (val : α) : Nonempty α
<span class="boring">end Hidden
</span></code></pre>
<p>Because <code>Nonempty α</code> has type <code>Prop</code> and its constructor contains data, it can only eliminate to <code>Prop</code>.
In fact, <code>Nonempty α</code> is equivalent to <code>∃ x : α, True</code>:</p>
<pre><code class="language-lean">example (α : Type u) : Nonempty α ↔ ∃ x : α, True :=
  Iff.intro (fun ⟨a⟩ =&gt; ⟨a, trivial⟩) (fun ⟨a, h⟩ =&gt; ⟨a⟩)
</code></pre>
<p>Our axiom of choice is now expressed simply as follows:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span><span class="boring">universe u
</span>axiom choice {α : Sort u} : Nonempty α → α
<span class="boring">end Hidden
</span></code></pre>
<p>Given only the assertion <code>h</code> that <code>α</code> is nonempty, <code>choice h</code>
magically produces an element of <code>α</code>. Of course, this blocks any
meaningful computation: by the interpretation of <code>Prop</code>, <code>h</code>
contains no information at all as to how to find such an element.</p>
<p>This is found in the <code>Classical</code> namespace, so the full name of the
theorem is <code>Classical.choice</code>. The choice principle is equivalent to
the principle of <em>indefinite description</em>, which can be expressed with
subtypes as follows:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span><span class="boring">universe u
</span><span class="boring">axiom choice {α : Sort u} : Nonempty α → α
</span>noncomputable def indefiniteDescription {α : Sort u} (p : α → Prop)
                                        (h : ∃ x, p x) : {x // p x} :=
  choice &lt;| let ⟨x, px⟩ := h; ⟨⟨x, px⟩⟩
<span class="boring">end Hidden
</span></code></pre>
<p>Because it depends on <code>choice</code>, Lean cannot generate bytecode for
<code>indefiniteDescription</code>, and so requires us to mark the definition
as <code>noncomputable</code>. Also in the <code>Classical</code> namespace, the
function <code>choose</code> and the property <code>choose_spec</code> decompose the two
parts of the output of <code>indefinite_description</code>:</p>
<pre><code class="language-lean"><span class="boring">open Classical
</span><span class="boring">namespace Hidden
</span>noncomputable def choose {α : Sort u} {p : α → Prop} (h : ∃ x, p x) : α :=
  (indefiniteDescription p h).val

theorem choose_spec {α : Sort u} {p : α → Prop} (h : ∃ x, p x) : p (choose h) :=
  (indefiniteDescription p h).property
<span class="boring">end Hidden
</span></code></pre>
<p>The <code>choice</code> principle also erases the distinction between the
property of being <code>Nonempty</code> and the more constructive property of
being <code>Inhabited</code>:</p>
<pre><code class="language-lean"><span class="boring">open Classical
</span>theorem inhabited_of_nonempty :Nonempty α → Inhabited α :=
  fun h =&gt; choice (let ⟨a⟩ := h; ⟨⟨a⟩⟩)
</code></pre>
<p>In the next section, we will see that <code>propext</code>, <code>funext</code>, and
<code>choice</code>, taken together, imply the law of the excluded middle and
the decidability of all propositions. Using those, one can strengthen
the principle of indefinite description as follows:</p>
<pre><code class="language-lean"><span class="boring">open Classical
</span><span class="boring">universe u
</span>#check (@strongIndefiniteDescription :
         {α : Sort u} → (p : α → Prop)
         → Nonempty α → {x // (∃ (y : α), p y) → p x})
</code></pre>
<p>Assuming the ambient type <code>α</code> is nonempty,
<code>strongIndefiniteDescription p</code> produces an element of <code>α</code>
satisfying <code>p</code> if there is one. The data component of this
definition is conventionally known as <em>Hilbert's epsilon function</em>:</p>
<pre><code class="language-lean"><span class="boring">open Classical
</span><span class="boring">universe u
</span>#check (@epsilon :
         {α : Sort u} → [Nonempty α]
         → (α → Prop) → α)

#check (@epsilon_spec :
          ∀ {a : Sort u} {p : a → Prop}(hex : ∃ (y : a), p y),
            p (@epsilon _ (nonempty_of_exists hex) p))
</code></pre>
<h2><a class="header" href="#the-law-of-the-excluded-middle" id="the-law-of-the-excluded-middle">The Law of the Excluded Middle</a></h2>
<p>The law of the excluded middle is the following</p>
<pre><code class="language-lean">open Classical

#check (@em : ∀ (p : Prop), p ∨ ¬p)
</code></pre>
<p><a href="http://en.wikipedia.org/wiki/Diaconescu%27s_theorem">Diaconescu's theorem</a> states
that the axiom of choice is sufficient to derive the law of excluded
middle. More precisely, it shows that the law of the excluded middle
follows from <code>Classical.choice</code>, <code>propext</code>, and <code>funext</code>. We
sketch the proof that is found in the standard library.</p>
<p>First, we import the necessary axioms, and define two predicates <code>U</code> and <code>V</code>:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>open Classical
theorem em (p : Prop) : p ∨ ¬p :=
  let U (x : Prop) : Prop := x = True ∨ p
  let V (x : Prop) : Prop := x = False ∨ p

  have exU : ∃ x, U x := ⟨True, Or.inl rfl⟩
  have exV : ∃ x, V x := ⟨False, Or.inl rfl⟩
<span class="boring">  sorry
</span><span class="boring">end Hidden
</span></code></pre>
<p>If <code>p</code> is true, then every element of <code>Prop</code> is in both <code>U</code> and <code>V</code>.
If <code>p</code> is false, then <code>U</code> is the singleton <code>true</code>, and <code>V</code> is the singleton <code>false</code>.</p>
<p>Next, we use <code>some</code> to choose an element from each of <code>U</code> and <code>V</code>:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span><span class="boring">open Classical
</span><span class="boring">theorem em (p : Prop) : p ∨ ¬p :=
</span><span class="boring">  let U (x : Prop) : Prop := x = True ∨ p
</span><span class="boring">  let V (x : Prop) : Prop := x = False ∨ p
</span><span class="boring">  have exU : ∃ x, U x := ⟨True, Or.inl rfl⟩
</span><span class="boring">  have exV : ∃ x, V x := ⟨False, Or.inl rfl⟩
</span>  let u : Prop := choose exU
  let v : Prop := choose exV

  have u_def : U u := choose_spec exU
  have v_def : V v := choose_spec exV
<span class="boring">  sorry
</span><span class="boring">end Hidden
</span></code></pre>
<p>Each of <code>U</code> and <code>V</code> is a disjunction, so <code>u_def</code> and <code>v_def</code>
represent four cases. In one of these cases, <code>u = True</code> and
<code>v = False</code>, and in all the other cases, <code>p</code> is true. Thus we have:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span><span class="boring">open Classical
</span><span class="boring">theorem em (p : Prop) : p ∨ ¬p :=
</span><span class="boring">  let U (x : Prop) : Prop := x = True ∨ p
</span><span class="boring">  let V (x : Prop) : Prop := x = False ∨ p
</span><span class="boring">  have exU : ∃ x, U x := ⟨True, Or.inl rfl⟩
</span><span class="boring">  have exV : ∃ x, V x := ⟨False, Or.inl rfl⟩
</span><span class="boring">  let u : Prop := choose exU
</span><span class="boring">  let v : Prop := choose exV
</span><span class="boring">  have u_def : U u := choose_spec exU
</span><span class="boring">  have v_def : V v := choose_spec exV
</span>  have not_uv_or_p : u ≠ v ∨ p :=
    match u_def, v_def with
    | Or.inr h, _ =&gt; Or.inr h
    | _, Or.inr h =&gt; Or.inr h
    | Or.inl hut, Or.inl hvf =&gt;
      have hne : u ≠ v := by simp [hvf, hut, true_ne_false]
      Or.inl hne
<span class="boring">  sorry
</span><span class="boring">end Hidden
</span></code></pre>
<p>On the other hand, if <code>p</code> is true, then, by function extensionality
and propositional extensionality, <code>U</code> and <code>V</code> are equal. By the
definition of <code>u</code> and <code>v</code>, this implies that they are equal as well.</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span><span class="boring">open Classical
</span><span class="boring">theorem em (p : Prop) : p ∨ ¬p :=
</span><span class="boring">  let U (x : Prop) : Prop := x = True ∨ p
</span><span class="boring">  let V (x : Prop) : Prop := x = False ∨ p
</span><span class="boring">  have exU : ∃ x, U x := ⟨True, Or.inl rfl⟩
</span><span class="boring">  have exV : ∃ x, V x := ⟨False, Or.inl rfl⟩
</span><span class="boring">  let u : Prop := choose exU
</span><span class="boring">  let v : Prop := choose exV
</span><span class="boring">  have u_def : U u := choose_spec exU
</span><span class="boring">  have v_def : V v := choose_spec exV
</span><span class="boring">  have not_uv_or_p : u ≠ v ∨ p :=
</span><span class="boring">    match u_def, v_def with
</span><span class="boring">    | Or.inr h, _ =&gt; Or.inr h
</span><span class="boring">    | _, Or.inr h =&gt; Or.inr h
</span><span class="boring">    | Or.inl hut, Or.inl hvf =&gt;
</span><span class="boring">      have hne : u ≠ v := by simp [hvf, hut, true_ne_false]
</span><span class="boring">      Or.inl hne
</span>  have p_implies_uv : p → u = v :=
    fun hp =&gt;
    have hpred : U = V :=
      funext fun x =&gt;
        have hl : (x = True ∨ p) → (x = False ∨ p) :=
          fun _ =&gt; Or.inr hp
        have hr : (x = False ∨ p) → (x = True ∨ p) :=
          fun _ =&gt; Or.inr hp
        show (x = True ∨ p) = (x = False ∨ p) from
          propext (Iff.intro hl hr)
    have h₀ : ∀ exU exV, @choose _ U exU = @choose _ V exV := by
      rw [hpred]; intros; rfl
    show u = v from h₀ _ _
<span class="boring">  sorry
</span><span class="boring">end Hidden
</span></code></pre>
<p>Putting these last two facts together yields the desired conclusion:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span><span class="boring">open Classical
</span><span class="boring">theorem em (p : Prop) : p ∨ ¬p :=
</span><span class="boring">  let U (x : Prop) : Prop := x = True ∨ p
</span><span class="boring">  let V (x : Prop) : Prop := x = False ∨ p
</span><span class="boring">  have exU : ∃ x, U x := ⟨True, Or.inl rfl⟩
</span><span class="boring">  have exV : ∃ x, V x := ⟨False, Or.inl rfl⟩
</span><span class="boring">  let u : Prop := choose exU
</span><span class="boring">  let v : Prop := choose exV
</span><span class="boring">  have u_def : U u := choose_spec exU
</span><span class="boring">  have v_def : V v := choose_spec exV
</span><span class="boring">  have not_uv_or_p : u ≠ v ∨ p :=
</span><span class="boring">    match u_def, v_def with
</span><span class="boring">    | Or.inr h, _ =&gt; Or.inr h
</span><span class="boring">    | _, Or.inr h =&gt; Or.inr h
</span><span class="boring">    | Or.inl hut, Or.inl hvf =&gt;
</span><span class="boring">      have hne : u ≠ v := by simp [hvf, hut, true_ne_false]
</span><span class="boring">      Or.inl hne
</span><span class="boring"> have p_implies_uv : p → u = v :=
</span><span class="boring">    fun hp =&gt;
</span><span class="boring">    have hpred : U = V :=
</span><span class="boring">      funext fun x =&gt;
</span><span class="boring">        have hl : (x = True ∨ p) → (x = False ∨ p) :=
</span><span class="boring">          fun _ =&gt; Or.inr hp
</span><span class="boring">        have hr : (x = False ∨ p) → (x = True ∨ p) :=
</span><span class="boring">          fun _ =&gt; Or.inr hp
</span><span class="boring">        show (x = True ∨ p) = (x = False ∨ p) from
</span><span class="boring">          propext (Iff.intro hl hr)
</span><span class="boring">    have h₀ : ∀ exU exV, @choose _ U exU = @choose _ V exV := by
</span><span class="boring">      rw [hpred]; intros; rfl
</span><span class="boring">    show u = v from h₀ _ _
</span>  match not_uv_or_p with
  | Or.inl hne =&gt; Or.inr (mt p_implies_uv hne)
  | Or.inr h   =&gt; Or.inl h
<span class="boring">end Hidden
</span></code></pre>
<p>Consequences of excluded middle include double-negation elimination,
proof by cases, and proof by contradiction, all of which are described
in the <a href="./propositions_and_proofs.html#_classical">Section Classical Logic</a>.
The law of the excluded middle and propositional extensionality imply propositional completeness:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>open Classical
theorem propComplete (a : Prop) : a = True ∨ a = False :=
  match em a with
  | Or.inl ha =&gt; Or.inl (propext (Iff.intro (fun _ =&gt; ⟨⟩) (fun _ =&gt; ha)))
  | Or.inr hn =&gt; Or.inr (propext (Iff.intro (fun h =&gt; hn h) (fun h =&gt; False.elim h)))
<span class="boring">end Hidden
</span></code></pre>
<p>Together with choice, we also get the stronger principle that every
proposition is decidable. Recall that the class of <code>Decidable</code>
propositions is defined as follows:</p>
<pre><code class="language-lean"><span class="boring">namespace Hidden
</span>class inductive Decidable (p : Prop) where
  | isFalse (h : ¬p) : Decidable p
  | isTrue  (h : p)  : Decidable p
<span class="boring">end Hidden
</span></code></pre>
<p>In contrast to <code>p ∨ ¬ p</code>, which can only eliminate to <code>Prop</code>, the
type <code>decidable p</code> is equivalent to the sum type <code>Sum p (¬ p)</code>, which
can eliminate to any type. It is this data that is needed to write an
if-then-else expression.</p>
<p>As an example of classical reasoning, we use <code>choose</code> to show that if
<code>f : α → β</code> is injective and <code>α</code> is inhabited, then <code>f</code> has a
left inverse. To define the left inverse <code>linv</code>, we use a dependent
if-then-else expression. Recall that <code>if h : c then t else e</code> is
notation for <code>dite c (fun  h : c =&gt; t) (fun h : ¬ c =&gt; e)</code>. In the definition
of <code>linv</code>, choice is used twice: first, to show that
<code>(∃ a : A, f a = b)</code> is &quot;decidable,&quot; and then to choose an <code>a</code> such that
<code>f a = b</code>. Notice that <code>propDecidable</code> is a scoped instance and is activated
by the <code>open Classical</code> command. We use this instance to justify
the if-then-else expression. (See also the discussion in
<a href="./type_classes.html#decidable_propositions">Section Decidable Propositions</a>).</p>
<pre><code class="language-lean">open Classical

noncomputable def linv [Inhabited α] (f : α → β) : β → α :=
  fun b : β =&gt; if ex : (∃ a : α, f a = b) then choose ex else arbitrary

theorem linv_comp_self {f : α → β} [Inhabited α]
                       (inj : ∀ {a b}, f a = f b → a = b)
                       : linv f ∘ f = id :=
  funext fun a =&gt;
    have ex  : ∃ a₁ : α, f a₁ = f a := ⟨a, rfl⟩
    have feq : f (choose ex) = f a  := choose_spec ex
    calc linv f (f a) = choose ex := dif_pos ex
               _      = a         := inj feq

</code></pre>
<p>From a classical point of view, <code>linv</code> is a function. From a
constructive point of view, it is unacceptable; because there is no
way to implement such a function in general, the construction is not
informative.</p>

                    </main>

                    <nav class="nav-wrapper" aria-label="Page navigation">
                        <!-- Mobile navigation buttons -->
                        

                        

                        <div style="clear: both"></div>
                    </nav>
                </div>
            </div>

            <nav class="nav-wide-wrapper" aria-label="Page navigation">
                

                
            </nav>

        </div>

        

        

        

        
        <script type="text/javascript">
            window.playground_copyable = true;
        </script>
        

        

        
        <script src="elasticlunr.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="mark.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="searcher.js" type="text/javascript" charset="utf-8"></script>
        

        <script src="clipboard.min.js" type="text/javascript" charset="utf-8"></script>
        <script src="highlight.js" type="text/javascript" charset="utf-8"></script>
        <script src="book.js" type="text/javascript" charset="utf-8"></script>

        <!-- Custom JS scripts -->
        

        
        
        <script type="text/javascript">
        window.addEventListener('load', function() {
            window.setTimeout(window.print, 100);
        });
        </script>
        
        

    </body>
</html>
